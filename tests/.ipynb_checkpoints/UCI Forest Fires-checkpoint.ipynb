{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import random\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../directionalvi/utils\")\n",
    "sys.path.append(\"../directionalvi\")\n",
    "import traditional_vi\n",
    "from RBFKernelDirectionalGrad import RBFKernelDirectionalGrad\n",
    "#from DirectionalGradVariationalStrategy import DirectionalGradVariationalStrategy\n",
    "from dfree_directional_vi import train_gp, eval_gp\n",
    "from metrics import MSE\n",
    "import testfun\n",
    "from csv_dataset import csv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "[48]\n"
     ]
    }
   ],
   "source": [
    "dataset = csv_dataset(\"../experiments/real_data/WECs_DataSet/Adelaide_Data.csv\", gradients=False, rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71999"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is:  71999\n",
      "dims is:  32\n"
     ]
    }
   ],
   "source": [
    "# data parameters\n",
    "n   = dataset.n\n",
    "print(\"n is: \", n)\n",
    "dim = dataset.dim\n",
    "print(\"dims is: \", dim)\n",
    "\n",
    "# training params\n",
    "num_inducing = 500\n",
    "num_directions = 1\n",
    "minibatch_size = 500\n",
    "num_epochs = 100\n",
    "\n",
    "# seed\n",
    "torch.random.manual_seed(0)\n",
    "# use tqdm or just have print statements\n",
    "tqdm = False\n",
    "# use data to initialize inducing stuff\n",
    "inducing_data_initialization = False\n",
    "# use natural gradients and/or CIQ\n",
    "use_ngd = False\n",
    "use_ciq = False\n",
    "num_contour_quadrature=15\n",
    "# learning rate\n",
    "learning_rate_hypers = 0.01\n",
    "learning_rate_ngd    = 0.1\n",
    "gamma  = 10.0\n",
    "#levels = np.array([20,150,300])\n",
    "#def lr_sched(epoch):\n",
    "#  a = np.sum(levels > epoch)\n",
    "#  return (1./gamma)**a\n",
    "lr_sched = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "n_train = int(0.8*dataset.n)\n",
    "n_test  = n - n_train\n",
    "train_dataset,test_dataset = torch.utils.data.random_split(dataset,[n_train,n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=n_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [item[1] for item in test_loader]\n",
    "test_x = [item[0] for item in test_loader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D-Free Grad SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---DirectionalGradVGP---\n",
      "Start training with 517 trainig data of dim 12\n",
      "VI setups: 400 inducing points, 2 inducing directions\n",
      "All parameters to learn:\n",
      "      variational_strategy.inducing_points\n",
      "      torch.Size([400, 12])\n",
      "      variational_strategy.inducing_directions\n",
      "      torch.Size([800, 12])\n",
      "      variational_strategy._variational_distribution.variational_mean\n",
      "      torch.Size([1200])\n",
      "      variational_strategy._variational_distribution.chol_variational_covar\n",
      "      torch.Size([1200, 1200])\n",
      "      mean_module.constant\n",
      "      torch.Size([1])\n",
      "      covar_module.raw_outputscale\n",
      "      torch.Size([])\n",
      "      covar_module.base_kernel.raw_lengthscale\n",
      "      torch.Size([1, 1])\n",
      "      noise_covar.raw_noise\n",
      "      torch.Size([1])\n",
      "Total number of parameters:  1455604.0\n",
      "Epoch: 0; total_step: 0, loss: 2.3042598725043044, nll: 1.132673509154352\n",
      "Epoch: 16; total_step: 50, loss: 1.2527715682622307, nll: 0.7283301913095945\n",
      "Epoch: 33; total_step: 100, loss: 1.4360152891531113, nll: 0.7191127906908803\n",
      "Epoch: 50; total_step: 150, loss: 1.709476675506499, nll: 1.9865661006058977\n",
      "Epoch: 66; total_step: 200, loss: 1.2826679336879638, nll: 0.9087314207040379\n",
      "Epoch: 83; total_step: 250, loss: 1.3965565593278455, nll: 0.8963383021894099\n",
      "Epoch: 100; total_step: 300, loss: 1.2264089308337212, nll: 0.6637865266279477\n",
      "Epoch: 116; total_step: 350, loss: 1.3713332085214285, nll: 0.5859119850126632\n",
      "Epoch: 133; total_step: 400, loss: 1.3054812351974174, nll: 0.6693859901609995\n",
      "Epoch: 150; total_step: 450, loss: 1.8023865690957712, nll: 1.796499397696231\n",
      "Epoch: 166; total_step: 500, loss: 1.58761363164671, nll: 0.5808234207734904\n",
      "Epoch: 183; total_step: 550, loss: 1.7933750152042736, nll: 0.779124673075344\n",
      "Done! loss: 1.106308830114951\n",
      "\n",
      "Done Training!\n",
      "Done Testing!\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "print(\"\\n\\n---DirectionalGradVGP---\")\n",
    "print(f\"Start training with {n} trainig data of dim {dim}\")\n",
    "print(f\"VI setups: {num_inducing} inducing points, {num_directions} inducing directions\")\n",
    "args={\"verbose\":True}\n",
    "t1 = time.time()\t\n",
    "model,likelihood = train_gp(train_dataset,\n",
    "                      num_inducing=num_inducing,\n",
    "                      num_directions=num_directions,\n",
    "                      minibatch_size = minibatch_size,\n",
    "                      minibatch_dim = num_directions,\n",
    "                      num_epochs =num_epochs, \n",
    "                      learning_rate_hypers=learning_rate_hypers,\n",
    "                      learning_rate_ngd=learning_rate_ngd,\n",
    "                      inducing_data_initialization=inducing_data_initialization,\n",
    "                      use_ngd = use_ngd,\n",
    "                      use_ciq = use_ciq,\n",
    "                      lr_sched=lr_sched,\n",
    "                      num_contour_quadrature=num_contour_quadrature,\n",
    "                      tqdm=tqdm,**args\n",
    "                      )\n",
    "t2 = time.time()\t\n",
    "\n",
    "# save the model\n",
    "# torch.save(model.state_dict(), \"../data/test_dvi_basic.model\")\n",
    "\n",
    "# test\n",
    "means, variances = eval_gp( test_dataset,model,likelihood,\n",
    "                            num_directions=num_directions,\n",
    "                            minibatch_size=n_test,\n",
    "                            minibatch_dim=num_directions)\n",
    "t3 = time.time()\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 104 testing points, MSE: 3.0218e+00, nll: 4.2752e+00.\n",
      "Training time: 837.60 sec, testing time: 0.31 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# compute MSE\n",
    "#test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y[0],means)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means, variances.sqrt()).log_prob(test_y[0]).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")\n",
    "\n",
    "#plot=1\n",
    "#if plot == 1:\n",
    "#    from mpl_toolkits.mplot3d import axes3d\n",
    "#    import matplotlib.pyplot as plt\n",
    "#    fig = plt.figure(figsize=(12,6))\n",
    "#    ax = fig.add_subplot(111, projection='3d')\n",
    "#    ax.scatter(test_x[0][:,0],test_x[:,1],test_y, color='k')\n",
    "#    ax.scatter(test_x[0][:,0],test_x[:,1],means, color='b')\n",
    "#    plt.title(\"f(x,y) variational fit; actual curve is black, variational is blue\")\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "#num_inducing = 50\n",
    "#num_directions = 6\n",
    "#minibatch_size = 200\n",
    "#num_epochs = 100\n",
    "\n",
    "\n",
    "# 2 directions\n",
    "#At 104 testing points, MSE: 2.9133e+00, nll: 3.3945e+00. \n",
    "# 3 directions\n",
    "#At 104 testing points, MSE: 2.9455e+00, nll: 3.3617e+00.\n",
    "#Training time: 70.29 sec, testing time: 0.10 sec\n",
    "# 4 directions\n",
    "#At 104 testing points, MSE: 2.9810e+00, nll: 3.0743e+00.\n",
    "#Training time: 57.68 sec, testing time: 0.08 sec\n",
    "# 5 directions\n",
    "#At 104 testing points, MSE: 2.9440e+00, nll: 3.6124e+00.\n",
    "#Training time: 104.46 sec, testing time: 0.12 sec\n",
    "# 6 directions\n",
    "#At 104 testing points, MSE: 2.9795e+00, nll: 3.1092e+00.\n",
    "#Training time: 127.73 sec, testing time: 0.10 sec\n",
    "# 7 directions\n",
    "#At 104 testing points, MSE: 2.9272e+00, nll: 3.6537e+00.\n",
    "#Training time: 153.38 sec, testing time: 0.12 sec\n",
    "# 8 directions\n",
    "#At 104 testing points, MSE: 2.9503e+00, nll: 3.3300e+00.\n",
    "#Training time: 173.86 sec, testing time: 0.15 sec\n",
    "# 9 directions\n",
    "# 10 directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters to learn:\n",
      "      variational_strategy.inducing_points\n",
      "      torch.Size([400, 12])\n",
      "      variational_strategy._variational_distribution.variational_mean\n",
      "      torch.Size([400])\n",
      "      variational_strategy._variational_distribution.chol_variational_covar\n",
      "      torch.Size([400, 400])\n",
      "      mean_module.constant\n",
      "      torch.Size([1])\n",
      "      covar_module.raw_outputscale\n",
      "      torch.Size([])\n",
      "      covar_module.base_kernel.raw_lengthscale\n",
      "      torch.Size([1, 1])\n",
      "      noise_covar.raw_noise\n",
      "      torch.Size([1])\n",
      "Total number of parameters:  165204.0\n",
      "Using ELBO\n",
      "Epoch: 0; total_step: 0, loss: 2.325866372370561, nll: 1.3773836596656395\n",
      "Epoch: 16; total_step: 50, loss: 1.412803470859386, nll: 0.8634456532284903\n",
      "Epoch: 33; total_step: 100, loss: 1.3417703412237887, nll: 0.7925601768467943\n",
      "Epoch: 50; total_step: 150, loss: 1.304523028078541, nll: 0.7550020453570607\n",
      "Epoch: 66; total_step: 200, loss: 1.1726882573731852, nll: 0.6361890493291381\n",
      "Epoch: 83; total_step: 250, loss: 1.8273089577275365, nll: 1.2631464936919066\n",
      "Epoch: 100; total_step: 300, loss: 1.828317532264014, nll: 1.270440234282399\n",
      "Epoch: 116; total_step: 350, loss: 1.2327371533846632, nll: 0.7011149632737657\n",
      "Epoch: 133; total_step: 400, loss: 1.9745967810972858, nll: 1.4167958425763103\n",
      "Epoch: 150; total_step: 450, loss: 1.27467630177789, nll: 0.7453400950972956\n",
      "Epoch: 166; total_step: 500, loss: 1.1329474543259441, nll: 0.6074078047465398\n",
      "Epoch: 183; total_step: 550, loss: 1.3677171474421284, nll: 0.8359646467951943\n",
      "Done! loss: 1.840421951238335\n",
      "\n",
      "Done Training!\n"
     ]
    }
   ],
   "source": [
    "model_t,likelihood_t = traditional_vi.train_gp(train_dataset,dim,\n",
    "                                                   num_inducing=num_inducing,\n",
    "                                                   minibatch_size=minibatch_size,\n",
    "                                                   num_epochs=num_epochs,\n",
    "                                                   use_ngd=use_ngd, use_ciq=use_ciq,\n",
    "                                                   learning_rate_hypers=learning_rate_hypers,\n",
    "                                                   learning_rate_ngd=learning_rate_ngd,\n",
    "                                                   lr_sched=lr_sched,\n",
    "                                                   num_contour_quadrature=num_contour_quadrature,gamma=gamma, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_t, variances_t = traditional_vi.eval_gp(test_dataset, model_t, likelihood_t, minibatch_size=n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 104 testing points, MSE: 2.8974e+00, nll: 3.5117e+00.\n",
      "Training time: 837.60 sec, testing time: 0.31 sec\n"
     ]
    }
   ],
   "source": [
    "# compute MSE\n",
    "#test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y[0],means_t)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means_t, variances_t.sqrt()).log_prob(test_y[0]).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein\n",
    "# dfree and svgp\n",
    "# At 9146 testing points, MSE: 5.9555e-01, nll: 1.1599e+00.\n",
    "# At 9146 testing points, MSE: 6.2736e-01, nll: 1.1856e+00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forest fire\n",
    "\n",
    "# At 104 testing points, MSE: 3.0218e+00, nll: 4.2752e+00.\n",
    "#Training time: 837.60 sec, testing time: 0.31 sec\n",
    "\n",
    "#At 104 testing points, MSE: 2.8974e+00, nll: 3.5117e+00.\n",
    "#Training time: 837.60 sec, testing time: 0.31 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
