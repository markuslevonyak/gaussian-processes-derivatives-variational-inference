{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import random\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../directionalvi/utils\")\n",
    "sys.path.append(\"../directionalvi\")\n",
    "import traditional_vi\n",
    "from RBFKernelDirectionalGrad import RBFKernelDirectionalGrad\n",
    "#from DirectionalGradVariationalStrategy import DirectionalGradVariationalStrategy\n",
    "from dfree_directional_vi import train_gp, eval_gp\n",
    "from metrics import MSE\n",
    "import testfun\n",
    "from csv_dataset import csv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8]\n",
      "[9]\n"
     ]
    }
   ],
   "source": [
    "dataset = csv_dataset(\"../experiments/real_data/CASP.csv\", gradients=False, rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is:  45730\n",
      "dims is:  9\n"
     ]
    }
   ],
   "source": [
    "# data parameters\n",
    "n   = dataset.n\n",
    "print(\"n is: \", n)\n",
    "dim = dataset.dim\n",
    "print(\"dims is: \", dim)\n",
    "\n",
    "# training params\n",
    "num_inducing = 500\n",
    "num_directions = 1\n",
    "minibatch_size = 200\n",
    "num_epochs = 100\n",
    "\n",
    "# seed\n",
    "torch.random.manual_seed(0)\n",
    "# use tqdm or just have print statements\n",
    "tqdm = False\n",
    "# use data to initialize inducing stuff\n",
    "inducing_data_initialization = False\n",
    "# use natural gradients and/or CIQ\n",
    "use_ngd = False\n",
    "use_ciq = False\n",
    "num_contour_quadrature=15\n",
    "# learning rate\n",
    "learning_rate_hypers = 0.01\n",
    "learning_rate_ngd    = 0.1\n",
    "gamma  = 10.0\n",
    "#levels = np.array([20,150,300])\n",
    "#def lr_sched(epoch):\n",
    "#  a = np.sum(levels > epoch)\n",
    "#  return (1./gamma)**a\n",
    "lr_sched = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "n_train = int(0.8*dataset.n)\n",
    "n_test  = n - n_train\n",
    "train_dataset,test_dataset = torch.utils.data.random_split(dataset,[n_train,n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=n_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [item[1] for item in test_loader]\n",
    "test_x = [item[0] for item in test_loader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D-Free Grad SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---DirectionalGradVGP---\n",
      "Start training with 45730 trainig data of dim 9\n",
      "VI setups: 500 inducing points, 1 inducing directions\n",
      "All parameters to learn:\n",
      "      variational_strategy.inducing_points\n",
      "      torch.Size([500, 9])\n",
      "      variational_strategy.inducing_directions\n",
      "      torch.Size([500, 9])\n",
      "      variational_strategy._variational_distribution.variational_mean\n",
      "      torch.Size([1000])\n",
      "      variational_strategy._variational_distribution.chol_variational_covar\n",
      "      torch.Size([1000, 1000])\n",
      "      mean_module.constant\n",
      "      torch.Size([1])\n",
      "      covar_module.raw_outputscale\n",
      "      torch.Size([])\n",
      "      covar_module.base_kernel.raw_lengthscale\n",
      "      torch.Size([1, 1])\n",
      "      noise_covar.raw_noise\n",
      "      torch.Size([1])\n",
      "Total number of parameters:  1010004.0\n",
      "Epoch: 0; total_step: 0, loss: 2.5546049320523667, nll: 1.5186942597074\n",
      "Epoch: 0; total_step: 50, loss: 1.8084012538245064, nll: 1.2835976646088023\n",
      "Epoch: 0; total_step: 100, loss: 1.738893468901481, nll: 1.2476965661885733\n",
      "Epoch: 0; total_step: 150, loss: 1.7229705259743326, nll: 1.1685941411919398\n",
      "Epoch: 1; total_step: 200, loss: 1.7639526252879665, nll: 1.172045714867734\n",
      "Epoch: 1; total_step: 250, loss: 1.7544448063789775, nll: 1.2385488290250577\n",
      "Epoch: 1; total_step: 300, loss: 1.7560208501057053, nll: 1.2417297308147128\n",
      "Epoch: 1; total_step: 350, loss: 1.707522848004053, nll: 1.221469277888271\n",
      "Epoch: 2; total_step: 400, loss: 1.7820150924026876, nll: 1.2675812552606862\n",
      "Epoch: 2; total_step: 450, loss: 1.735081212304032, nll: 1.240882727565708\n",
      "Epoch: 2; total_step: 500, loss: 1.7172458085734332, nll: 1.2030750506967953\n",
      "Epoch: 3; total_step: 550, loss: 1.6950605171874584, nll: 1.2727180993199936\n",
      "Epoch: 3; total_step: 600, loss: 1.7345089130407718, nll: 1.2642291473039797\n",
      "Epoch: 3; total_step: 650, loss: 1.8267637751044532, nll: 1.2818098582272466\n",
      "Epoch: 3; total_step: 700, loss: 1.6498000843094747, nll: 1.1790304599144044\n",
      "Epoch: 4; total_step: 750, loss: 1.6970307672918687, nll: 1.2372683580591255\n",
      "Epoch: 4; total_step: 800, loss: 1.7035825731006926, nll: 1.1631157965764063\n",
      "Epoch: 4; total_step: 850, loss: 1.8053790944296033, nll: 1.3564815687118457\n",
      "Epoch: 4; total_step: 900, loss: 1.6331643598155952, nll: 1.0986267709165496\n",
      "Epoch: 5; total_step: 950, loss: 1.7362359251376358, nll: 1.207122977292744\n",
      "Epoch: 5; total_step: 1000, loss: 1.7484257020074208, nll: 1.1807473275718672\n",
      "Epoch: 5; total_step: 1050, loss: 1.6832164847166116, nll: 1.1736528247369515\n",
      "Epoch: 6; total_step: 1100, loss: 1.7479523868887412, nll: 1.178971626438095\n",
      "Epoch: 6; total_step: 1150, loss: 1.7365139782198216, nll: 1.1825201377825052\n",
      "Epoch: 6; total_step: 1200, loss: 1.769334138313285, nll: 1.2106465111164586\n",
      "Epoch: 6; total_step: 1250, loss: 1.6773049436157073, nll: 1.194302967773446\n",
      "Epoch: 7; total_step: 1300, loss: 1.6664089462462417, nll: 1.0805534688174723\n",
      "Epoch: 7; total_step: 1350, loss: 1.8053711943525284, nll: 1.306673997139817\n",
      "Epoch: 7; total_step: 1400, loss: 1.6899571522021148, nll: 1.2249929354419644\n",
      "Epoch: 7; total_step: 1450, loss: 1.6674305350754752, nll: 1.2495144396070084\n",
      "Epoch: 8; total_step: 1500, loss: 1.6961619589259629, nll: 1.1488156127164393\n",
      "Epoch: 8; total_step: 1550, loss: 1.7014557773600374, nll: 1.0651553282524433\n",
      "Epoch: 8; total_step: 1600, loss: 1.6307394223308225, nll: 1.1326510162399035\n",
      "Epoch: 9; total_step: 1650, loss: 1.7021026502422734, nll: 1.1212699636070511\n",
      "Epoch: 9; total_step: 1700, loss: 1.7424908290924654, nll: 1.2123931640627925\n",
      "Epoch: 9; total_step: 1750, loss: 1.6377529021017148, nll: 1.1462198487564494\n",
      "Epoch: 9; total_step: 1800, loss: 1.6757698258891978, nll: 1.2091223856618796\n",
      "Epoch: 10; total_step: 1850, loss: 1.6223359370358017, nll: 1.0644750304735298\n",
      "Epoch: 10; total_step: 1900, loss: 1.7192942995379792, nll: 1.1587259044280598\n",
      "Epoch: 10; total_step: 1950, loss: 1.8381532019992226, nll: 1.3713796418937216\n",
      "Epoch: 10; total_step: 2000, loss: 1.6670566241571614, nll: 1.1468529661872535\n",
      "Epoch: 11; total_step: 2050, loss: 1.6569559965545995, nll: 1.1153987546214355\n",
      "Epoch: 11; total_step: 2100, loss: 1.6290196197354752, nll: 1.0735809929366713\n",
      "Epoch: 11; total_step: 2150, loss: 1.7959058229776985, nll: 1.322203285684833\n",
      "Epoch: 12; total_step: 2200, loss: 1.6566273844474448, nll: 1.1735915965166228\n",
      "Epoch: 12; total_step: 2250, loss: 1.7691922831379656, nll: 1.2836745788471842\n",
      "Epoch: 12; total_step: 2300, loss: 1.6359816345991778, nll: 1.1012536738087986\n",
      "Epoch: 12; total_step: 2350, loss: 1.6218639277007418, nll: 1.1433655153185998\n",
      "Epoch: 13; total_step: 2400, loss: 1.7101996929679157, nll: 1.1740140457883086\n",
      "Epoch: 13; total_step: 2450, loss: 1.6898553813921773, nll: 1.2396882034649799\n",
      "Epoch: 13; total_step: 2500, loss: 1.6499805710717288, nll: 1.2467128073730709\n",
      "Epoch: 13; total_step: 2550, loss: 1.7559665320014994, nll: 1.2603819686217623\n",
      "Epoch: 14; total_step: 2600, loss: 1.6860133982531011, nll: 1.20416929331807\n",
      "Epoch: 14; total_step: 2650, loss: 1.7650941973047152, nll: 1.2454317242389654\n",
      "Epoch: 14; total_step: 2700, loss: 1.6167661201834205, nll: 1.1859112211844454\n",
      "Epoch: 15; total_step: 2750, loss: 1.6161114908406335, nll: 1.0957782727917498\n",
      "Epoch: 15; total_step: 2800, loss: 1.6940385300725032, nll: 1.2598032078580697\n",
      "Epoch: 15; total_step: 2850, loss: 1.6192867316750739, nll: 1.0856276410478503\n",
      "Epoch: 15; total_step: 2900, loss: 1.673435890111807, nll: 1.2273935613814453\n",
      "Epoch: 16; total_step: 2950, loss: 1.7329304424795742, nll: 1.211543702658702\n",
      "Epoch: 16; total_step: 3000, loss: 1.7768396338522132, nll: 1.1539320607554273\n",
      "Epoch: 16; total_step: 3050, loss: 1.688765799786144, nll: 1.1783266721045407\n",
      "Epoch: 16; total_step: 3100, loss: 1.6359202087801124, nll: 1.0408646995211766\n",
      "Epoch: 17; total_step: 3150, loss: 1.6916526257622053, nll: 1.2423777826640823\n",
      "Epoch: 17; total_step: 3200, loss: 1.6793661653385512, nll: 1.087665008264392\n",
      "Epoch: 17; total_step: 3250, loss: 1.721688574531457, nll: 1.1534584244708599\n",
      "Epoch: 18; total_step: 3300, loss: 1.6588690985424432, nll: 1.1379683802797056\n",
      "Epoch: 18; total_step: 3350, loss: 1.7651136627437873, nll: 1.2541590982887763\n",
      "Epoch: 18; total_step: 3400, loss: 1.6942821503707302, nll: 1.2328632437362987\n",
      "Epoch: 18; total_step: 3450, loss: 1.70383334745703, nll: 1.1857263009533525\n",
      "Epoch: 19; total_step: 3500, loss: 1.7529965418331483, nll: 1.2575265419867572\n",
      "Epoch: 19; total_step: 3550, loss: 1.6757799785805587, nll: 1.1745565949435997\n",
      "Epoch: 19; total_step: 3600, loss: 1.661241686896599, nll: 1.1142054864259896\n",
      "Epoch: 19; total_step: 3650, loss: 1.643114668804539, nll: 1.1561324061573075\n",
      "Epoch: 20; total_step: 3700, loss: 1.6907786443114297, nll: 1.2065789846456745\n",
      "Epoch: 20; total_step: 3750, loss: 1.6315723628016008, nll: 1.1208235322687883\n",
      "Epoch: 20; total_step: 3800, loss: 1.6603929962611732, nll: 1.1202193659988617\n",
      "Epoch: 21; total_step: 3850, loss: 1.6342341396045879, nll: 1.037368663393621\n",
      "Epoch: 21; total_step: 3900, loss: 1.705800720208985, nll: 1.2108626240277551\n",
      "Epoch: 21; total_step: 3950, loss: 1.7405427179403263, nll: 1.2857921267543384\n",
      "Epoch: 21; total_step: 4000, loss: 1.638729142395523, nll: 1.0310691446952691\n",
      "Epoch: 22; total_step: 4050, loss: 1.73752278692272, nll: 1.2101602410213375\n",
      "Epoch: 22; total_step: 4100, loss: 1.7686058263437716, nll: 1.2487205993170774\n",
      "Epoch: 22; total_step: 4150, loss: 1.6083166929375572, nll: 1.072528710674332\n",
      "Epoch: 22; total_step: 4200, loss: 1.5872036941640482, nll: 1.0733480864711442\n",
      "Epoch: 23; total_step: 4250, loss: 1.6530660135338158, nll: 1.1590659565483017\n",
      "Epoch: 23; total_step: 4300, loss: 1.6422950972222266, nll: 1.167824144123461\n",
      "Epoch: 23; total_step: 4350, loss: 1.6526122314235456, nll: 1.1819168936171094\n",
      "Epoch: 24; total_step: 4400, loss: 1.7400901132113529, nll: 1.203136233592828\n",
      "Epoch: 24; total_step: 4450, loss: 1.7312624169967699, nll: 1.1919682957307662\n",
      "Epoch: 24; total_step: 4500, loss: 1.645039323522871, nll: 1.1542232444382605\n",
      "Epoch: 24; total_step: 4550, loss: 1.6306720605632465, nll: 1.1068678642889378\n",
      "Epoch: 25; total_step: 4600, loss: 1.659068063504384, nll: 1.2091553719932011\n",
      "Epoch: 25; total_step: 4650, loss: 1.6494528756397264, nll: 1.0987232514552503\n",
      "Epoch: 25; total_step: 4700, loss: 1.7813815675396782, nll: 1.2807979673027972\n",
      "Epoch: 25; total_step: 4750, loss: 1.732887506333232, nll: 1.3148136930643994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26; total_step: 4800, loss: 1.6923812909118132, nll: 1.1830591796899028\n",
      "Epoch: 26; total_step: 4850, loss: 1.7279505722410418, nll: 1.2938393524526213\n",
      "Epoch: 26; total_step: 4900, loss: 1.6560486002179808, nll: 1.108975642179913\n",
      "Epoch: 27; total_step: 4950, loss: 1.7134121522834267, nll: 1.1572707121263088\n",
      "Epoch: 27; total_step: 5000, loss: 1.724345091635982, nll: 1.2428133554393332\n",
      "Epoch: 27; total_step: 5050, loss: 1.5965660225373908, nll: 1.1202069650004405\n",
      "Epoch: 27; total_step: 5100, loss: 1.6377579739756003, nll: 1.1053572042307842\n",
      "Epoch: 28; total_step: 5150, loss: 1.733804238646575, nll: 1.2491318485294198\n",
      "Epoch: 28; total_step: 5200, loss: 1.5890153847511699, nll: 1.0759993921752327\n",
      "Epoch: 28; total_step: 5250, loss: 1.6236911549256186, nll: 1.1072626290627319\n",
      "Epoch: 28; total_step: 5300, loss: 1.647873352489607, nll: 1.1629221651485795\n",
      "Epoch: 29; total_step: 5350, loss: 1.6677832037970548, nll: 1.179505137547505\n",
      "Epoch: 29; total_step: 5400, loss: 1.6269227297572149, nll: 1.1238559858620143\n",
      "Epoch: 29; total_step: 5450, loss: 1.621812852722749, nll: 1.1760167455950243\n",
      "Epoch: 30; total_step: 5500, loss: 1.699360628838015, nll: 1.234757024573379\n",
      "Epoch: 30; total_step: 5550, loss: 1.6630936929345614, nll: 1.2813465746750246\n",
      "Epoch: 30; total_step: 5600, loss: 1.6727964164323965, nll: 1.1941121401800243\n",
      "Epoch: 30; total_step: 5650, loss: 1.6999106132133521, nll: 1.19297800551507\n",
      "Epoch: 31; total_step: 5700, loss: 1.6307164461216814, nll: 1.0843103250426638\n",
      "Epoch: 31; total_step: 5750, loss: 1.7074876817035118, nll: 1.1974355089975715\n",
      "Epoch: 31; total_step: 5800, loss: 1.6487961471495538, nll: 1.1550367183304646\n",
      "Epoch: 31; total_step: 5850, loss: 1.668329784291812, nll: 1.1704003769212996\n",
      "Epoch: 32; total_step: 5900, loss: 1.6628948479085954, nll: 1.143528048231483\n",
      "Epoch: 32; total_step: 5950, loss: 1.706971835427322, nll: 1.1343224608449618\n",
      "Epoch: 32; total_step: 6000, loss: 1.6752093996763466, nll: 1.1824184742731498\n",
      "Epoch: 33; total_step: 6050, loss: 1.6412846271152546, nll: 1.1325481127672583\n",
      "Epoch: 33; total_step: 6100, loss: 1.6497225552988204, nll: 1.2242948891992764\n",
      "Epoch: 33; total_step: 6150, loss: 1.7382348352621333, nll: 1.2241433837241298\n",
      "Epoch: 33; total_step: 6200, loss: 1.6340615928120759, nll: 1.1282675543556508\n",
      "Epoch: 34; total_step: 6250, loss: 1.717848590081295, nll: 1.1145715619483632\n",
      "Epoch: 34; total_step: 6300, loss: 1.6452497818864495, nll: 1.117739952320804\n",
      "Epoch: 34; total_step: 6350, loss: 1.68707316523974, nll: 1.150069772790243\n",
      "Epoch: 34; total_step: 6400, loss: 1.6526771078504465, nll: 1.144715364953533\n",
      "Epoch: 35; total_step: 6450, loss: 1.6851622608185761, nll: 1.1552789286500431\n",
      "Epoch: 35; total_step: 6500, loss: 1.5909080984392148, nll: 1.0720213402374852\n",
      "Epoch: 35; total_step: 6550, loss: 1.7026113854978293, nll: 1.2097916657388077\n",
      "Epoch: 36; total_step: 6600, loss: 1.619712294617928, nll: 1.1346192347692086\n",
      "Epoch: 36; total_step: 6650, loss: 1.6642901839569781, nll: 1.1267050717338662\n",
      "Epoch: 36; total_step: 6700, loss: 1.6607976678972085, nll: 1.1009162926298004\n",
      "Epoch: 36; total_step: 6750, loss: 1.7282965897656621, nll: 1.1423923468447994\n",
      "Epoch: 37; total_step: 6800, loss: 1.713432301511297, nll: 1.3186217273046672\n",
      "Epoch: 37; total_step: 6850, loss: 1.7450608637651346, nll: 1.1937155437048315\n",
      "Epoch: 37; total_step: 6900, loss: 1.7017995154689942, nll: 1.2091816552178054\n",
      "Epoch: 37; total_step: 6950, loss: 1.691565335703786, nll: 1.099523573701303\n",
      "Epoch: 38; total_step: 7000, loss: 1.62258462272516, nll: 1.1645443958745676\n",
      "Epoch: 38; total_step: 7050, loss: 1.705720900835882, nll: 1.1448954872050827\n",
      "Epoch: 38; total_step: 7100, loss: 1.7518110390615615, nll: 1.2218967756912904\n",
      "Epoch: 39; total_step: 7150, loss: 1.6976846619495694, nll: 1.1942063415981177\n",
      "Epoch: 39; total_step: 7200, loss: 1.5871336718759779, nll: 1.095268242636356\n",
      "Epoch: 39; total_step: 7250, loss: 1.7059769749582285, nll: 1.18292301439281\n",
      "Epoch: 39; total_step: 7300, loss: 1.708200308112724, nll: 1.1951500839467355\n",
      "Epoch: 40; total_step: 7350, loss: 1.6727299436073508, nll: 1.1820578214379378\n",
      "Epoch: 40; total_step: 7400, loss: 1.6133672062512745, nll: 1.0339361504568298\n",
      "Epoch: 40; total_step: 7450, loss: 1.6138440799392044, nll: 1.1040229081800321\n",
      "Epoch: 40; total_step: 7500, loss: 1.6384996846886117, nll: 1.1409849628457196\n",
      "Epoch: 41; total_step: 7550, loss: 1.603007112284307, nll: 1.1478626200026156\n",
      "Epoch: 41; total_step: 7600, loss: 1.6105724106531927, nll: 1.1033246240922312\n",
      "Epoch: 41; total_step: 7650, loss: 1.6551107454620217, nll: 1.1970133888568588\n",
      "Epoch: 42; total_step: 7700, loss: 1.6440979049607665, nll: 1.1167210506202199\n",
      "Epoch: 42; total_step: 7750, loss: 1.7492399081633239, nll: 1.2488149692956403\n",
      "Epoch: 42; total_step: 7800, loss: 1.6333226332456416, nll: 1.1469836392555985\n",
      "Epoch: 42; total_step: 7850, loss: 1.6049633409938178, nll: 1.1285063368833512\n",
      "Epoch: 43; total_step: 7900, loss: 1.642890010201551, nll: 1.1191902802463003\n",
      "Epoch: 43; total_step: 7950, loss: 1.724982276068233, nll: 1.3249449899842844\n",
      "Epoch: 43; total_step: 8000, loss: 1.6939555481124569, nll: 1.1750002509451098\n",
      "Epoch: 43; total_step: 8050, loss: 1.613169621339273, nll: 1.0572781423397846\n",
      "Epoch: 44; total_step: 8100, loss: 1.7789145776430655, nll: 1.1959075917794808\n",
      "Epoch: 44; total_step: 8150, loss: 1.6216424590343335, nll: 1.08198038077034\n",
      "Epoch: 44; total_step: 8200, loss: 1.7128352041767108, nll: 1.10791094796167\n",
      "Epoch: 45; total_step: 8250, loss: 1.6099418444508475, nll: 1.0974023299363496\n",
      "Epoch: 45; total_step: 8300, loss: 1.630311775302755, nll: 1.1517403568384148\n",
      "Epoch: 45; total_step: 8350, loss: 1.601534956538384, nll: 1.1103320541041242\n",
      "Epoch: 45; total_step: 8400, loss: 1.731883042404312, nll: 1.3799429493276159\n",
      "Epoch: 46; total_step: 8450, loss: 1.6094657442087146, nll: 1.0728960692705227\n",
      "Epoch: 46; total_step: 8500, loss: 1.6116998990333602, nll: 1.1736232975246914\n",
      "Epoch: 46; total_step: 8550, loss: 1.7263036320097631, nll: 1.15511721765687\n",
      "Epoch: 46; total_step: 8600, loss: 1.771749034079213, nll: 1.2649766569959735\n",
      "Epoch: 47; total_step: 8650, loss: 1.6359593106544437, nll: 1.1351551677325216\n",
      "Epoch: 47; total_step: 8700, loss: 1.674480945830667, nll: 1.2399596069995293\n",
      "Epoch: 47; total_step: 8750, loss: 1.6823070117206367, nll: 1.1866125538851622\n",
      "Epoch: 48; total_step: 8800, loss: 1.5872629412575063, nll: 1.0810144144996436\n",
      "Epoch: 48; total_step: 8850, loss: 1.6434723163907023, nll: 1.2000282433889178\n",
      "Epoch: 48; total_step: 8900, loss: 1.6516313345287796, nll: 1.1138810799794507\n",
      "Epoch: 48; total_step: 8950, loss: 1.6219956996315477, nll: 1.2109938841091403\n",
      "Epoch: 49; total_step: 9000, loss: 1.6578960893292043, nll: 1.1255768603068288\n",
      "Epoch: 49; total_step: 9050, loss: 1.6877468911539688, nll: 1.1586815357021865\n",
      "Epoch: 49; total_step: 9100, loss: 1.7080190682000083, nll: 1.2378322907486214\n",
      "Epoch: 50; total_step: 9150, loss: 1.6178663626684264, nll: 1.139083765872495\n",
      "Epoch: 50; total_step: 9200, loss: 1.7363318492756254, nll: 1.2682437277196346\n",
      "Epoch: 50; total_step: 9250, loss: 1.713920786047261, nll: 1.1906721944395822\n",
      "Epoch: 50; total_step: 9300, loss: 1.66959286068173, nll: 1.2037791565835811\n",
      "Epoch: 51; total_step: 9350, loss: 1.7413290963929164, nll: 1.2096257018135588\n",
      "Epoch: 51; total_step: 9400, loss: 1.62711101968772, nll: 1.1605510620367103\n",
      "Epoch: 51; total_step: 9450, loss: 1.6742346594919346, nll: 1.1404172457373598\n",
      "Epoch: 51; total_step: 9500, loss: 1.686774862525196, nll: 1.0908214072675384\n",
      "Epoch: 52; total_step: 9550, loss: 1.6293156199024141, nll: 1.1523168403186295\n",
      "Epoch: 52; total_step: 9600, loss: 1.6616317387245392, nll: 1.0974355402563547\n",
      "Epoch: 52; total_step: 9650, loss: 1.7019791661191024, nll: 1.2098512122696026\n",
      "Epoch: 53; total_step: 9700, loss: 1.729467261897631, nll: 1.1784595402335896\n",
      "Epoch: 53; total_step: 9750, loss: 1.6415304079233994, nll: 1.0601298385482902\n",
      "Epoch: 53; total_step: 9800, loss: 1.7734815838656601, nll: 1.1753171381145606\n",
      "Epoch: 53; total_step: 9850, loss: 1.6436409561372733, nll: 1.06414338303674\n",
      "Epoch: 54; total_step: 9900, loss: 1.774836554334907, nll: 1.2276898689656255\n",
      "Epoch: 54; total_step: 9950, loss: 1.6477999013146423, nll: 1.1551387708083607\n",
      "Epoch: 54; total_step: 10000, loss: 1.6874877847588794, nll: 1.1207756968393234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54; total_step: 10050, loss: 1.6706827444833907, nll: 1.1496090401682362\n",
      "Epoch: 55; total_step: 10100, loss: 1.7015126660833542, nll: 1.1503766073143096\n",
      "Epoch: 55; total_step: 10150, loss: 1.7066115151270884, nll: 1.2539013959640177\n",
      "Epoch: 55; total_step: 10200, loss: 1.6827154900518873, nll: 1.187986188303058\n",
      "Epoch: 56; total_step: 10250, loss: 1.6768109421786275, nll: 1.2028768930744276\n",
      "Epoch: 56; total_step: 10300, loss: 1.7123309400587114, nll: 1.1878174568799214\n",
      "Epoch: 56; total_step: 10350, loss: 1.6833170567212454, nll: 1.0950377601143624\n",
      "Epoch: 56; total_step: 10400, loss: 1.6240748514684578, nll: 1.1179898183492873\n",
      "Epoch: 57; total_step: 10450, loss: 1.658434227334724, nll: 1.1676971981896855\n",
      "Epoch: 57; total_step: 10500, loss: 1.6558806747035442, nll: 1.1274239779728714\n",
      "Epoch: 57; total_step: 10550, loss: 1.709263563917849, nll: 1.1446303812432084\n",
      "Epoch: 57; total_step: 10600, loss: 1.6681375438930304, nll: 1.2503702576294424\n",
      "Epoch: 58; total_step: 10650, loss: 1.677222015919546, nll: 1.1821078092834605\n",
      "Epoch: 58; total_step: 10700, loss: 1.6661973215571726, nll: 1.2005133994347437\n",
      "Epoch: 58; total_step: 10750, loss: 1.6052237966510043, nll: 1.0610142863782752\n",
      "Epoch: 59; total_step: 10800, loss: 1.6272521845511827, nll: 1.1086598286844385\n",
      "Epoch: 59; total_step: 10850, loss: 1.6443670896457327, nll: 1.1036638457328438\n",
      "Epoch: 59; total_step: 10900, loss: 1.6800756822886518, nll: 1.1422609703665862\n",
      "Epoch: 59; total_step: 10950, loss: 1.6681231387850255, nll: 1.1792945822443452\n",
      "Epoch: 60; total_step: 11000, loss: 1.607453691857011, nll: 1.1711158533706663\n",
      "Epoch: 60; total_step: 11050, loss: 1.7054680510505338, nll: 1.2107624105394987\n",
      "Epoch: 60; total_step: 11100, loss: 1.5993424495971913, nll: 1.0910422195623737\n",
      "Epoch: 60; total_step: 11150, loss: 1.6566519826714836, nll: 1.0837312243987673\n",
      "Epoch: 61; total_step: 11200, loss: 1.694641056526721, nll: 1.2467593315540066\n",
      "Epoch: 61; total_step: 11250, loss: 1.6381711837269657, nll: 1.1742595460968475\n",
      "Epoch: 61; total_step: 11300, loss: 1.6841002340701192, nll: 1.1607108442796163\n",
      "Epoch: 62; total_step: 11350, loss: 1.6844442967777935, nll: 1.1278036963597895\n",
      "Epoch: 62; total_step: 11400, loss: 1.7097670686680018, nll: 1.1533436887845196\n",
      "Epoch: 62; total_step: 11450, loss: 1.6607328262248637, nll: 1.103174258652963\n",
      "Epoch: 62; total_step: 11500, loss: 1.6370498449255768, nll: 1.0896161502158666\n",
      "Epoch: 63; total_step: 11550, loss: 1.7292720809685331, nll: 1.1599654480041615\n",
      "Epoch: 63; total_step: 11600, loss: 1.6214161420832958, nll: 1.0937270047385093\n",
      "Epoch: 63; total_step: 11650, loss: 1.5958850935880224, nll: 1.0824099765889708\n",
      "Epoch: 63; total_step: 11700, loss: 1.6460272426027711, nll: 1.1682929060353975\n",
      "Epoch: 64; total_step: 11750, loss: 1.6519192864817382, nll: 1.1014598977108343\n",
      "Epoch: 64; total_step: 11800, loss: 1.690525151941085, nll: 1.2444833533578719\n",
      "Epoch: 64; total_step: 11850, loss: 1.6351943178912083, nll: 1.1623159708737998\n",
      "Epoch: 65; total_step: 11900, loss: 1.633378629473574, nll: 1.0841537391792473\n",
      "Epoch: 65; total_step: 11950, loss: 1.623005154010685, nll: 1.098111152176894\n",
      "Epoch: 65; total_step: 12000, loss: 1.6410976981216907, nll: 1.182496013058494\n",
      "Epoch: 65; total_step: 12050, loss: 1.6625258853969371, nll: 1.188469688452272\n",
      "Epoch: 66; total_step: 12100, loss: 1.6796527973112452, nll: 1.2277884406059234\n",
      "Epoch: 66; total_step: 12150, loss: 1.7055402775554278, nll: 1.1997434301500371\n",
      "Epoch: 66; total_step: 12200, loss: 1.708903456303728, nll: 1.1922987845147401\n",
      "Epoch: 66; total_step: 12250, loss: 1.5509623439943598, nll: 1.0260084399546927\n",
      "Epoch: 67; total_step: 12300, loss: 1.7559479774202666, nll: 1.232897269566148\n",
      "Epoch: 67; total_step: 12350, loss: 1.745253076599145, nll: 1.2055354190792609\n",
      "Epoch: 67; total_step: 12400, loss: 1.6262826369669503, nll: 1.106133485174431\n",
      "Epoch: 68; total_step: 12450, loss: 1.6831802187177483, nll: 1.1872965123065375\n",
      "Epoch: 68; total_step: 12500, loss: 1.650907141374602, nll: 1.1450786939122104\n",
      "Epoch: 68; total_step: 12550, loss: 1.5902341345663678, nll: 1.0407158511300374\n",
      "Epoch: 68; total_step: 12600, loss: 1.6139896822251154, nll: 1.0969452219407245\n",
      "Epoch: 69; total_step: 12650, loss: 1.6430219741211565, nll: 1.101933310443609\n",
      "Epoch: 69; total_step: 12700, loss: 1.620842570711111, nll: 1.083133462344518\n",
      "Epoch: 69; total_step: 12750, loss: 1.6716592294541248, nll: 1.2095192297693904\n",
      "Epoch: 69; total_step: 12800, loss: 1.7505715609066987, nll: 1.123683148455226\n",
      "Epoch: 70; total_step: 12850, loss: 1.7283027435529044, nll: 1.1771311951094265\n",
      "Epoch: 70; total_step: 12900, loss: 1.6385174456218599, nll: 1.075800401402403\n",
      "Epoch: 70; total_step: 12950, loss: 1.7124143519313662, nll: 1.1981300267166928\n",
      "Epoch: 71; total_step: 13000, loss: 1.7449270527908245, nll: 1.173407017093175\n",
      "Epoch: 71; total_step: 13050, loss: 1.6297622299026484, nll: 1.1369998571555422\n",
      "Epoch: 71; total_step: 13100, loss: 1.6689380525338913, nll: 1.1856049254634546\n",
      "Epoch: 71; total_step: 13150, loss: 1.6876537221331358, nll: 1.1053637075987266\n",
      "Epoch: 72; total_step: 13200, loss: 1.7248353500326317, nll: 1.1580371350364613\n",
      "Epoch: 72; total_step: 13250, loss: 1.7004445632953542, nll: 1.1978779795233983\n",
      "Epoch: 72; total_step: 13300, loss: 1.7486496344787879, nll: 1.226878300352685\n",
      "Epoch: 72; total_step: 13350, loss: 1.733525741400543, nll: 1.250705630108318\n",
      "Epoch: 73; total_step: 13400, loss: 1.6768066153050716, nll: 1.2565556725046934\n",
      "Epoch: 73; total_step: 13450, loss: 1.6391904983681151, nll: 1.1119609847950607\n",
      "Epoch: 73; total_step: 13500, loss: 1.720138774935268, nll: 1.1990011680176555\n",
      "Epoch: 74; total_step: 13550, loss: 1.7404885727309283, nll: 1.1813578838291594\n",
      "Epoch: 74; total_step: 13600, loss: 1.6825318734851908, nll: 1.2410403260298506\n",
      "Epoch: 74; total_step: 13650, loss: 1.6809388101747382, nll: 1.1810202808184105\n",
      "Epoch: 74; total_step: 13700, loss: 1.6293007026296045, nll: 1.1386397070772156\n",
      "Epoch: 75; total_step: 13750, loss: 1.744430596667254, nll: 1.2025210733267802\n",
      "Epoch: 75; total_step: 13800, loss: 1.751099690011263, nll: 1.1820548441881027\n",
      "Epoch: 75; total_step: 13850, loss: 1.624904467325373, nll: 1.121007008222433\n",
      "Epoch: 75; total_step: 13900, loss: 1.6731980192567644, nll: 1.1637659556441338\n",
      "Epoch: 76; total_step: 13950, loss: 1.7011513701400873, nll: 1.2254906189054144\n",
      "Epoch: 76; total_step: 14000, loss: 1.6046172934679361, nll: 1.0560850931265016\n",
      "Epoch: 76; total_step: 14050, loss: 1.647848955908989, nll: 1.1155103122217331\n",
      "Epoch: 77; total_step: 14100, loss: 1.6512346054341185, nll: 1.1276112864626375\n",
      "Epoch: 77; total_step: 14150, loss: 1.6816751326121528, nll: 1.182038687164513\n",
      "Epoch: 77; total_step: 14200, loss: 1.7772375257359534, nll: 1.2662943615514275\n",
      "Epoch: 77; total_step: 14250, loss: 1.6358394421018807, nll: 1.092498192707811\n",
      "Epoch: 78; total_step: 14300, loss: 1.6753448462333436, nll: 1.206412592338717\n",
      "Epoch: 78; total_step: 14350, loss: 1.5764207348030115, nll: 0.9935782570127702\n",
      "Epoch: 78; total_step: 14400, loss: 1.6150652665882932, nll: 1.0553703489649349\n",
      "Epoch: 78; total_step: 14450, loss: 1.6736733147444118, nll: 1.171362479346257\n",
      "Epoch: 79; total_step: 14500, loss: 1.6847250409559758, nll: 1.2237631983235298\n",
      "Epoch: 79; total_step: 14550, loss: 1.6344252112911852, nll: 1.1873058000643935\n",
      "Epoch: 79; total_step: 14600, loss: 1.683822562590384, nll: 1.2191257034936769\n",
      "Epoch: 80; total_step: 14650, loss: 1.6356766935682492, nll: 1.1100737242923926\n",
      "Epoch: 80; total_step: 14700, loss: 1.7083943692992398, nll: 1.165995025966895\n",
      "Epoch: 80; total_step: 14750, loss: 1.6485997017567724, nll: 1.1399156079249233\n",
      "Epoch: 80; total_step: 14800, loss: 1.5925147132021358, nll: 1.080008494414043\n",
      "Epoch: 81; total_step: 14850, loss: 1.5461395718913082, nll: 1.057108476521826\n",
      "Epoch: 81; total_step: 14900, loss: 1.6366428789221268, nll: 1.1342510793233955\n",
      "Epoch: 81; total_step: 14950, loss: 1.5677545153413968, nll: 1.0859567407293793\n",
      "Epoch: 81; total_step: 15000, loss: 1.604743829492243, nll: 1.0873795361650402\n",
      "Epoch: 82; total_step: 15050, loss: 1.6127910704968076, nll: 1.1576606805044616\n",
      "Epoch: 82; total_step: 15100, loss: 1.7043438501277732, nll: 1.2052297816523057\n",
      "Epoch: 82; total_step: 15150, loss: 1.6652668844967005, nll: 1.1027286649736892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83; total_step: 15200, loss: 1.6839627063067715, nll: 1.2024427466861944\n",
      "Epoch: 83; total_step: 15250, loss: 1.5951114637284272, nll: 1.0958603452108417\n",
      "Epoch: 83; total_step: 15300, loss: 1.594004563265631, nll: 1.0991652003384216\n",
      "Epoch: 83; total_step: 15350, loss: 1.7034791582116935, nll: 1.308489066748954\n",
      "Epoch: 84; total_step: 15400, loss: 1.6462517459709358, nll: 1.1236176296845128\n",
      "Epoch: 84; total_step: 15450, loss: 1.6515469276626118, nll: 1.082604549391296\n",
      "Epoch: 84; total_step: 15500, loss: 1.7322496070668216, nll: 1.2874041766892328\n",
      "Epoch: 84; total_step: 15550, loss: 1.6460587487235818, nll: 1.0920256993713675\n",
      "Epoch: 85; total_step: 15600, loss: 1.7014415017840545, nll: 1.2074432349266124\n",
      "Epoch: 85; total_step: 15650, loss: 1.749313536146043, nll: 1.2615194371492788\n",
      "Epoch: 85; total_step: 15700, loss: 1.6894229305707764, nll: 1.199971279088559\n",
      "Epoch: 86; total_step: 15750, loss: 1.6434336571989494, nll: 1.1923088678283116\n",
      "Epoch: 86; total_step: 15800, loss: 1.5647919144558051, nll: 1.0137992550410175\n",
      "Epoch: 86; total_step: 15850, loss: 1.69661788318366, nll: 1.1315782036816393\n",
      "Epoch: 86; total_step: 15900, loss: 1.6402480985553423, nll: 1.145996328407876\n",
      "Epoch: 87; total_step: 15950, loss: 1.733377949722248, nll: 1.2401453491953636\n",
      "Epoch: 87; total_step: 16000, loss: 1.5980088418317606, nll: 1.0351938358716533\n",
      "Epoch: 87; total_step: 16050, loss: 1.6908068646614856, nll: 1.2018036173510747\n",
      "Epoch: 87; total_step: 16100, loss: 1.5965027925427138, nll: 1.0566958718869797\n",
      "Epoch: 88; total_step: 16150, loss: 1.6671235793215984, nll: 1.1336389378624236\n",
      "Epoch: 88; total_step: 16200, loss: 1.6815206150387036, nll: 1.1156209382011633\n",
      "Epoch: 88; total_step: 16250, loss: 1.5625633550937135, nll: 0.9517148291722137\n",
      "Epoch: 89; total_step: 16300, loss: 1.6503983859598974, nll: 1.1071675806282049\n",
      "Epoch: 89; total_step: 16350, loss: 1.7655959454214827, nll: 1.1545678669189632\n",
      "Epoch: 89; total_step: 16400, loss: 1.5647622591946848, nll: 1.0025036077881222\n",
      "Epoch: 89; total_step: 16450, loss: 1.6985068392047071, nll: 1.1950382539312816\n",
      "Epoch: 90; total_step: 16500, loss: 1.71031185691248, nll: 1.2695159360149646\n",
      "Epoch: 90; total_step: 16550, loss: 1.7049939905020048, nll: 1.2280698301562154\n",
      "Epoch: 90; total_step: 16600, loss: 1.6067904829872623, nll: 1.1332567395097701\n",
      "Epoch: 90; total_step: 16650, loss: 1.603868046945597, nll: 1.0718537987968515\n",
      "Epoch: 91; total_step: 16700, loss: 1.6660080424493788, nll: 1.1191362969257925\n",
      "Epoch: 91; total_step: 16750, loss: 1.634527994895878, nll: 1.104546645974103\n",
      "Epoch: 91; total_step: 16800, loss: 1.7228216837568615, nll: 1.1817432892148754\n",
      "Epoch: 92; total_step: 16850, loss: 1.637333831420098, nll: 1.0447294867895713\n",
      "Epoch: 92; total_step: 16900, loss: 1.6674092820555708, nll: 1.1546359796999723\n",
      "Epoch: 92; total_step: 16950, loss: 1.612571435673363, nll: 1.037372915406268\n",
      "Epoch: 92; total_step: 17000, loss: 1.6312350148078811, nll: 1.111986408645713\n",
      "Epoch: 93; total_step: 17050, loss: 1.6576669938210638, nll: 1.0814108827431246\n",
      "Epoch: 93; total_step: 17100, loss: 1.6916964876328526, nll: 1.2034641286741392\n",
      "Epoch: 93; total_step: 17150, loss: 1.6912122292575094, nll: 1.315773328122933\n",
      "Epoch: 93; total_step: 17200, loss: 1.7220741655497165, nll: 1.153637091503445\n",
      "Epoch: 94; total_step: 17250, loss: 1.6221963333678497, nll: 1.0804751490703064\n",
      "Epoch: 94; total_step: 17300, loss: 1.6288837356682109, nll: 1.095945307584455\n",
      "Epoch: 94; total_step: 17350, loss: 1.5662480635326534, nll: 1.0436566214042784\n",
      "Epoch: 95; total_step: 17400, loss: 1.676566587054091, nll: 1.2179367663946192\n",
      "Epoch: 95; total_step: 17450, loss: 1.6316440664151128, nll: 1.092152225519777\n",
      "Epoch: 95; total_step: 17500, loss: 1.6766864530176242, nll: 1.1212599170160618\n",
      "Epoch: 95; total_step: 17550, loss: 1.625343398212608, nll: 1.1468983376989994\n",
      "Epoch: 96; total_step: 17600, loss: 1.7061365759609861, nll: 1.1106498410673897\n",
      "Epoch: 96; total_step: 17650, loss: 1.6816527307890223, nll: 1.091931691338472\n",
      "Epoch: 96; total_step: 17700, loss: 1.705331287942968, nll: 1.1482550415164723\n",
      "Epoch: 96; total_step: 17750, loss: 1.6403027692704948, nll: 1.1501504742506738\n",
      "Epoch: 97; total_step: 17800, loss: 1.5884596068285064, nll: 1.1305865423672552\n",
      "Epoch: 97; total_step: 17850, loss: 1.6312781448099773, nll: 1.103236448712754\n",
      "Epoch: 97; total_step: 17900, loss: 1.684679412784159, nll: 1.1850349079976668\n",
      "Epoch: 98; total_step: 17950, loss: 1.6947002041918529, nll: 1.1558111838150646\n",
      "Epoch: 98; total_step: 18000, loss: 1.6133049692779715, nll: 1.1646145432781965\n",
      "Epoch: 98; total_step: 18050, loss: 1.6341240740560619, nll: 1.071046503067386\n",
      "Epoch: 98; total_step: 18100, loss: 1.6890357749712417, nll: 1.2153271305640758\n",
      "Epoch: 99; total_step: 18150, loss: 1.7518398972775282, nll: 1.2916345673668763\n",
      "Epoch: 99; total_step: 18200, loss: 1.7187395133618204, nll: 1.232240300243621\n",
      "Epoch: 99; total_step: 18250, loss: 1.6436945248139387, nll: 1.1727600901761093\n",
      "Done! loss: 1.6679460702991418\n",
      "\n",
      "Done Training!\n",
      "Done Testing!\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "print(\"\\n\\n---DirectionalGradVGP---\")\n",
    "print(f\"Start training with {n} trainig data of dim {dim}\")\n",
    "print(f\"VI setups: {num_inducing} inducing points, {num_directions} inducing directions\")\n",
    "args={\"verbose\":True}\n",
    "t1 = time.time()\t\n",
    "model,likelihood = train_gp(train_dataset,\n",
    "                      num_inducing=num_inducing,\n",
    "                      num_directions=num_directions,\n",
    "                      minibatch_size = minibatch_size,\n",
    "                      minibatch_dim = num_directions,\n",
    "                      num_epochs =num_epochs, \n",
    "                      learning_rate_hypers=learning_rate_hypers,\n",
    "                      learning_rate_ngd=learning_rate_ngd,\n",
    "                      inducing_data_initialization=inducing_data_initialization,\n",
    "                      use_ngd = use_ngd,\n",
    "                      use_ciq = use_ciq,\n",
    "                      lr_sched=lr_sched,\n",
    "                      num_contour_quadrature=num_contour_quadrature,\n",
    "                      tqdm=tqdm,**args\n",
    "                      )\n",
    "t2 = time.time()\t\n",
    "\n",
    "# save the model\n",
    "# torch.save(model.state_dict(), \"../data/test_dvi_basic.model\")\n",
    "\n",
    "# test\n",
    "means, variances = eval_gp( test_dataset,model,likelihood,\n",
    "                            num_directions=num_directions,\n",
    "                            minibatch_size=n_test,\n",
    "                            minibatch_dim=num_directions)\n",
    "t3 = time.time()\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 9146 testing points, MSE: 5.9555e-01, nll: 1.1599e+00.\n",
      "Training time: 8148.59 sec, testing time: 6.37 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# compute MSE\n",
    "#test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y[0],means)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means, variances.sqrt()).log_prob(test_y[0]).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")\n",
    "\n",
    "#plot=1\n",
    "#if plot == 1:\n",
    "#    from mpl_toolkits.mplot3d import axes3d\n",
    "#    import matplotlib.pyplot as plt\n",
    "#    fig = plt.figure(figsize=(12,6))\n",
    "#    ax = fig.add_subplot(111, projection='3d')\n",
    "#    ax.scatter(test_x[0][:,0],test_x[:,1],test_y, color='k')\n",
    "#    ax.scatter(test_x[0][:,0],test_x[:,1],means, color='b')\n",
    "#    plt.title(\"f(x,y) variational fit; actual curve is black, variational is blue\")\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "#num_inducing = 50\n",
    "#num_directions = 6\n",
    "#minibatch_size = 200\n",
    "#num_epochs = 100\n",
    "\n",
    "\n",
    "# 2 directions\n",
    "#At 104 testing points, MSE: 2.9133e+00, nll: 3.3945e+00. \n",
    "# 3 directions\n",
    "#At 104 testing points, MSE: 2.9455e+00, nll: 3.3617e+00.\n",
    "#Training time: 70.29 sec, testing time: 0.10 sec\n",
    "# 4 directions\n",
    "#At 104 testing points, MSE: 2.9810e+00, nll: 3.0743e+00.\n",
    "#Training time: 57.68 sec, testing time: 0.08 sec\n",
    "# 5 directions\n",
    "#At 104 testing points, MSE: 2.9440e+00, nll: 3.6124e+00.\n",
    "#Training time: 104.46 sec, testing time: 0.12 sec\n",
    "# 6 directions\n",
    "#At 104 testing points, MSE: 2.9795e+00, nll: 3.1092e+00.\n",
    "#Training time: 127.73 sec, testing time: 0.10 sec\n",
    "# 7 directions\n",
    "#At 104 testing points, MSE: 2.9272e+00, nll: 3.6537e+00.\n",
    "#Training time: 153.38 sec, testing time: 0.12 sec\n",
    "# 8 directions\n",
    "#At 104 testing points, MSE: 2.9503e+00, nll: 3.3300e+00.\n",
    "#Training time: 173.86 sec, testing time: 0.15 sec\n",
    "# 9 directions\n",
    "# 10 directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters to learn:\n",
      "      variational_strategy.inducing_points\n",
      "      torch.Size([500, 9])\n",
      "      variational_strategy._variational_distribution.variational_mean\n",
      "      torch.Size([500])\n",
      "      variational_strategy._variational_distribution.chol_variational_covar\n",
      "      torch.Size([500, 500])\n",
      "      mean_module.constant\n",
      "      torch.Size([1])\n",
      "      covar_module.raw_outputscale\n",
      "      torch.Size([])\n",
      "      covar_module.base_kernel.raw_lengthscale\n",
      "      torch.Size([1, 1])\n",
      "      noise_covar.raw_noise\n",
      "      torch.Size([1])\n",
      "Total number of parameters:  255004.0\n",
      "Using ELBO\n",
      "Epoch: 0; total_step: 0, loss: 2.4442716960932573, nll: 1.4365865539417353\n",
      "Epoch: 0; total_step: 50, loss: 1.7168978216076511, nll: 1.2087576877397188\n",
      "Epoch: 0; total_step: 100, loss: 1.7202699924596345, nll: 1.2138562715051886\n",
      "Epoch: 0; total_step: 150, loss: 1.8007331416387604, nll: 1.292580674154088\n",
      "Epoch: 1; total_step: 200, loss: 1.7723763100538963, nll: 1.2660390302183935\n",
      "Epoch: 1; total_step: 250, loss: 1.7064899198695316, nll: 1.2004581856128238\n",
      "Epoch: 1; total_step: 300, loss: 1.6722978367986796, nll: 1.166431110062467\n",
      "Epoch: 1; total_step: 350, loss: 1.6887948429292317, nll: 1.1829571817909954\n",
      "Epoch: 2; total_step: 400, loss: 1.696926352444842, nll: 1.1908929118409355\n",
      "Epoch: 2; total_step: 450, loss: 1.6816519968578683, nll: 1.1754123417121565\n",
      "Epoch: 2; total_step: 500, loss: 1.6213316518110983, nll: 1.1157200941088332\n",
      "Epoch: 3; total_step: 550, loss: 1.7579697058335284, nll: 1.2508671938218143\n",
      "Epoch: 3; total_step: 600, loss: 1.6792748146291052, nll: 1.1729560360435394\n",
      "Epoch: 3; total_step: 650, loss: 1.7235924254728792, nll: 1.216285448461031\n",
      "Epoch: 3; total_step: 700, loss: 1.7519860558957605, nll: 1.2442788950399508\n",
      "Epoch: 4; total_step: 750, loss: 1.6785444203607656, nll: 1.1717728173799868\n",
      "Epoch: 4; total_step: 800, loss: 1.6649573298498248, nll: 1.157344356100272\n",
      "Epoch: 4; total_step: 850, loss: 1.6937052949731382, nll: 1.1859047971169676\n",
      "Epoch: 4; total_step: 900, loss: 1.6763152195897584, nll: 1.169254517444374\n",
      "Epoch: 5; total_step: 950, loss: 1.7839731112848474, nll: 1.2756891351084123\n",
      "Epoch: 5; total_step: 1000, loss: 1.690867233020724, nll: 1.1832013539845598\n",
      "Epoch: 5; total_step: 1050, loss: 1.6800449979767853, nll: 1.1718699895722466\n",
      "Epoch: 6; total_step: 1100, loss: 1.6646507555453633, nll: 1.1561587594298621\n",
      "Epoch: 6; total_step: 1150, loss: 1.6805685351837019, nll: 1.1731235925353858\n",
      "Epoch: 6; total_step: 1200, loss: 1.7465520978650693, nll: 1.2380927944813322\n",
      "Epoch: 6; total_step: 1250, loss: 1.8687599339125007, nll: 1.359068772216698\n",
      "Epoch: 7; total_step: 1300, loss: 1.7211422355671255, nll: 1.2122262037336387\n",
      "Epoch: 7; total_step: 1350, loss: 1.730008584793011, nll: 1.2217276941828665\n",
      "Epoch: 7; total_step: 1400, loss: 1.7520217494806254, nll: 1.242420987939126\n",
      "Epoch: 7; total_step: 1450, loss: 1.7269597801728298, nll: 1.2174250005614113\n",
      "Epoch: 8; total_step: 1500, loss: 1.7097955792350785, nll: 1.200215979848567\n",
      "Epoch: 8; total_step: 1550, loss: 1.741028609633523, nll: 1.2323474257955283\n",
      "Epoch: 8; total_step: 1600, loss: 1.7732432364777446, nll: 1.262760229112786\n",
      "Epoch: 9; total_step: 1650, loss: 1.7775856393454623, nll: 1.2681655256023425\n",
      "Epoch: 9; total_step: 1700, loss: 1.7600600881402084, nll: 1.2491741998521404\n",
      "Epoch: 9; total_step: 1750, loss: 1.7196539312526975, nll: 1.2097639453866957\n",
      "Epoch: 9; total_step: 1800, loss: 1.6988958490751804, nll: 1.1890648307175447\n",
      "Epoch: 10; total_step: 1850, loss: 1.6704111807201076, nll: 1.1604188354533067\n",
      "Epoch: 10; total_step: 1900, loss: 1.697624412133336, nll: 1.1882557042980972\n",
      "Epoch: 10; total_step: 1950, loss: 1.6525715757015393, nll: 1.1421243755145694\n",
      "Epoch: 10; total_step: 2000, loss: 1.7156433012557597, nll: 1.2051788973083304\n",
      "Epoch: 11; total_step: 2050, loss: 1.6593003754127287, nll: 1.1496670552672386\n",
      "Epoch: 11; total_step: 2100, loss: 1.708249221129296, nll: 1.197151232031321\n",
      "Epoch: 11; total_step: 2150, loss: 1.7006724014556374, nll: 1.190161724967238\n",
      "Epoch: 12; total_step: 2200, loss: 1.6775226249019632, nll: 1.1674886052343745\n",
      "Epoch: 12; total_step: 2250, loss: 1.7498990601994848, nll: 1.2384856050646729\n",
      "Epoch: 12; total_step: 2300, loss: 1.7214974438256951, nll: 1.2103882705553097\n",
      "Epoch: 12; total_step: 2350, loss: 1.6800382086291268, nll: 1.1700197147751452\n",
      "Epoch: 13; total_step: 2400, loss: 1.7547866515336352, nll: 1.241762059860746\n",
      "Epoch: 13; total_step: 2450, loss: 1.848704879736257, nll: 1.3353695120984164\n",
      "Epoch: 13; total_step: 2500, loss: 1.711408097284914, nll: 1.201038939614198\n",
      "Epoch: 13; total_step: 2550, loss: 1.701667365734641, nll: 1.1902315430298693\n",
      "Epoch: 14; total_step: 2600, loss: 1.6872215901015921, nll: 1.1754559020824096\n",
      "Epoch: 14; total_step: 2650, loss: 1.7584802709641325, nll: 1.2478672036196028\n",
      "Epoch: 14; total_step: 2700, loss: 1.7172081012152791, nll: 1.2038544816029464\n",
      "Epoch: 15; total_step: 2750, loss: 1.7524500668070906, nll: 1.240804260679337\n",
      "Epoch: 15; total_step: 2800, loss: 1.6685135596579586, nll: 1.1567280255377748\n",
      "Epoch: 15; total_step: 2850, loss: 1.592036086215396, nll: 1.0808456382076586\n",
      "Epoch: 15; total_step: 2900, loss: 1.685262916705199, nll: 1.1724484985187902\n",
      "Epoch: 16; total_step: 2950, loss: 1.6303999044258477, nll: 1.1199328512895037\n",
      "Epoch: 16; total_step: 3000, loss: 1.8641751058721503, nll: 1.3483215188320257\n",
      "Epoch: 16; total_step: 3050, loss: 1.730806786860428, nll: 1.2183098700906514\n",
      "Epoch: 16; total_step: 3100, loss: 1.7454345040030903, nll: 1.2330994604776313\n",
      "Epoch: 17; total_step: 3150, loss: 1.7039162122080453, nll: 1.189960112478041\n",
      "Epoch: 17; total_step: 3200, loss: 1.634846781873225, nll: 1.1241958988840879\n",
      "Epoch: 17; total_step: 3250, loss: 1.6757723882247157, nll: 1.163189282022282\n",
      "Epoch: 18; total_step: 3300, loss: 1.6787341517578298, nll: 1.166908223006847\n",
      "Epoch: 18; total_step: 3350, loss: 1.718163349115851, nll: 1.205847864524959\n",
      "Epoch: 18; total_step: 3400, loss: 1.7723222606831246, nll: 1.258844376128477\n",
      "Epoch: 18; total_step: 3450, loss: 1.696570994506218, nll: 1.1840441280534848\n",
      "Epoch: 19; total_step: 3500, loss: 1.6758564496011812, nll: 1.1628524045779949\n",
      "Epoch: 19; total_step: 3550, loss: 1.665317903553667, nll: 1.1538862219198742\n",
      "Epoch: 19; total_step: 3600, loss: 1.7428185674641474, nll: 1.2272228172806954\n",
      "Epoch: 19; total_step: 3650, loss: 1.7430132245391639, nll: 1.2300509851567596\n",
      "Epoch: 20; total_step: 3700, loss: 1.7026159257460023, nll: 1.1892304176062092\n",
      "Epoch: 20; total_step: 3750, loss: 1.6668377105549768, nll: 1.1522283919348295\n",
      "Epoch: 20; total_step: 3800, loss: 1.6559644088810144, nll: 1.143626784480128\n",
      "Epoch: 21; total_step: 3850, loss: 1.7674818880683965, nll: 1.2527925802088486\n",
      "Epoch: 21; total_step: 3900, loss: 1.6678955208724147, nll: 1.15423255363398\n",
      "Epoch: 21; total_step: 3950, loss: 1.7977148593133727, nll: 1.2836497539078615\n",
      "Epoch: 21; total_step: 4000, loss: 1.6344472429165364, nll: 1.1203623373761085\n",
      "Epoch: 22; total_step: 4050, loss: 1.72589986702668, nll: 1.2118570917095612\n",
      "Epoch: 22; total_step: 4100, loss: 1.7553835589988056, nll: 1.2384024967918068\n",
      "Epoch: 22; total_step: 4150, loss: 1.6705591275668028, nll: 1.1569714128828477\n",
      "Epoch: 22; total_step: 4200, loss: 1.7382980870808344, nll: 1.2243203012998631\n",
      "Epoch: 23; total_step: 4250, loss: 1.7358711558605333, nll: 1.2206308187721313\n",
      "Epoch: 23; total_step: 4300, loss: 1.6851347305403168, nll: 1.1723600938568033\n",
      "Epoch: 23; total_step: 4350, loss: 1.7322469949753685, nll: 1.2176193699290643\n",
      "Epoch: 24; total_step: 4400, loss: 1.7797353991541007, nll: 1.2623509917714155\n",
      "Epoch: 24; total_step: 4450, loss: 1.7005567980325786, nll: 1.1863169934940974\n",
      "Epoch: 24; total_step: 4500, loss: 1.7452383918591707, nll: 1.229471568251907\n",
      "Epoch: 24; total_step: 4550, loss: 1.6662434043865242, nll: 1.1504075392141728\n",
      "Epoch: 25; total_step: 4600, loss: 1.7269642799617628, nll: 1.212455452115825\n",
      "Epoch: 25; total_step: 4650, loss: 1.7045832325041173, nll: 1.1893400403217562\n",
      "Epoch: 25; total_step: 4700, loss: 1.7458563034640593, nll: 1.2301663171688102\n",
      "Epoch: 25; total_step: 4750, loss: 1.6786922942752915, nll: 1.1642203554388888\n",
      "Epoch: 26; total_step: 4800, loss: 1.6609282445279994, nll: 1.1443919794332889\n",
      "Epoch: 26; total_step: 4850, loss: 1.775076357690418, nll: 1.2586495822199035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26; total_step: 4900, loss: 1.7084710510936332, nll: 1.1939964991634509\n",
      "Epoch: 27; total_step: 4950, loss: 1.6579208110696018, nll: 1.1421964844336747\n",
      "Epoch: 27; total_step: 5000, loss: 1.642699350379093, nll: 1.1263757967483705\n",
      "Epoch: 27; total_step: 5050, loss: 1.7020007229416558, nll: 1.1867606771095718\n",
      "Epoch: 27; total_step: 5100, loss: 1.698396390565223, nll: 1.176132911077666\n",
      "Epoch: 28; total_step: 5150, loss: 1.6424828448703577, nll: 1.127448315729192\n",
      "Epoch: 28; total_step: 5200, loss: 1.7217072611572355, nll: 1.2061330396904466\n",
      "Epoch: 28; total_step: 5250, loss: 1.7334169749150419, nll: 1.218828464829425\n",
      "Epoch: 28; total_step: 5300, loss: 1.5877762131213442, nll: 1.0748802074089843\n",
      "Epoch: 29; total_step: 5350, loss: 1.789768189761249, nll: 1.273678032564406\n",
      "Epoch: 29; total_step: 5400, loss: 1.6807936307250038, nll: 1.1652577370640365\n",
      "Epoch: 29; total_step: 5450, loss: 1.659871177619687, nll: 1.1449087106979219\n",
      "Epoch: 30; total_step: 5500, loss: 1.6562798060202502, nll: 1.142368727041634\n",
      "Epoch: 30; total_step: 5550, loss: 1.7691476325936828, nll: 1.2499035894736208\n",
      "Epoch: 30; total_step: 5600, loss: 1.7562494779660698, nll: 1.2381757609798496\n",
      "Epoch: 30; total_step: 5650, loss: 1.6308160582905176, nll: 1.116220140660763\n",
      "Epoch: 31; total_step: 5700, loss: 1.7263646221548958, nll: 1.210434791713815\n",
      "Epoch: 31; total_step: 5750, loss: 1.695596041452668, nll: 1.181043121391526\n",
      "Epoch: 31; total_step: 5800, loss: 1.8040830349028345, nll: 1.2886988880846277\n",
      "Epoch: 31; total_step: 5850, loss: 1.650596167389422, nll: 1.1363722622083896\n",
      "Epoch: 32; total_step: 5900, loss: 1.7133510466343642, nll: 1.19718235429246\n",
      "Epoch: 32; total_step: 5950, loss: 1.7286664996667895, nll: 1.2090719882217549\n",
      "Epoch: 32; total_step: 6000, loss: 1.6880961077242298, nll: 1.1720964997347072\n",
      "Epoch: 33; total_step: 6050, loss: 1.7678288445366954, nll: 1.2524896884005767\n",
      "Epoch: 33; total_step: 6100, loss: 1.6768504714543822, nll: 1.1580831737900055\n",
      "Epoch: 33; total_step: 6150, loss: 1.7119080011681773, nll: 1.1957843687854532\n",
      "Epoch: 33; total_step: 6200, loss: 1.7070135878032269, nll: 1.1918731739299906\n",
      "Epoch: 34; total_step: 6250, loss: 1.660817531347027, nll: 1.146714393924207\n",
      "Epoch: 34; total_step: 6300, loss: 1.6476583094503963, nll: 1.1326340165822886\n",
      "Epoch: 34; total_step: 6350, loss: 1.7418169223951327, nll: 1.2242608906335115\n",
      "Epoch: 34; total_step: 6400, loss: 1.6831329829227435, nll: 1.1670627145337995\n",
      "Epoch: 35; total_step: 6450, loss: 1.7322623093193021, nll: 1.2152943504405942\n",
      "Epoch: 35; total_step: 6500, loss: 1.738483894736591, nll: 1.2221990368858062\n",
      "Epoch: 35; total_step: 6550, loss: 1.6612917029124157, nll: 1.1438729263337855\n",
      "Epoch: 36; total_step: 6600, loss: 1.65947898263875, nll: 1.1423031489521067\n",
      "Epoch: 36; total_step: 6650, loss: 1.7242787846849241, nll: 1.208214796472987\n",
      "Epoch: 36; total_step: 6700, loss: 1.6867115001882609, nll: 1.1694556413899448\n",
      "Epoch: 36; total_step: 6750, loss: 1.7100472724715194, nll: 1.192924381716251\n",
      "Epoch: 37; total_step: 6800, loss: 1.6637388893108502, nll: 1.1483329319222326\n",
      "Epoch: 37; total_step: 6850, loss: 1.6323736825694033, nll: 1.1175197996856696\n",
      "Epoch: 37; total_step: 6900, loss: 1.676174104987544, nll: 1.160621327629004\n",
      "Epoch: 37; total_step: 6950, loss: 1.70647712874862, nll: 1.191278323320923\n",
      "Epoch: 38; total_step: 7000, loss: 1.682765748588846, nll: 1.1665809065276982\n",
      "Epoch: 38; total_step: 7050, loss: 1.7555189396508093, nll: 1.2386008904330403\n",
      "Epoch: 38; total_step: 7100, loss: 1.6736464709676762, nll: 1.1569050265431842\n",
      "Epoch: 39; total_step: 7150, loss: 1.7707776698214956, nll: 1.2536855567233278\n",
      "Epoch: 39; total_step: 7200, loss: 1.8029303561161252, nll: 1.285345067645714\n",
      "Epoch: 39; total_step: 7250, loss: 1.6601958723584027, nll: 1.1449874309914565\n",
      "Epoch: 39; total_step: 7300, loss: 1.752931366580047, nll: 1.233692697884277\n",
      "Epoch: 40; total_step: 7350, loss: 1.682136015885274, nll: 1.163714727454076\n",
      "Epoch: 40; total_step: 7400, loss: 1.7673628516180275, nll: 1.2497465792045714\n",
      "Epoch: 40; total_step: 7450, loss: 1.732772365993506, nll: 1.215543566575004\n",
      "Epoch: 40; total_step: 7500, loss: 1.6875768281031267, nll: 1.1720774298594376\n",
      "Epoch: 41; total_step: 7550, loss: 1.694226822459468, nll: 1.17839816321278\n",
      "Epoch: 41; total_step: 7600, loss: 1.6378068252802434, nll: 1.1217869827038027\n",
      "Epoch: 41; total_step: 7650, loss: 1.6750955876616758, nll: 1.1592702690431245\n",
      "Epoch: 42; total_step: 7700, loss: 1.6928821531193086, nll: 1.1774686015642846\n",
      "Epoch: 42; total_step: 7750, loss: 1.6526982002551631, nll: 1.1363080411303064\n",
      "Epoch: 42; total_step: 7800, loss: 1.697736271145073, nll: 1.1770383454916895\n",
      "Epoch: 42; total_step: 7850, loss: 1.7378028487427426, nll: 1.2192493748996098\n",
      "Epoch: 43; total_step: 7900, loss: 1.6885858759469718, nll: 1.1724942571648083\n",
      "Epoch: 43; total_step: 7950, loss: 1.7697818884743686, nll: 1.2521125722555766\n",
      "Epoch: 43; total_step: 8000, loss: 1.7489159124107925, nll: 1.2290740731121126\n",
      "Epoch: 43; total_step: 8050, loss: 1.6814579493285917, nll: 1.165112704932538\n",
      "Epoch: 44; total_step: 8100, loss: 1.7033568571744864, nll: 1.1894561874078458\n",
      "Epoch: 44; total_step: 8150, loss: 1.7245374920368894, nll: 1.2069413597879268\n",
      "Epoch: 44; total_step: 8200, loss: 1.6759127333661628, nll: 1.158508610025841\n",
      "Epoch: 45; total_step: 8250, loss: 1.7443494811807363, nll: 1.2256194775782583\n",
      "Epoch: 45; total_step: 8300, loss: 1.7308898092447378, nll: 1.2113099482552587\n",
      "Epoch: 45; total_step: 8350, loss: 1.6673874054328977, nll: 1.1515044126643097\n",
      "Epoch: 45; total_step: 8400, loss: 1.7542097094622975, nll: 1.2347479518790458\n",
      "Epoch: 46; total_step: 8450, loss: 1.6001486319298752, nll: 1.0828196174524418\n",
      "Epoch: 46; total_step: 8500, loss: 1.7654837660957647, nll: 1.2458187401457106\n",
      "Epoch: 46; total_step: 8550, loss: 1.6669873348039754, nll: 1.1504636488136575\n",
      "Epoch: 46; total_step: 8600, loss: 1.6402064012971747, nll: 1.120922013691626\n",
      "Epoch: 47; total_step: 8650, loss: 1.6901626943899006, nll: 1.1736214140270755\n",
      "Epoch: 47; total_step: 8700, loss: 1.598002886374187, nll: 1.0801698050960797\n",
      "Epoch: 47; total_step: 8750, loss: 1.6417498283558842, nll: 1.1260479058214998\n",
      "Epoch: 48; total_step: 8800, loss: 1.6376501624221271, nll: 1.120077306754691\n",
      "Epoch: 48; total_step: 8850, loss: 1.657970534923487, nll: 1.1406129921253623\n",
      "Epoch: 48; total_step: 8900, loss: 1.746215815125224, nll: 1.2274426950171775\n",
      "Epoch: 48; total_step: 8950, loss: 1.6893366754083505, nll: 1.1707349710040134\n",
      "Epoch: 49; total_step: 9000, loss: 1.70983362644701, nll: 1.1931449482963856\n",
      "Epoch: 49; total_step: 9050, loss: 1.6583402289851206, nll: 1.1421572882034479\n",
      "Epoch: 49; total_step: 9100, loss: 1.6517295216268622, nll: 1.1340872888814681\n",
      "Epoch: 50; total_step: 9150, loss: 1.7040590818151775, nll: 1.186241256725892\n",
      "Epoch: 50; total_step: 9200, loss: 1.6787257368076967, nll: 1.16221315561739\n",
      "Epoch: 50; total_step: 9250, loss: 1.7550272229615291, nll: 1.2345569999507864\n",
      "Epoch: 50; total_step: 9300, loss: 1.692429834418478, nll: 1.1761144672376878\n",
      "Epoch: 51; total_step: 9350, loss: 1.7505066485785823, nll: 1.2304813939979218\n",
      "Epoch: 51; total_step: 9400, loss: 1.7129922652710659, nll: 1.1926478952331643\n",
      "Epoch: 51; total_step: 9450, loss: 1.6857007432568833, nll: 1.169311589788252\n",
      "Epoch: 51; total_step: 9500, loss: 1.6920848491492335, nll: 1.1764670362967429\n",
      "Epoch: 52; total_step: 9550, loss: 1.747974501985388, nll: 1.2259319468232555\n",
      "Epoch: 52; total_step: 9600, loss: 1.6283218319505237, nll: 1.1121917944674455\n",
      "Epoch: 52; total_step: 9650, loss: 1.6605327914440937, nll: 1.1445619026522016\n",
      "Epoch: 53; total_step: 9700, loss: 1.691948717335265, nll: 1.1727581771525124\n",
      "Epoch: 53; total_step: 9750, loss: 1.7281352420059273, nll: 1.209627410080136\n",
      "Epoch: 53; total_step: 9800, loss: 1.7057144483499607, nll: 1.1890981771451221\n",
      "Epoch: 53; total_step: 9850, loss: 1.7691914637329427, nll: 1.2509751762249866\n",
      "Epoch: 54; total_step: 9900, loss: 1.7179680532325838, nll: 1.200147291467851\n",
      "Epoch: 54; total_step: 9950, loss: 1.7275938368765373, nll: 1.2078074429325865\n",
      "Epoch: 54; total_step: 10000, loss: 1.7174914180174894, nll: 1.1997103589918099\n",
      "Epoch: 54; total_step: 10050, loss: 1.722521204723749, nll: 1.1978958299505533\n",
      "Epoch: 55; total_step: 10100, loss: 1.7559119337479632, nll: 1.2388944757714473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55; total_step: 10150, loss: 1.6620246935580198, nll: 1.1452536309040147\n",
      "Epoch: 55; total_step: 10200, loss: 1.6637382857324485, nll: 1.1460438906403974\n",
      "Epoch: 56; total_step: 10250, loss: 1.6438613689799308, nll: 1.125650629461636\n",
      "Epoch: 56; total_step: 10300, loss: 1.684403183768155, nll: 1.1669278098806792\n",
      "Epoch: 56; total_step: 10350, loss: 1.63494902458216, nll: 1.1188602060576018\n",
      "Epoch: 56; total_step: 10400, loss: 1.7109726446789342, nll: 1.1924193313613336\n",
      "Epoch: 57; total_step: 10450, loss: 1.6606755793972514, nll: 1.1426327701473746\n",
      "Epoch: 57; total_step: 10500, loss: 1.6793099510861738, nll: 1.1584034498697735\n",
      "Epoch: 57; total_step: 10550, loss: 1.64300425846966, nll: 1.1249023694782325\n",
      "Epoch: 57; total_step: 10600, loss: 1.6989660245047702, nll: 1.1811847467103447\n",
      "Epoch: 58; total_step: 10650, loss: 1.7946042352718155, nll: 1.2681708874363893\n",
      "Epoch: 58; total_step: 10700, loss: 1.7341551243724902, nll: 1.2162171247054951\n",
      "Epoch: 58; total_step: 10750, loss: 1.6520256693337807, nll: 1.134758930984998\n",
      "Epoch: 59; total_step: 10800, loss: 1.6981741188475479, nll: 1.177722736658707\n",
      "Epoch: 59; total_step: 10850, loss: 1.6690997965624532, nll: 1.152886305821308\n"
     ]
    }
   ],
   "source": [
    "model_t,likelihood_t = traditional_vi.train_gp(train_dataset,dim,\n",
    "                                                   num_inducing=num_inducing,\n",
    "                                                   minibatch_size=minibatch_size,\n",
    "                                                   num_epochs=num_epochs,\n",
    "                                                   use_ngd=use_ngd, use_ciq=use_ciq,\n",
    "                                                   learning_rate_hypers=learning_rate_hypers,\n",
    "                                                   learning_rate_ngd=learning_rate_ngd,\n",
    "                                                   lr_sched=lr_sched,\n",
    "                                                   num_contour_quadrature=num_contour_quadrature,gamma=gamma, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_t, variances_t = traditional_vi.eval_gp(test_dataset, model_t, likelihood_t, minibatch_size=n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute MSE\n",
    "#test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y[0],means_t)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means_t, variances_t.sqrt()).log_prob(test_y[0]).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
