{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import random\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../directionalvi/utils\")\n",
    "sys.path.append(\"../directionalvi\")\n",
    "import traditional_vi\n",
    "from RBFKernelDirectionalGrad import RBFKernelDirectionalGrad\n",
    "#from DirectionalGradVariationalStrategy import DirectionalGradVariationalStrategy\n",
    "from dfree_directional_vi import train_gp, eval_gp\n",
    "from metrics import MSE\n",
    "import testfun\n",
    "from csv_dataset import csv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "[48]\n"
     ]
    }
   ],
   "source": [
    "dataset = csv_dataset(\"../experiments/real_data/WECs_DataSet/Perth_Data.csv\", gradients=False, rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is:  72000\n",
      "dims is:  32\n"
     ]
    }
   ],
   "source": [
    "# data parameters\n",
    "n   = dataset.n\n",
    "print(\"n is: \", n)\n",
    "dim = dataset.dim\n",
    "print(\"dims is: \", dim)\n",
    "\n",
    "# training params\n",
    "num_inducing = 500\n",
    "num_directions = 1\n",
    "minibatch_size = 500\n",
    "num_epochs = 100\n",
    "\n",
    "# seed\n",
    "torch.random.manual_seed(0)\n",
    "# use tqdm or just have print statements\n",
    "tqdm = False\n",
    "# use data to initialize inducing stuff\n",
    "inducing_data_initialization = False\n",
    "# use natural gradients and/or CIQ\n",
    "use_ngd = False\n",
    "use_ciq = False\n",
    "num_contour_quadrature=15\n",
    "# learning rate\n",
    "learning_rate_hypers = 0.01\n",
    "learning_rate_ngd    = 0.1\n",
    "gamma  = 10.0\n",
    "#levels = np.array([20,150,300])\n",
    "#def lr_sched(epoch):\n",
    "#  a = np.sum(levels > epoch)\n",
    "#  return (1./gamma)**a\n",
    "lr_sched = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "n_train = int(0.8*dataset.n)\n",
    "n_test  = n - n_train\n",
    "train_dataset,test_dataset = torch.utils.data.random_split(dataset,[n_train,n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=n_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [item[1] for item in test_loader]\n",
    "test_x = [item[0] for item in test_loader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D-Free Grad SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---DirectionalGradVGP---\n",
      "Start training with 72000 trainig data of dim 32\n",
      "VI setups: 500 inducing points, 1 inducing directions\n",
      "All parameters to learn:\n",
      "      variational_strategy.inducing_points\n",
      "      torch.Size([500, 32])\n",
      "      variational_strategy.inducing_directions\n",
      "      torch.Size([500, 32])\n",
      "      variational_strategy._variational_distribution.variational_mean\n",
      "      torch.Size([1000])\n",
      "      variational_strategy._variational_distribution.chol_variational_covar\n",
      "      torch.Size([1000, 1000])\n",
      "      mean_module.constant\n",
      "      torch.Size([1])\n",
      "      covar_module.raw_outputscale\n",
      "      torch.Size([])\n",
      "      covar_module.base_kernel.raw_lengthscale\n",
      "      torch.Size([1, 1])\n",
      "      noise_covar.raw_noise\n",
      "      torch.Size([1])\n",
      "Total number of parameters:  1033004.0\n",
      "Epoch: 0; total_step: 0, loss: 2.458941669014896, nll: 1.4041819382616334\n",
      "Epoch: 0; total_step: 50, loss: 1.6743896982942377, nll: 1.090002514624555\n",
      "Epoch: 0; total_step: 100, loss: 1.5148116300287284, nll: 0.9731543793524597\n",
      "Epoch: 1; total_step: 150, loss: 1.3942345099994573, nll: 0.8544914875590965\n",
      "Epoch: 1; total_step: 200, loss: 1.262579369887665, nll: 0.708232630581935\n",
      "Epoch: 2; total_step: 250, loss: 1.2300144637654435, nll: 0.6328524873837763\n",
      "Epoch: 2; total_step: 300, loss: 1.1640064938421746, nll: 0.5152684957473954\n",
      "Epoch: 3; total_step: 350, loss: 1.141935289983164, nll: 0.5377655511406858\n",
      "Epoch: 3; total_step: 400, loss: 1.0705889792400602, nll: 0.5173847871179835\n",
      "Epoch: 3; total_step: 450, loss: 1.0673086741540379, nll: 0.5149839491812646\n",
      "Epoch: 4; total_step: 500, loss: 1.0678563041100488, nll: 0.4772647472617107\n",
      "Epoch: 4; total_step: 550, loss: 1.047591104392441, nll: 0.515403901902015\n",
      "Epoch: 5; total_step: 600, loss: 1.0242387055685982, nll: 0.4674079329648336\n",
      "Epoch: 5; total_step: 650, loss: 1.062594373462346, nll: 0.5147211612316911\n",
      "Epoch: 6; total_step: 700, loss: 1.0551438579562191, nll: 0.489109963709871\n",
      "Epoch: 6; total_step: 750, loss: 1.0353641583356625, nll: 0.4637556013170112\n",
      "Epoch: 6; total_step: 800, loss: 1.0238086324915736, nll: 0.4350578201389251\n",
      "Epoch: 7; total_step: 850, loss: 0.9943917360724305, nll: 0.3879039339624652\n",
      "Epoch: 7; total_step: 900, loss: 0.9892157268894459, nll: 0.45424835830271165\n",
      "Epoch: 8; total_step: 950, loss: 0.9657678198917465, nll: 0.3772762319978722\n",
      "Epoch: 8; total_step: 1000, loss: 1.0255577396004303, nll: 0.4627165956447526\n",
      "Epoch: 9; total_step: 1050, loss: 1.000515447281562, nll: 0.41935520010402944\n",
      "Epoch: 9; total_step: 1100, loss: 1.0641365008876225, nll: 0.5042955259620291\n",
      "Epoch: 9; total_step: 1150, loss: 0.9450668096104271, nll: 0.3706826100576382\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "print(\"\\n\\n---DirectionalGradVGP---\")\n",
    "print(f\"Start training with {n} trainig data of dim {dim}\")\n",
    "print(f\"VI setups: {num_inducing} inducing points, {num_directions} inducing directions\")\n",
    "args={\"verbose\":True}\n",
    "t1 = time.time()\t\n",
    "model,likelihood = train_gp(train_dataset,\n",
    "                      num_inducing=num_inducing,\n",
    "                      num_directions=num_directions,\n",
    "                      minibatch_size = minibatch_size,\n",
    "                      minibatch_dim = num_directions,\n",
    "                      num_epochs =num_epochs, \n",
    "                      learning_rate_hypers=learning_rate_hypers,\n",
    "                      learning_rate_ngd=learning_rate_ngd,\n",
    "                      inducing_data_initialization=inducing_data_initialization,\n",
    "                      use_ngd = use_ngd,\n",
    "                      use_ciq = use_ciq,\n",
    "                      lr_sched=lr_sched,\n",
    "                      num_contour_quadrature=num_contour_quadrature,\n",
    "                      tqdm=tqdm,**args\n",
    "                      )\n",
    "t2 = time.time()\t\n",
    "\n",
    "# save the model\n",
    "# torch.save(model.state_dict(), \"../data/test_dvi_basic.model\")\n",
    "\n",
    "# test\n",
    "means, variances = eval_gp( test_dataset,model,likelihood,\n",
    "                            num_directions=num_directions,\n",
    "                            minibatch_size=n_test,\n",
    "                            minibatch_dim=num_directions)\n",
    "t3 = time.time()\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute MSE\n",
    "#test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y[0],means)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means, variances.sqrt()).log_prob(test_y[0]).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")\n",
    "\n",
    "#plot=1\n",
    "#if plot == 1:\n",
    "#    from mpl_toolkits.mplot3d import axes3d\n",
    "#    import matplotlib.pyplot as plt\n",
    "#    fig = plt.figure(figsize=(12,6))\n",
    "#    ax = fig.add_subplot(111, projection='3d')\n",
    "#    ax.scatter(test_x[0][:,0],test_x[:,1],test_y, color='k')\n",
    "#    ax.scatter(test_x[0][:,0],test_x[:,1],means, color='b')\n",
    "#    plt.title(\"f(x,y) variational fit; actual curve is black, variational is blue\")\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "#num_inducing = 50\n",
    "#num_directions = 6\n",
    "#minibatch_size = 200\n",
    "#num_epochs = 100\n",
    "\n",
    "\n",
    "# 2 directions\n",
    "#At 104 testing points, MSE: 2.9133e+00, nll: 3.3945e+00. \n",
    "# 3 directions\n",
    "#At 104 testing points, MSE: 2.9455e+00, nll: 3.3617e+00.\n",
    "#Training time: 70.29 sec, testing time: 0.10 sec\n",
    "# 4 directions\n",
    "#At 104 testing points, MSE: 2.9810e+00, nll: 3.0743e+00.\n",
    "#Training time: 57.68 sec, testing time: 0.08 sec\n",
    "# 5 directions\n",
    "#At 104 testing points, MSE: 2.9440e+00, nll: 3.6124e+00.\n",
    "#Training time: 104.46 sec, testing time: 0.12 sec\n",
    "# 6 directions\n",
    "#At 104 testing points, MSE: 2.9795e+00, nll: 3.1092e+00.\n",
    "#Training time: 127.73 sec, testing time: 0.10 sec\n",
    "# 7 directions\n",
    "#At 104 testing points, MSE: 2.9272e+00, nll: 3.6537e+00.\n",
    "#Training time: 153.38 sec, testing time: 0.12 sec\n",
    "# 8 directions\n",
    "#At 104 testing points, MSE: 2.9503e+00, nll: 3.3300e+00.\n",
    "#Training time: 173.86 sec, testing time: 0.15 sec\n",
    "# 9 directions\n",
    "# 10 directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_t,likelihood_t = traditional_vi.train_gp(train_dataset,dim,\n",
    "                                                   num_inducing=num_inducing,\n",
    "                                                   minibatch_size=minibatch_size,\n",
    "                                                   num_epochs=num_epochs,\n",
    "                                                   use_ngd=use_ngd, use_ciq=use_ciq,\n",
    "                                                   learning_rate_hypers=learning_rate_hypers,\n",
    "                                                   learning_rate_ngd=learning_rate_ngd,\n",
    "                                                   lr_sched=lr_sched,\n",
    "                                                   num_contour_quadrature=num_contour_quadrature,gamma=gamma, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_t, variances_t = traditional_vi.eval_gp(test_dataset, model_t, likelihood_t, minibatch_size=n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute MSE\n",
    "#test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y[0],means_t)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means_t, variances_t.sqrt()).log_prob(test_y[0]).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein\n",
    "# dfree and svgp\n",
    "# At 9146 testing points, MSE: 5.9555e-01, nll: 1.1599e+00.\n",
    "# At 9146 testing points, MSE: 6.2736e-01, nll: 1.1856e+00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forest fire\n",
    "\n",
    "# At 104 testing points, MSE: 3.0218e+00, nll: 4.2752e+00.\n",
    "#Training time: 837.60 sec, testing time: 0.31 sec\n",
    "\n",
    "#At 104 testing points, MSE: 2.8974e+00, nll: 3.5117e+00.\n",
    "#Training time: 837.60 sec, testing time: 0.31 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
