{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import random\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../directionalvi/utils\")\n",
    "sys.path.append(\"../directionalvi\")\n",
    "import traditional_vi\n",
    "from RBFKernelDirectionalGrad import RBFKernelDirectionalGrad\n",
    "#from DirectionalGradVariationalStrategy import DirectionalGradVariationalStrategy\n",
    "from dfree_directional_vi import train_gp, eval_gp\n",
    "from metrics import MSE\n",
    "import testfun\n",
    "from csv_dataset import csv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8]\n",
      "[9]\n"
     ]
    }
   ],
   "source": [
    "dataset = csv_dataset(\"../experiments/real_data/CASP.csv\", gradients=False, rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is:  45730\n",
      "dims is:  9\n"
     ]
    }
   ],
   "source": [
    "# data parameters\n",
    "n   = dataset.n\n",
    "print(\"n is: \", n)\n",
    "dim = dataset.dim\n",
    "print(\"dims is: \", dim)\n",
    "\n",
    "# training params\n",
    "num_inducing = 500\n",
    "num_directions = 1\n",
    "minibatch_size = 200\n",
    "num_epochs = 100\n",
    "\n",
    "# seed\n",
    "torch.random.manual_seed(0)\n",
    "# use tqdm or just have print statements\n",
    "tqdm = False\n",
    "# use data to initialize inducing stuff\n",
    "inducing_data_initialization = False\n",
    "# use natural gradients and/or CIQ\n",
    "use_ngd = False\n",
    "use_ciq = False\n",
    "num_contour_quadrature=15\n",
    "# learning rate\n",
    "learning_rate_hypers = 0.01\n",
    "learning_rate_ngd    = 0.1\n",
    "gamma  = 10.0\n",
    "#levels = np.array([20,150,300])\n",
    "#def lr_sched(epoch):\n",
    "#  a = np.sum(levels > epoch)\n",
    "#  return (1./gamma)**a\n",
    "lr_sched = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "n_train = int(0.8*dataset.n)\n",
    "n_test  = n - n_train\n",
    "train_dataset,test_dataset = torch.utils.data.random_split(dataset,[n_train,n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=n_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [item[1] for item in test_loader]\n",
    "test_x = [item[0] for item in test_loader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D-Free Grad SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---DirectionalGradVGP---\n",
      "Start training with 45730 trainig data of dim 9\n",
      "VI setups: 500 inducing points, 1 inducing directions\n",
      "All parameters to learn:\n",
      "      variational_strategy.inducing_points\n",
      "      torch.Size([500, 9])\n",
      "      variational_strategy.inducing_directions\n",
      "      torch.Size([500, 9])\n",
      "      variational_strategy._variational_distribution.variational_mean\n",
      "      torch.Size([1000])\n",
      "      variational_strategy._variational_distribution.chol_variational_covar\n",
      "      torch.Size([1000, 1000])\n",
      "      mean_module.constant\n",
      "      torch.Size([1])\n",
      "      covar_module.raw_outputscale\n",
      "      torch.Size([])\n",
      "      covar_module.base_kernel.raw_lengthscale\n",
      "      torch.Size([1, 1])\n",
      "      noise_covar.raw_noise\n",
      "      torch.Size([1])\n",
      "Total number of parameters:  1010004.0\n",
      "Epoch: 0; total_step: 0, loss: 2.5546049320523667, nll: 1.5186942597074\n",
      "Epoch: 0; total_step: 50, loss: 1.8084012538245064, nll: 1.2835976646088023\n",
      "Epoch: 0; total_step: 100, loss: 1.738893468901481, nll: 1.2476965661885733\n",
      "Epoch: 0; total_step: 150, loss: 1.7229705259743326, nll: 1.1685941411919398\n",
      "Epoch: 1; total_step: 200, loss: 1.7639526252879665, nll: 1.172045714867734\n",
      "Epoch: 1; total_step: 250, loss: 1.7544448063789775, nll: 1.2385488290250577\n",
      "Epoch: 1; total_step: 300, loss: 1.7560208501057053, nll: 1.2417297308147128\n",
      "Epoch: 1; total_step: 350, loss: 1.707522848004053, nll: 1.221469277888271\n",
      "Epoch: 2; total_step: 400, loss: 1.7820150924026876, nll: 1.2675812552606862\n",
      "Epoch: 2; total_step: 450, loss: 1.735081212304032, nll: 1.240882727565708\n",
      "Epoch: 2; total_step: 500, loss: 1.7172458085734332, nll: 1.2030750506967953\n",
      "Epoch: 3; total_step: 550, loss: 1.6950605171874584, nll: 1.2727180993199936\n",
      "Epoch: 3; total_step: 600, loss: 1.7345089130407718, nll: 1.2642291473039797\n",
      "Epoch: 3; total_step: 650, loss: 1.8267637751044532, nll: 1.2818098582272466\n",
      "Epoch: 3; total_step: 700, loss: 1.6498000843094747, nll: 1.1790304599144044\n",
      "Epoch: 4; total_step: 750, loss: 1.6970307672918687, nll: 1.2372683580591255\n",
      "Epoch: 4; total_step: 800, loss: 1.7035825731006926, nll: 1.1631157965764063\n",
      "Epoch: 4; total_step: 850, loss: 1.8053790944296033, nll: 1.3564815687118457\n",
      "Epoch: 4; total_step: 900, loss: 1.6331643598155952, nll: 1.0986267709165496\n",
      "Epoch: 5; total_step: 950, loss: 1.7362359251376358, nll: 1.207122977292744\n",
      "Epoch: 5; total_step: 1000, loss: 1.7484257020074208, nll: 1.1807473275718672\n",
      "Epoch: 5; total_step: 1050, loss: 1.6832164847166116, nll: 1.1736528247369515\n",
      "Epoch: 6; total_step: 1100, loss: 1.7479523868887412, nll: 1.178971626438095\n",
      "Epoch: 6; total_step: 1150, loss: 1.7365139782198216, nll: 1.1825201377825052\n",
      "Epoch: 6; total_step: 1200, loss: 1.769334138313285, nll: 1.2106465111164586\n",
      "Epoch: 6; total_step: 1250, loss: 1.6773049436157073, nll: 1.194302967773446\n",
      "Epoch: 7; total_step: 1300, loss: 1.6664089462462417, nll: 1.0805534688174723\n",
      "Epoch: 7; total_step: 1350, loss: 1.8053711943525284, nll: 1.306673997139817\n",
      "Epoch: 7; total_step: 1400, loss: 1.6899571522021148, nll: 1.2249929354419644\n",
      "Epoch: 7; total_step: 1450, loss: 1.6674305350754752, nll: 1.2495144396070084\n",
      "Epoch: 8; total_step: 1500, loss: 1.6961619589259629, nll: 1.1488156127164393\n",
      "Epoch: 8; total_step: 1550, loss: 1.7014557773600374, nll: 1.0651553282524433\n",
      "Epoch: 8; total_step: 1600, loss: 1.6307394223308225, nll: 1.1326510162399035\n",
      "Epoch: 9; total_step: 1650, loss: 1.7021026502422734, nll: 1.1212699636070511\n",
      "Epoch: 9; total_step: 1700, loss: 1.7424908290924654, nll: 1.2123931640627925\n",
      "Epoch: 9; total_step: 1750, loss: 1.6377529021017148, nll: 1.1462198487564494\n",
      "Epoch: 9; total_step: 1800, loss: 1.6757698258891978, nll: 1.2091223856618796\n",
      "Epoch: 10; total_step: 1850, loss: 1.6223359370358017, nll: 1.0644750304735298\n",
      "Epoch: 10; total_step: 1900, loss: 1.7192942995379792, nll: 1.1587259044280598\n",
      "Epoch: 10; total_step: 1950, loss: 1.8381532019992226, nll: 1.3713796418937216\n",
      "Epoch: 10; total_step: 2000, loss: 1.6670566241571614, nll: 1.1468529661872535\n",
      "Epoch: 11; total_step: 2050, loss: 1.6569559965545995, nll: 1.1153987546214355\n",
      "Epoch: 11; total_step: 2100, loss: 1.6290196197354752, nll: 1.0735809929366713\n",
      "Epoch: 11; total_step: 2150, loss: 1.7959058229776985, nll: 1.322203285684833\n",
      "Epoch: 12; total_step: 2200, loss: 1.6566273844474448, nll: 1.1735915965166228\n",
      "Epoch: 12; total_step: 2250, loss: 1.7691922831379656, nll: 1.2836745788471842\n",
      "Epoch: 12; total_step: 2300, loss: 1.6359816345991778, nll: 1.1012536738087986\n",
      "Epoch: 12; total_step: 2350, loss: 1.6218639277007418, nll: 1.1433655153185998\n",
      "Epoch: 13; total_step: 2400, loss: 1.7101996929679157, nll: 1.1740140457883086\n",
      "Epoch: 13; total_step: 2450, loss: 1.6898553813921773, nll: 1.2396882034649799\n",
      "Epoch: 13; total_step: 2500, loss: 1.6499805710717288, nll: 1.2467128073730709\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "print(\"\\n\\n---DirectionalGradVGP---\")\n",
    "print(f\"Start training with {n} trainig data of dim {dim}\")\n",
    "print(f\"VI setups: {num_inducing} inducing points, {num_directions} inducing directions\")\n",
    "args={\"verbose\":True}\n",
    "t1 = time.time()\t\n",
    "model,likelihood = train_gp(train_dataset,\n",
    "                      num_inducing=num_inducing,\n",
    "                      num_directions=num_directions,\n",
    "                      minibatch_size = minibatch_size,\n",
    "                      minibatch_dim = num_directions,\n",
    "                      num_epochs =num_epochs, \n",
    "                      learning_rate_hypers=learning_rate_hypers,\n",
    "                      learning_rate_ngd=learning_rate_ngd,\n",
    "                      inducing_data_initialization=inducing_data_initialization,\n",
    "                      use_ngd = use_ngd,\n",
    "                      use_ciq = use_ciq,\n",
    "                      lr_sched=lr_sched,\n",
    "                      num_contour_quadrature=num_contour_quadrature,\n",
    "                      tqdm=tqdm,**args\n",
    "                      )\n",
    "t2 = time.time()\t\n",
    "\n",
    "# save the model\n",
    "# torch.save(model.state_dict(), \"../data/test_dvi_basic.model\")\n",
    "\n",
    "# test\n",
    "means, variances = eval_gp( test_dataset,model,likelihood,\n",
    "                            num_directions=num_directions,\n",
    "                            minibatch_size=n_test,\n",
    "                            minibatch_dim=num_directions)\n",
    "t3 = time.time()\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute MSE\n",
    "#test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y[0],means)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means, variances.sqrt()).log_prob(test_y[0]).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")\n",
    "\n",
    "#plot=1\n",
    "#if plot == 1:\n",
    "#    from mpl_toolkits.mplot3d import axes3d\n",
    "#    import matplotlib.pyplot as plt\n",
    "#    fig = plt.figure(figsize=(12,6))\n",
    "#    ax = fig.add_subplot(111, projection='3d')\n",
    "#    ax.scatter(test_x[0][:,0],test_x[:,1],test_y, color='k')\n",
    "#    ax.scatter(test_x[0][:,0],test_x[:,1],means, color='b')\n",
    "#    plt.title(\"f(x,y) variational fit; actual curve is black, variational is blue\")\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "#num_inducing = 50\n",
    "#num_directions = 6\n",
    "#minibatch_size = 200\n",
    "#num_epochs = 100\n",
    "\n",
    "\n",
    "# 2 directions\n",
    "#At 104 testing points, MSE: 2.9133e+00, nll: 3.3945e+00. \n",
    "# 3 directions\n",
    "#At 104 testing points, MSE: 2.9455e+00, nll: 3.3617e+00.\n",
    "#Training time: 70.29 sec, testing time: 0.10 sec\n",
    "# 4 directions\n",
    "#At 104 testing points, MSE: 2.9810e+00, nll: 3.0743e+00.\n",
    "#Training time: 57.68 sec, testing time: 0.08 sec\n",
    "# 5 directions\n",
    "#At 104 testing points, MSE: 2.9440e+00, nll: 3.6124e+00.\n",
    "#Training time: 104.46 sec, testing time: 0.12 sec\n",
    "# 6 directions\n",
    "#At 104 testing points, MSE: 2.9795e+00, nll: 3.1092e+00.\n",
    "#Training time: 127.73 sec, testing time: 0.10 sec\n",
    "# 7 directions\n",
    "#At 104 testing points, MSE: 2.9272e+00, nll: 3.6537e+00.\n",
    "#Training time: 153.38 sec, testing time: 0.12 sec\n",
    "# 8 directions\n",
    "#At 104 testing points, MSE: 2.9503e+00, nll: 3.3300e+00.\n",
    "#Training time: 173.86 sec, testing time: 0.15 sec\n",
    "# 9 directions\n",
    "# 10 directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t,likelihood_t = traditional_vi.train_gp(train_dataset,dim,\n",
    "                                                   num_inducing=num_inducing,\n",
    "                                                   minibatch_size=minibatch_size,\n",
    "                                                   num_epochs=num_epochs,\n",
    "                                                   use_ngd=use_ngd, use_ciq=use_ciq,\n",
    "                                                   learning_rate_hypers=learning_rate_hypers,\n",
    "                                                   learning_rate_ngd=learning_rate_ngd,\n",
    "                                                   lr_sched=lr_sched,\n",
    "                                                   num_contour_quadrature=num_contour_quadrature,gamma=gamma, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_t, variances_t = traditional_vi.eval_gp(test_dataset, model_t, likelihood_t, minibatch_size=n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute MSE\n",
    "#test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y[0],means_t)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means_t, variances_t.sqrt()).log_prob(test_y[0]).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
