{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import random\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../directionalvi/utils\")\n",
    "sys.path.append(\"../directionalvi\")\n",
    "import traditional_vi\n",
    "from RBFKernelDirectionalGrad import RBFKernelDirectionalGrad\n",
    "#from DirectionalGradVariationalStrategy import DirectionalGradVariationalStrategy\n",
    "from dfree_directional_vi import train_gp, eval_gp\n",
    "from metrics import MSE\n",
    "import testfun\n",
    "from csv_dataset import csv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "[48]\n"
     ]
    }
   ],
   "source": [
    "dataset = csv_dataset(\"../experiments/real_data/WECs_DataSet/Adelaide_Data.csv\", gradients=False, rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71999"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is:  71999\n",
      "dims is:  32\n"
     ]
    }
   ],
   "source": [
    "# data parameters\n",
    "n   = dataset.n\n",
    "print(\"n is: \", n)\n",
    "dim = dataset.dim\n",
    "print(\"dims is: \", dim)\n",
    "\n",
    "# training params\n",
    "num_inducing = 500\n",
    "num_directions = 1\n",
    "minibatch_size = 500\n",
    "num_epochs = 100\n",
    "\n",
    "# seed\n",
    "torch.random.manual_seed(0)\n",
    "# use tqdm or just have print statements\n",
    "tqdm = False\n",
    "# use data to initialize inducing stuff\n",
    "inducing_data_initialization = False\n",
    "# use natural gradients and/or CIQ\n",
    "use_ngd = False\n",
    "use_ciq = False\n",
    "num_contour_quadrature=15\n",
    "# learning rate\n",
    "learning_rate_hypers = 0.01\n",
    "learning_rate_ngd    = 0.1\n",
    "gamma  = 10.0\n",
    "#levels = np.array([20,150,300])\n",
    "#def lr_sched(epoch):\n",
    "#  a = np.sum(levels > epoch)\n",
    "#  return (1./gamma)**a\n",
    "lr_sched = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "n_train = int(0.8*dataset.n)\n",
    "n_test  = n - n_train\n",
    "train_dataset,test_dataset = torch.utils.data.random_split(dataset,[n_train,n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=n_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [item[1] for item in test_loader]\n",
    "test_x = [item[0] for item in test_loader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D-Free Grad SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---DirectionalGradVGP---\n",
      "Start training with 71999 trainig data of dim 32\n",
      "VI setups: 500 inducing points, 1 inducing directions\n",
      "All parameters to learn:\n",
      "      variational_strategy.inducing_points\n",
      "      torch.Size([500, 32])\n",
      "      variational_strategy.inducing_directions\n",
      "      torch.Size([500, 32])\n",
      "      variational_strategy._variational_distribution.variational_mean\n",
      "      torch.Size([1000])\n",
      "      variational_strategy._variational_distribution.chol_variational_covar\n",
      "      torch.Size([1000, 1000])\n",
      "      mean_module.constant\n",
      "      torch.Size([1])\n",
      "      covar_module.raw_outputscale\n",
      "      torch.Size([])\n",
      "      covar_module.base_kernel.raw_lengthscale\n",
      "      torch.Size([1, 1])\n",
      "      noise_covar.raw_noise\n",
      "      torch.Size([1])\n",
      "Total number of parameters:  1033004.0\n",
      "Epoch: 0; total_step: 0, loss: 2.447085651562016, nll: 1.4299344319627434\n",
      "Epoch: 0; total_step: 50, loss: 1.665164807180518, nll: 1.092660237192947\n",
      "Epoch: 0; total_step: 100, loss: 1.4598424966029546, nll: 0.9278071120597614\n",
      "Epoch: 1; total_step: 150, loss: 1.3167675657150535, nll: 0.7555221803937484\n",
      "Epoch: 1; total_step: 200, loss: 1.1968963159865285, nll: 0.6279000578418634\n",
      "Epoch: 2; total_step: 250, loss: 1.166558440998062, nll: 0.5934357296704557\n",
      "Epoch: 2; total_step: 300, loss: 1.0900995405963987, nll: 0.5024714851282016\n",
      "Epoch: 3; total_step: 350, loss: 1.0407862750048988, nll: 0.46325369160525626\n",
      "Epoch: 3; total_step: 400, loss: 1.056797313957647, nll: 0.454439829513011\n",
      "Epoch: 3; total_step: 450, loss: 0.9930937456070412, nll: 0.4037171176915401\n",
      "Epoch: 4; total_step: 500, loss: 0.9943714394073992, nll: 0.39515217320240525\n",
      "Epoch: 4; total_step: 550, loss: 1.022377080267275, nll: 0.4540653138878692\n",
      "Epoch: 5; total_step: 600, loss: 0.9310137571367649, nll: 0.37431746406817906\n",
      "Epoch: 5; total_step: 650, loss: 0.9732891479837832, nll: 0.41526871434226903\n",
      "Epoch: 6; total_step: 700, loss: 0.9418103011700698, nll: 0.34255937623487864\n",
      "Epoch: 6; total_step: 750, loss: 0.9795041236712884, nll: 0.37742495123077435\n",
      "Epoch: 6; total_step: 800, loss: 0.9260453122816481, nll: 0.33768510009126895\n",
      "Epoch: 7; total_step: 850, loss: 0.9058288199325328, nll: 0.363595189928192\n",
      "Epoch: 7; total_step: 900, loss: 0.9087106593021419, nll: 0.263385108356072\n",
      "Epoch: 8; total_step: 950, loss: 0.9880348380105186, nll: 0.4035038465211678\n",
      "Epoch: 8; total_step: 1000, loss: 0.8939883363795847, nll: 0.3403509782719065\n",
      "Epoch: 9; total_step: 1050, loss: 0.8641606250346082, nll: 0.3001988041784706\n",
      "Epoch: 9; total_step: 1100, loss: 0.8915053752462823, nll: 0.34930914863887996\n",
      "Epoch: 9; total_step: 1150, loss: 0.885355719392498, nll: 0.26388397759587373\n",
      "Epoch: 10; total_step: 1200, loss: 0.888015246769176, nll: 0.3309534079705022\n",
      "Epoch: 10; total_step: 1250, loss: 0.9052138420733418, nll: 0.31435759846433375\n",
      "Epoch: 11; total_step: 1300, loss: 0.8922746106128768, nll: 0.32479199505506334\n",
      "Epoch: 11; total_step: 1350, loss: 0.8696004751757056, nll: 0.2699641193146565\n",
      "Epoch: 12; total_step: 1400, loss: 0.8987264092361101, nll: 0.27518826640102156\n",
      "Epoch: 12; total_step: 1450, loss: 0.8898738262948881, nll: 0.2935591319618528\n",
      "Epoch: 12; total_step: 1500, loss: 0.8654586348134725, nll: 0.3357887656366805\n",
      "Epoch: 13; total_step: 1550, loss: 0.842773299413862, nll: 0.2726299313338592\n",
      "Epoch: 13; total_step: 1600, loss: 0.8499688056249494, nll: 0.24373241553064487\n",
      "Epoch: 14; total_step: 1650, loss: 0.8561227925415992, nll: 0.2995391413358995\n",
      "Epoch: 14; total_step: 1700, loss: 0.816644534347155, nll: 0.24352129674002346\n",
      "Epoch: 15; total_step: 1750, loss: 0.7839868273975222, nll: 0.18392857244744384\n",
      "Epoch: 15; total_step: 1800, loss: 0.8774049032895445, nll: 0.27560772795261196\n",
      "Epoch: 15; total_step: 1850, loss: 0.7934701643486164, nll: 0.18050316522102974\n",
      "Epoch: 16; total_step: 1900, loss: 0.8534015447075504, nll: 0.28085940186842495\n",
      "Epoch: 16; total_step: 1950, loss: 0.8337746534093313, nll: 0.2599903245499178\n",
      "Epoch: 17; total_step: 2000, loss: 0.9151634033456806, nll: 0.341264484265408\n",
      "Epoch: 17; total_step: 2050, loss: 0.8136068355481751, nll: 0.2676178675988351\n",
      "Epoch: 18; total_step: 2100, loss: 0.7906172542277721, nll: 0.2236816468948873\n",
      "Epoch: 18; total_step: 2150, loss: 0.8328359334624413, nll: 0.2809043345118304\n",
      "Epoch: 18; total_step: 2200, loss: 0.8084500406103191, nll: 0.20682346061768603\n",
      "Epoch: 19; total_step: 2250, loss: 0.8476579955972022, nll: 0.23058120680135777\n",
      "Epoch: 19; total_step: 2300, loss: 0.8168364161743585, nll: 0.2495473700485771\n",
      "Epoch: 20; total_step: 2350, loss: 0.7930878014255364, nll: 0.24823776836044356\n",
      "Epoch: 20; total_step: 2400, loss: 0.8567160826427297, nll: 0.24426650062508629\n",
      "Epoch: 21; total_step: 2450, loss: 0.7995529258860709, nll: 0.20022850797664882\n",
      "Epoch: 21; total_step: 2500, loss: 0.785904691583346, nll: 0.20272459809762666\n",
      "Epoch: 21; total_step: 2550, loss: 0.7771555798215027, nll: 0.18271554407157373\n",
      "Epoch: 22; total_step: 2600, loss: 0.7893147273543943, nll: 0.21749500625900525\n",
      "Epoch: 22; total_step: 2650, loss: 0.8399645849305316, nll: 0.24566818536183824\n",
      "Epoch: 23; total_step: 2700, loss: 0.7892145037968757, nll: 0.24594305560579235\n",
      "Epoch: 23; total_step: 2750, loss: 0.8037330508098521, nll: 0.21024544816329316\n",
      "Epoch: 24; total_step: 2800, loss: 0.8367264996228573, nll: 0.1277409578269258\n",
      "Epoch: 24; total_step: 2850, loss: 0.7990442301785095, nll: 0.22889606482484764\n",
      "Epoch: 25; total_step: 2900, loss: 0.8154531193028172, nll: 0.25012224522518905\n",
      "Epoch: 25; total_step: 2950, loss: 0.8243214905349369, nll: 0.2159956415048813\n",
      "Epoch: 25; total_step: 3000, loss: 0.8018930327222601, nll: 0.2142443642605004\n",
      "Epoch: 26; total_step: 3050, loss: 0.7027330346590713, nll: 0.15827940335113463\n",
      "Epoch: 26; total_step: 3100, loss: 0.8618369160917264, nll: 0.28642775241027496\n",
      "Epoch: 27; total_step: 3150, loss: 0.7554353074281248, nll: 0.17919572504556816\n",
      "Epoch: 27; total_step: 3200, loss: 0.8124348039237055, nll: 0.285986825505292\n",
      "Epoch: 28; total_step: 3250, loss: 0.8279211991394395, nll: 0.20857978328839147\n",
      "Epoch: 28; total_step: 3300, loss: 0.7689762419672687, nll: 0.20924230886199394\n",
      "Epoch: 28; total_step: 3350, loss: 0.7345625715848584, nll: 0.17227501824172098\n",
      "Epoch: 29; total_step: 3400, loss: 0.7692779124792679, nll: 0.21032735102931469\n",
      "Epoch: 29; total_step: 3450, loss: 0.8070611691479042, nll: 0.2554308355719088\n",
      "Epoch: 30; total_step: 3500, loss: 0.776470818046922, nll: 0.21488603084997454\n",
      "Epoch: 30; total_step: 3550, loss: 0.7467947163418726, nll: 0.21121608198497518\n",
      "Epoch: 31; total_step: 3600, loss: 0.8473951571105897, nll: 0.2705108967649634\n",
      "Epoch: 31; total_step: 3650, loss: 0.7640044023953253, nll: 0.17020810414304371\n",
      "Epoch: 31; total_step: 3700, loss: 0.7809260787117821, nll: 0.19018247828165669\n",
      "Epoch: 32; total_step: 3750, loss: 0.8330040370832316, nll: 0.25288270459222295\n",
      "Epoch: 32; total_step: 3800, loss: 0.8150106624305989, nll: 0.14876160195434698\n",
      "Epoch: 33; total_step: 3850, loss: 0.7778169908577356, nll: 0.21295398546263744\n",
      "Epoch: 33; total_step: 3900, loss: 0.8076568957085543, nll: 0.24799562925432259\n",
      "Epoch: 34; total_step: 3950, loss: 0.8010065291909566, nll: 0.1757916843174267\n",
      "Epoch: 34; total_step: 4000, loss: 0.7306591382946718, nll: 0.18624059316615096\n",
      "Epoch: 34; total_step: 4050, loss: 0.7609290036968732, nll: 0.1944755569114774\n",
      "Epoch: 35; total_step: 4100, loss: 0.8080591911053768, nll: 0.22580432389813504\n",
      "Epoch: 35; total_step: 4150, loss: 0.7811329185418346, nll: 0.19967190040411026\n",
      "Epoch: 36; total_step: 4200, loss: 0.7720377080168107, nll: 0.195258099245915\n",
      "Epoch: 36; total_step: 4250, loss: 0.7370959353379646, nll: 0.10872290782487644\n",
      "Epoch: 37; total_step: 4300, loss: 0.7311037050329051, nll: 0.20340374064746272\n",
      "Epoch: 37; total_step: 4350, loss: 0.7574532183306988, nll: 0.19418927788719864\n",
      "Epoch: 37; total_step: 4400, loss: 0.815607648808149, nll: 0.246050941389925\n",
      "Epoch: 38; total_step: 4450, loss: 0.6987566710953474, nll: 0.10801673901817707\n",
      "Epoch: 38; total_step: 4500, loss: 0.7383931888668172, nll: 0.12879489628333182\n",
      "Epoch: 39; total_step: 4550, loss: 0.7888008061147449, nll: 0.2110578143508916\n",
      "Epoch: 39; total_step: 4600, loss: 0.7708230243649536, nll: 0.20697426378295083\n",
      "Epoch: 40; total_step: 4650, loss: 0.7446253226512929, nll: 0.14996384611616803\n",
      "Epoch: 40; total_step: 4700, loss: 0.7420888114985835, nll: 0.1969071774867851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40; total_step: 4750, loss: 0.7718113643685642, nll: 0.1827085693669864\n",
      "Epoch: 41; total_step: 4800, loss: 0.7412004183555241, nll: 0.20920533949989548\n",
      "Epoch: 41; total_step: 4850, loss: 0.710377068544935, nll: 0.14791816608257133\n",
      "Epoch: 42; total_step: 4900, loss: 0.725999128885452, nll: 0.12053632683493268\n",
      "Epoch: 42; total_step: 4950, loss: 0.745344284064476, nll: 0.17746799877755348\n",
      "Epoch: 43; total_step: 5000, loss: 0.7382342326666669, nll: 0.19454226527399987\n",
      "Epoch: 43; total_step: 5050, loss: 0.7599104263214327, nll: 0.17698582769802335\n",
      "Epoch: 43; total_step: 5100, loss: 0.8183011556887363, nll: 0.24311971122740905\n",
      "Epoch: 44; total_step: 5150, loss: 0.7390665783390111, nll: 0.17470662044583718\n",
      "Epoch: 44; total_step: 5200, loss: 0.8321060805859929, nll: 0.21708296747803582\n",
      "Epoch: 45; total_step: 5250, loss: 0.7783315597528027, nll: 0.17241484969133533\n",
      "Epoch: 45; total_step: 5300, loss: 0.7234777173213294, nll: 0.13644292184833984\n",
      "Epoch: 46; total_step: 5350, loss: 0.7149461069289682, nll: 0.10726298785592858\n",
      "Epoch: 46; total_step: 5400, loss: 0.7588905189913411, nll: 0.16140980147046782\n",
      "Epoch: 46; total_step: 5450, loss: 0.7586346222909252, nll: 0.21814461984773612\n",
      "Epoch: 47; total_step: 5500, loss: 0.8279992103746138, nll: 0.18832939830634002\n",
      "Epoch: 47; total_step: 5550, loss: 0.6881005498828932, nll: 0.11847330551101731\n",
      "Epoch: 48; total_step: 5600, loss: 0.7130408505275962, nll: 0.17300585936871601\n",
      "Epoch: 48; total_step: 5650, loss: 0.7500403300718718, nll: 0.17436753844004932\n",
      "Epoch: 49; total_step: 5700, loss: 0.7476491759056413, nll: 0.21422327381077486\n",
      "Epoch: 49; total_step: 5750, loss: 0.7226157892654553, nll: 0.14590511942765358\n",
      "Epoch: 50; total_step: 5800, loss: 0.724297197920349, nll: 0.10095107055037394\n",
      "Epoch: 50; total_step: 5850, loss: 0.8412082883025882, nll: 0.21561561019101183\n",
      "Epoch: 50; total_step: 5900, loss: 0.7979934842580181, nll: 0.2399102253063287\n",
      "Epoch: 51; total_step: 5950, loss: 0.7211245870841737, nll: 0.13399633877938727\n",
      "Epoch: 51; total_step: 6000, loss: 0.7996949956952717, nll: 0.23222008727955346\n",
      "Epoch: 52; total_step: 6050, loss: 0.8738506593190808, nll: 0.3104511370815334\n",
      "Epoch: 52; total_step: 6100, loss: 0.709578610496473, nll: 0.07422236007524213\n",
      "Epoch: 53; total_step: 6150, loss: 0.7253433132432587, nll: 0.14795944070409972\n",
      "Epoch: 53; total_step: 6200, loss: 0.685196745753065, nll: 0.13310810712906038\n",
      "Epoch: 53; total_step: 6250, loss: 0.7121711207749231, nll: 0.15377776831019388\n",
      "Epoch: 54; total_step: 6300, loss: 0.7138770298020201, nll: 0.12499635579977207\n",
      "Epoch: 54; total_step: 6350, loss: 0.7549695631758148, nll: 0.19923847590157895\n",
      "Epoch: 55; total_step: 6400, loss: 0.7073667181412745, nll: 0.1080031942222005\n",
      "Epoch: 55; total_step: 6450, loss: 0.7496210927970465, nll: 0.17092099970883406\n",
      "Epoch: 56; total_step: 6500, loss: 0.7291231183198058, nll: 0.10792090796424908\n",
      "Epoch: 56; total_step: 6550, loss: 0.7240083687747125, nll: 0.156849129538364\n",
      "Epoch: 56; total_step: 6600, loss: 0.739585175635864, nll: 0.20443092522204398\n",
      "Epoch: 57; total_step: 6650, loss: 0.7224175667448512, nll: 0.12947621028643957\n",
      "Epoch: 57; total_step: 6700, loss: 0.7423899329084713, nll: 0.2007170601563919\n",
      "Epoch: 58; total_step: 6750, loss: 0.6908068811588196, nll: 0.1514375235840949\n",
      "Epoch: 58; total_step: 6800, loss: 0.7086824580829594, nll: 0.13269848500813536\n",
      "Epoch: 59; total_step: 6850, loss: 0.6807695683016293, nll: 0.1521180512370285\n",
      "Epoch: 59; total_step: 6900, loss: 0.7332251300545892, nll: 0.10018036994456254\n",
      "Epoch: 59; total_step: 6950, loss: 0.7069379545244203, nll: 0.16805155181040698\n",
      "Epoch: 60; total_step: 7000, loss: 0.6921463753529585, nll: 0.10533759804167454\n",
      "Epoch: 60; total_step: 7050, loss: 0.7607813370901033, nll: 0.20055618948647067\n",
      "Epoch: 61; total_step: 7100, loss: 0.6870451517880775, nll: 0.14413515111790165\n",
      "Epoch: 61; total_step: 7150, loss: 0.73567640511967, nll: 0.1881927624264033\n",
      "Epoch: 62; total_step: 7200, loss: 0.7345897821122171, nll: 0.09461504816769636\n",
      "Epoch: 62; total_step: 7250, loss: 0.7466787366742438, nll: 0.218520795825079\n",
      "Epoch: 62; total_step: 7300, loss: 0.7223978604626862, nll: 0.1907664429677913\n",
      "Epoch: 63; total_step: 7350, loss: 0.6698980359547824, nll: 0.12234538153601288\n",
      "Epoch: 63; total_step: 7400, loss: 0.6899605909599791, nll: 0.12684489373320354\n",
      "Epoch: 64; total_step: 7450, loss: 0.7215070500531039, nll: 0.15584037747236998\n",
      "Epoch: 64; total_step: 7500, loss: 0.7363938506495962, nll: 0.18770969981309496\n",
      "Epoch: 65; total_step: 7550, loss: 0.7821919479301266, nll: 0.22503876259072228\n",
      "Epoch: 65; total_step: 7600, loss: 0.7819931959503369, nll: 0.18014734434428512\n",
      "Epoch: 65; total_step: 7650, loss: 0.7997673372534242, nll: 0.15783665510140635\n",
      "Epoch: 66; total_step: 7700, loss: 0.74573785929489, nll: 0.1627387635157286\n",
      "Epoch: 66; total_step: 7750, loss: 0.760931832800309, nll: 0.15306768248219488\n",
      "Epoch: 67; total_step: 7800, loss: 0.7195533615023096, nll: 0.14451735714793396\n",
      "Epoch: 67; total_step: 7850, loss: 0.7038586541228217, nll: 0.15713194103438805\n",
      "Epoch: 68; total_step: 7900, loss: 0.7815185729083248, nll: 0.14220220248047882\n",
      "Epoch: 68; total_step: 7950, loss: 0.7440231847141472, nll: 0.19159410173262864\n",
      "Epoch: 68; total_step: 8000, loss: 0.6876842959169741, nll: 0.1207324425141565\n",
      "Epoch: 69; total_step: 8050, loss: 0.7565786995991817, nll: 0.205774294525924\n",
      "Epoch: 69; total_step: 8100, loss: 0.6665899318964464, nll: 0.16250100672546489\n",
      "Epoch: 70; total_step: 8150, loss: 0.7638366243132952, nll: 0.20092128084366162\n",
      "Epoch: 70; total_step: 8200, loss: 0.6757539076631466, nll: 0.13433735866174173\n",
      "Epoch: 71; total_step: 8250, loss: 0.7625290590932845, nll: 0.24479456107542844\n",
      "Epoch: 71; total_step: 8300, loss: 0.7209724416426454, nll: 0.18346703310841658\n",
      "Epoch: 71; total_step: 8350, loss: 0.7427156332481902, nll: 0.15834345360677315\n",
      "Epoch: 72; total_step: 8400, loss: 0.7574026494047276, nll: 0.24150848002796135\n",
      "Epoch: 72; total_step: 8450, loss: 0.7349377742463916, nll: 0.1746393635642056\n",
      "Epoch: 73; total_step: 8500, loss: 0.7116397905441096, nll: 0.13495995944064282\n",
      "Epoch: 73; total_step: 8550, loss: 0.7011326494242494, nll: 0.11749295551355249\n",
      "Epoch: 74; total_step: 8600, loss: 0.6960047513031903, nll: 0.15577653875649572\n",
      "Epoch: 74; total_step: 8650, loss: 0.7650330102915909, nll: 0.13167878278363063\n",
      "Epoch: 75; total_step: 8700, loss: 0.7397719846837447, nll: 0.2117703925613395\n",
      "Epoch: 75; total_step: 8750, loss: 0.6846158993814372, nll: 0.11823628519363058\n",
      "Epoch: 75; total_step: 8800, loss: 0.7312312970068992, nll: 0.1941215758499046\n",
      "Epoch: 76; total_step: 8850, loss: 0.7257333893377993, nll: 0.1594571456064927\n",
      "Epoch: 76; total_step: 8900, loss: 0.7182842253013876, nll: 0.12123056181208966\n",
      "Epoch: 77; total_step: 8950, loss: 0.6989857168199132, nll: 0.1276656681452462\n",
      "Epoch: 77; total_step: 9000, loss: 0.7022526039538681, nll: 0.1708139891146427\n",
      "Epoch: 78; total_step: 9050, loss: 0.773271964634678, nll: 0.1966378760909651\n",
      "Epoch: 78; total_step: 9100, loss: 0.7553393393512347, nll: 0.16155389805288997\n",
      "Epoch: 78; total_step: 9150, loss: 0.7717962612482716, nll: 0.23904764507654494\n",
      "Epoch: 79; total_step: 9200, loss: 0.6768340863466795, nll: 0.10932903604104491\n",
      "Epoch: 79; total_step: 9250, loss: 0.6797314038965737, nll: 0.1719314779815476\n",
      "Epoch: 80; total_step: 9300, loss: 0.6795623164542637, nll: 0.13772934273881768\n",
      "Epoch: 80; total_step: 9350, loss: 0.7167267962658972, nll: 0.22869437118545988\n",
      "Epoch: 81; total_step: 9400, loss: 0.7372309921035355, nll: 0.16284841573722056\n",
      "Epoch: 81; total_step: 9450, loss: 0.6971731959786764, nll: 0.08113545092139793\n",
      "Epoch: 81; total_step: 9500, loss: 0.7492699201692347, nll: 0.11752264504723055\n",
      "Epoch: 82; total_step: 9550, loss: 0.6813054401138476, nll: 0.1042260067154715\n",
      "Epoch: 82; total_step: 9600, loss: 0.7318830565619542, nll: 0.16719241675001956\n",
      "Epoch: 83; total_step: 9650, loss: 0.7020035707414475, nll: 0.14115743855905322\n",
      "Epoch: 83; total_step: 9700, loss: 0.7493590748373353, nll: 0.12883227727441837\n",
      "Epoch: 84; total_step: 9750, loss: 0.707559171983077, nll: 0.08446915853629132\n",
      "Epoch: 84; total_step: 9800, loss: 0.7183995104129476, nll: 0.13972061549246262\n",
      "Epoch: 84; total_step: 9850, loss: 0.6938132197643804, nll: 0.0953189822762165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85; total_step: 9900, loss: 0.7603975044922776, nll: 0.1725347898539301\n",
      "Epoch: 85; total_step: 9950, loss: 0.7406921914833374, nll: 0.13591764733525902\n",
      "Epoch: 86; total_step: 10000, loss: 0.7222007188963467, nll: 0.18182704334608354\n",
      "Epoch: 86; total_step: 10050, loss: 0.7023998272367388, nll: 0.1341520859722018\n",
      "Epoch: 87; total_step: 10100, loss: 0.7022649781877653, nll: 0.1350191093854381\n",
      "Epoch: 87; total_step: 10150, loss: 0.7142825846793518, nll: 0.15670719260646412\n",
      "Epoch: 87; total_step: 10200, loss: 0.7408725067098202, nll: 0.15187528192956343\n",
      "Epoch: 88; total_step: 10250, loss: 0.670246325327836, nll: 0.12234005179391386\n",
      "Epoch: 88; total_step: 10300, loss: 0.8085302295743488, nll: 0.23242287360187106\n",
      "Epoch: 89; total_step: 10350, loss: 0.678572661833214, nll: 0.1325017095485234\n",
      "Epoch: 89; total_step: 10400, loss: 0.6596862978411705, nll: 0.1387181399880714\n",
      "Epoch: 90; total_step: 10450, loss: 0.7807529013051421, nll: 0.12989073932517853\n",
      "Epoch: 90; total_step: 10500, loss: 0.7073153747644714, nll: 0.16039533315959334\n",
      "Epoch: 90; total_step: 10550, loss: 0.7559544759825754, nll: 0.2098184786017203\n",
      "Epoch: 91; total_step: 10600, loss: 0.7315476998882011, nll: 0.13689758146513847\n",
      "Epoch: 91; total_step: 10650, loss: 0.7647744395838233, nll: 0.22112848549381614\n",
      "Epoch: 92; total_step: 10700, loss: 0.6481939325892838, nll: 0.06311146359539734\n",
      "Epoch: 92; total_step: 10750, loss: 0.722312002464411, nll: 0.1729452298791974\n",
      "Epoch: 93; total_step: 10800, loss: 0.7013282809542337, nll: 0.11113811565906184\n",
      "Epoch: 93; total_step: 10850, loss: 0.7444755728405716, nll: 0.16038723530933918\n",
      "Epoch: 93; total_step: 10900, loss: 0.6809822881585659, nll: 0.13885334777793673\n",
      "Epoch: 94; total_step: 10950, loss: 0.7075399632162469, nll: 0.12895215719737324\n",
      "Epoch: 94; total_step: 11000, loss: 0.7433031883964062, nll: 0.12169514933311346\n",
      "Epoch: 95; total_step: 11050, loss: 0.6661244348092271, nll: 0.06418085613978056\n",
      "Epoch: 95; total_step: 11100, loss: 0.6860780797302595, nll: 0.09919090458468463\n",
      "Epoch: 96; total_step: 11150, loss: 0.676706193403234, nll: 0.11913082758017861\n",
      "Epoch: 96; total_step: 11200, loss: 0.7404484097901789, nll: 0.18608158371180064\n",
      "Epoch: 96; total_step: 11250, loss: 0.6875809034682732, nll: 0.10275023837528678\n",
      "Epoch: 97; total_step: 11300, loss: 0.745123546863833, nll: 0.1665534192260391\n",
      "Epoch: 97; total_step: 11350, loss: 0.695808756794155, nll: 0.10198899800843478\n",
      "Epoch: 98; total_step: 11400, loss: 0.7326998458279704, nll: 0.18286921040478876\n",
      "Epoch: 98; total_step: 11450, loss: 0.683695121777098, nll: 0.14404752353549077\n",
      "Epoch: 99; total_step: 11500, loss: 0.7254079765408686, nll: 0.16185500138973635\n",
      "Epoch: 99; total_step: 11550, loss: 0.701947855446099, nll: 0.08749977571865762\n",
      "Done! loss: 0.7056994391301253\n",
      "\n",
      "Done Training!\n",
      "Done Testing!\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "print(\"\\n\\n---DirectionalGradVGP---\")\n",
    "print(f\"Start training with {n} trainig data of dim {dim}\")\n",
    "print(f\"VI setups: {num_inducing} inducing points, {num_directions} inducing directions\")\n",
    "args={\"verbose\":True}\n",
    "t1 = time.time()\t\n",
    "model,likelihood = train_gp(train_dataset,\n",
    "                      num_inducing=num_inducing,\n",
    "                      num_directions=num_directions,\n",
    "                      minibatch_size = minibatch_size,\n",
    "                      minibatch_dim = num_directions,\n",
    "                      num_epochs =num_epochs, \n",
    "                      learning_rate_hypers=learning_rate_hypers,\n",
    "                      learning_rate_ngd=learning_rate_ngd,\n",
    "                      inducing_data_initialization=inducing_data_initialization,\n",
    "                      use_ngd = use_ngd,\n",
    "                      use_ciq = use_ciq,\n",
    "                      lr_sched=lr_sched,\n",
    "                      num_contour_quadrature=num_contour_quadrature,\n",
    "                      tqdm=tqdm,**args\n",
    "                      )\n",
    "t2 = time.time()\t\n",
    "\n",
    "# save the model\n",
    "# torch.save(model.state_dict(), \"../data/test_dvi_basic.model\")\n",
    "\n",
    "# test\n",
    "means, variances = eval_gp( test_dataset,model,likelihood,\n",
    "                            num_directions=num_directions,\n",
    "                            minibatch_size=n_test,\n",
    "                            minibatch_dim=num_directions)\n",
    "t3 = time.time()\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 14400 testing points, MSE: 8.9581e-02, nll: 2.0471e-01.\n",
      "Training time: 22806.69 sec, testing time: 20.81 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# compute MSE\n",
    "#test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y[0],means)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means, variances.sqrt()).log_prob(test_y[0]).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")\n",
    "\n",
    "#plot=1\n",
    "#if plot == 1:\n",
    "#    from mpl_toolkits.mplot3d import axes3d\n",
    "#    import matplotlib.pyplot as plt\n",
    "#    fig = plt.figure(figsize=(12,6))\n",
    "#    ax = fig.add_subplot(111, projection='3d')\n",
    "#    ax.scatter(test_x[0][:,0],test_x[:,1],test_y, color='k')\n",
    "#    ax.scatter(test_x[0][:,0],test_x[:,1],means, color='b')\n",
    "#    plt.title(\"f(x,y) variational fit; actual curve is black, variational is blue\")\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "#num_inducing = 50\n",
    "#num_directions = 6\n",
    "#minibatch_size = 200\n",
    "#num_epochs = 100\n",
    "\n",
    "\n",
    "# 2 directions\n",
    "#At 104 testing points, MSE: 2.9133e+00, nll: 3.3945e+00. \n",
    "# 3 directions\n",
    "#At 104 testing points, MSE: 2.9455e+00, nll: 3.3617e+00.\n",
    "#Training time: 70.29 sec, testing time: 0.10 sec\n",
    "# 4 directions\n",
    "#At 104 testing points, MSE: 2.9810e+00, nll: 3.0743e+00.\n",
    "#Training time: 57.68 sec, testing time: 0.08 sec\n",
    "# 5 directions\n",
    "#At 104 testing points, MSE: 2.9440e+00, nll: 3.6124e+00.\n",
    "#Training time: 104.46 sec, testing time: 0.12 sec\n",
    "# 6 directions\n",
    "#At 104 testing points, MSE: 2.9795e+00, nll: 3.1092e+00.\n",
    "#Training time: 127.73 sec, testing time: 0.10 sec\n",
    "# 7 directions\n",
    "#At 104 testing points, MSE: 2.9272e+00, nll: 3.6537e+00.\n",
    "#Training time: 153.38 sec, testing time: 0.12 sec\n",
    "# 8 directions\n",
    "#At 104 testing points, MSE: 2.9503e+00, nll: 3.3300e+00.\n",
    "#Training time: 173.86 sec, testing time: 0.15 sec\n",
    "# 9 directions\n",
    "# 10 directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters to learn:\n",
      "      variational_strategy.inducing_points\n",
      "      torch.Size([500, 32])\n",
      "      variational_strategy._variational_distribution.variational_mean\n",
      "      torch.Size([500])\n",
      "      variational_strategy._variational_distribution.chol_variational_covar\n",
      "      torch.Size([500, 500])\n",
      "      mean_module.constant\n",
      "      torch.Size([1])\n",
      "      covar_module.raw_outputscale\n",
      "      torch.Size([])\n",
      "      covar_module.base_kernel.raw_lengthscale\n",
      "      torch.Size([1, 1])\n",
      "      noise_covar.raw_noise\n",
      "      torch.Size([1])\n",
      "Total number of parameters:  266504.0\n",
      "Using ELBO\n",
      "Epoch: 0; total_step: 0, loss: 2.4303488237156334, nll: 1.429625159903971\n",
      "Epoch: 0; total_step: 50, loss: 1.7147404010280134, nll: 1.1300444980506033\n",
      "Epoch: 0; total_step: 100, loss: 1.5556107125336878, nll: 0.9989157119957579\n",
      "Epoch: 1; total_step: 150, loss: 1.4231348405147806, nll: 0.8639497738756452\n",
      "Epoch: 1; total_step: 200, loss: 1.3466182210865958, nll: 0.7648590500109362\n",
      "Epoch: 2; total_step: 250, loss: 1.2476403276082457, nll: 0.6545332402855847\n",
      "Epoch: 2; total_step: 300, loss: 1.1796783881375454, nll: 0.5780436657334558\n",
      "Epoch: 3; total_step: 350, loss: 1.1940192741177715, nll: 0.576179415197498\n",
      "Epoch: 3; total_step: 400, loss: 1.1244511475567687, nll: 0.512467392570914\n",
      "Epoch: 3; total_step: 450, loss: 1.1052726502217274, nll: 0.4898884025116496\n",
      "Epoch: 4; total_step: 500, loss: 1.067002577873361, nll: 0.4539844795610602\n",
      "Epoch: 4; total_step: 550, loss: 1.1169356557224746, nll: 0.4824936594450342\n",
      "Epoch: 5; total_step: 600, loss: 1.0951011761105698, nll: 0.45905928702139787\n",
      "Epoch: 5; total_step: 650, loss: 1.046647799568966, nll: 0.4259297427433462\n",
      "Epoch: 6; total_step: 700, loss: 1.0641704817773399, nll: 0.43619707816399866\n",
      "Epoch: 6; total_step: 750, loss: 0.9903932466165358, nll: 0.37489758791046063\n",
      "Epoch: 6; total_step: 800, loss: 1.0512223970244976, nll: 0.4125464224882022\n",
      "Epoch: 7; total_step: 850, loss: 1.0162002704245068, nll: 0.39251333505766867\n",
      "Epoch: 7; total_step: 900, loss: 0.9955108132617698, nll: 0.3711350229580368\n",
      "Epoch: 8; total_step: 950, loss: 1.0434713546039907, nll: 0.4034953123011894\n",
      "Epoch: 8; total_step: 1000, loss: 1.028796031197753, nll: 0.39336957268315\n",
      "Epoch: 9; total_step: 1050, loss: 1.0011706793536101, nll: 0.36975894371248247\n",
      "Epoch: 9; total_step: 1100, loss: 0.9815735735162853, nll: 0.35257912221624543\n",
      "Epoch: 9; total_step: 1150, loss: 1.0084923210024603, nll: 0.3645371146245417\n",
      "Epoch: 10; total_step: 1200, loss: 1.0138469608907088, nll: 0.36754397931460686\n",
      "Epoch: 10; total_step: 1250, loss: 1.0383449718424704, nll: 0.39438082243111916\n",
      "Epoch: 11; total_step: 1300, loss: 0.9888951640009657, nll: 0.3516616688416314\n",
      "Epoch: 11; total_step: 1350, loss: 0.976252203327175, nll: 0.33236008093205704\n",
      "Epoch: 12; total_step: 1400, loss: 1.0111801342799511, nll: 0.3681912159041683\n",
      "Epoch: 12; total_step: 1450, loss: 1.0257460228080975, nll: 0.36996603373314974\n",
      "Epoch: 12; total_step: 1500, loss: 0.9747930363156069, nll: 0.33535374651703814\n",
      "Epoch: 13; total_step: 1550, loss: 0.9681894934165379, nll: 0.3313094372944493\n",
      "Epoch: 13; total_step: 1600, loss: 1.0093967805688862, nll: 0.36443567953253364\n",
      "Epoch: 14; total_step: 1650, loss: 0.9389898607799986, nll: 0.30347537838372685\n",
      "Epoch: 14; total_step: 1700, loss: 0.9258796485420066, nll: 0.2881302883924592\n",
      "Epoch: 15; total_step: 1750, loss: 0.9532700864987534, nll: 0.31136624948832675\n",
      "Epoch: 15; total_step: 1800, loss: 1.0292621211904964, nll: 0.36635009269684654\n",
      "Epoch: 15; total_step: 1850, loss: 1.0020027814252632, nll: 0.34673583495682603\n",
      "Epoch: 16; total_step: 1900, loss: 0.9748588872263008, nll: 0.32442958343083617\n",
      "Epoch: 16; total_step: 1950, loss: 0.9435151827456498, nll: 0.2914165341277342\n",
      "Epoch: 17; total_step: 2000, loss: 0.9370344349972501, nll: 0.28749144321214376\n",
      "Epoch: 17; total_step: 2050, loss: 0.9279223288794927, nll: 0.2859957603259771\n",
      "Epoch: 18; total_step: 2100, loss: 0.9676594424501834, nll: 0.3173831333331615\n",
      "Epoch: 18; total_step: 2150, loss: 0.9806378789555761, nll: 0.32305152880783683\n",
      "Epoch: 18; total_step: 2200, loss: 0.9972337589347612, nll: 0.3346478538408381\n",
      "Epoch: 19; total_step: 2250, loss: 0.9437750357980128, nll: 0.29081333264787296\n",
      "Epoch: 19; total_step: 2300, loss: 0.9884831233072693, nll: 0.32182227417280584\n",
      "Epoch: 20; total_step: 2350, loss: 0.9393332861523565, nll: 0.2855689409251054\n",
      "Epoch: 20; total_step: 2400, loss: 0.9291599925080543, nll: 0.2851503650586412\n",
      "Epoch: 21; total_step: 2450, loss: 0.9605840988551522, nll: 0.30027745137572404\n",
      "Epoch: 21; total_step: 2500, loss: 0.9482546952015188, nll: 0.2955955720403101\n",
      "Epoch: 21; total_step: 2550, loss: 1.0001312397887725, nll: 0.33287344526497126\n",
      "Epoch: 22; total_step: 2600, loss: 0.9535021327435288, nll: 0.29754099212510876\n",
      "Epoch: 22; total_step: 2650, loss: 0.9497220369747216, nll: 0.2930102880204669\n",
      "Epoch: 23; total_step: 2700, loss: 0.8812584907106582, nll: 0.23858555900643644\n",
      "Epoch: 23; total_step: 2750, loss: 0.9383620757923105, nll: 0.28016646076553353\n",
      "Epoch: 24; total_step: 2800, loss: 1.0476349889310093, nll: 0.3635050717013503\n",
      "Epoch: 24; total_step: 2850, loss: 0.954194476369804, nll: 0.2882739827030713\n",
      "Epoch: 25; total_step: 2900, loss: 0.935663547975212, nll: 0.27718393463426083\n",
      "Epoch: 25; total_step: 2950, loss: 1.003911992309971, nll: 0.3275320477850548\n",
      "Epoch: 25; total_step: 3000, loss: 0.9814756344817572, nll: 0.3112150140142565\n",
      "Epoch: 26; total_step: 3050, loss: 0.9548325416021907, nll: 0.29386610455450135\n",
      "Epoch: 26; total_step: 3100, loss: 0.931430211304166, nll: 0.27591082960294844\n",
      "Epoch: 27; total_step: 3150, loss: 0.9947691666557589, nll: 0.32069937578546076\n",
      "Epoch: 27; total_step: 3200, loss: 0.9210726758093233, nll: 0.2608881344867732\n",
      "Epoch: 28; total_step: 3250, loss: 0.9736266696806628, nll: 0.30533777839528853\n",
      "Epoch: 28; total_step: 3300, loss: 0.932710790861711, nll: 0.2655682268408904\n",
      "Epoch: 28; total_step: 3350, loss: 0.9351574450462055, nll: 0.2697522013986844\n",
      "Epoch: 29; total_step: 3400, loss: 0.9038523378088742, nll: 0.2475773202967496\n",
      "Epoch: 29; total_step: 3450, loss: 0.9467615631712762, nll: 0.2759406095182797\n",
      "Epoch: 30; total_step: 3500, loss: 0.9398225079917684, nll: 0.2648836217189754\n",
      "Epoch: 30; total_step: 3550, loss: 0.9373651727889031, nll: 0.26871745177778517\n",
      "Epoch: 31; total_step: 3600, loss: 1.0141908853695853, nll: 0.334034760600245\n",
      "Epoch: 31; total_step: 3650, loss: 0.9034054549670794, nll: 0.2454200478973978\n",
      "Epoch: 31; total_step: 3700, loss: 0.9659701104340661, nll: 0.292024673443091\n",
      "Epoch: 32; total_step: 3750, loss: 0.9314526308524247, nll: 0.2679872846463849\n",
      "Epoch: 32; total_step: 3800, loss: 0.9239723153882166, nll: 0.2570347222032495\n",
      "Epoch: 33; total_step: 3850, loss: 0.9916337563509258, nll: 0.3186470038624701\n",
      "Epoch: 33; total_step: 3900, loss: 0.902957514212364, nll: 0.2414916435130316\n",
      "Epoch: 34; total_step: 3950, loss: 0.889479542368516, nll: 0.22200833048319707\n",
      "Epoch: 34; total_step: 4000, loss: 0.9683598719329095, nll: 0.29357483489035935\n",
      "Epoch: 34; total_step: 4050, loss: 0.9474658626372686, nll: 0.2711364697583602\n",
      "Epoch: 35; total_step: 4100, loss: 0.8965596396821212, nll: 0.23711029740914427\n",
      "Epoch: 35; total_step: 4150, loss: 0.9166677019059958, nll: 0.2527682194452404\n",
      "Epoch: 36; total_step: 4200, loss: 0.9183153833036531, nll: 0.24701154724252217\n",
      "Epoch: 36; total_step: 4250, loss: 0.9464349434748119, nll: 0.2755915501801144\n",
      "Epoch: 37; total_step: 4300, loss: 0.9377765394573305, nll: 0.25945025529865196\n",
      "Epoch: 37; total_step: 4350, loss: 0.9167441681292304, nll: 0.24383294648919285\n",
      "Epoch: 37; total_step: 4400, loss: 0.9870473538523836, nll: 0.301671801610545\n",
      "Epoch: 38; total_step: 4450, loss: 0.9464452855492083, nll: 0.2749555905980658\n",
      "Epoch: 38; total_step: 4500, loss: 0.9204121857943276, nll: 0.24752971203108867\n",
      "Epoch: 39; total_step: 4550, loss: 0.9090827948862571, nll: 0.2364531860131801\n",
      "Epoch: 39; total_step: 4600, loss: 0.9624403964369123, nll: 0.28429631983743403\n",
      "Epoch: 40; total_step: 4650, loss: 0.9454647247046205, nll: 0.26452458125937767\n",
      "Epoch: 40; total_step: 4700, loss: 0.9865052282292025, nll: 0.2974999241342664\n",
      "Epoch: 40; total_step: 4750, loss: 0.9275595210790344, nll: 0.2561270865314231\n",
      "Epoch: 41; total_step: 4800, loss: 0.9451592003757835, nll: 0.2717794451653202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41; total_step: 4850, loss: 0.9223424861270223, nll: 0.25638188013211727\n",
      "Epoch: 42; total_step: 4900, loss: 0.9419478549036264, nll: 0.26712374072664824\n",
      "Epoch: 42; total_step: 4950, loss: 0.9773105069237997, nll: 0.29751672819740466\n",
      "Epoch: 43; total_step: 5000, loss: 0.9798422697344326, nll: 0.29530082362359245\n",
      "Epoch: 43; total_step: 5050, loss: 0.9183639196540692, nll: 0.24068976593795036\n",
      "Epoch: 43; total_step: 5100, loss: 0.9274180324566742, nll: 0.2546063756536531\n",
      "Epoch: 44; total_step: 5150, loss: 0.9030776230154012, nll: 0.23387604366077053\n",
      "Epoch: 44; total_step: 5200, loss: 0.9369213028681934, nll: 0.26292644456533537\n",
      "Epoch: 45; total_step: 5250, loss: 0.9215193430522371, nll: 0.246968391413592\n",
      "Epoch: 45; total_step: 5300, loss: 0.8897328585829688, nll: 0.22046214612079512\n",
      "Epoch: 46; total_step: 5350, loss: 0.9771219167613898, nll: 0.2963244062538112\n",
      "Epoch: 46; total_step: 5400, loss: 0.9457091975289484, nll: 0.26742014796221136\n",
      "Epoch: 46; total_step: 5450, loss: 0.9138579318831653, nll: 0.24093045432288185\n",
      "Epoch: 47; total_step: 5500, loss: 0.9266403375175201, nll: 0.25022714879257585\n",
      "Epoch: 47; total_step: 5550, loss: 0.9349547037205903, nll: 0.2581612960817355\n",
      "Epoch: 48; total_step: 5600, loss: 0.9622846607890992, nll: 0.2776510531453262\n",
      "Epoch: 48; total_step: 5650, loss: 0.9622276094396627, nll: 0.279915709160944\n",
      "Epoch: 49; total_step: 5700, loss: 0.9623306965112536, nll: 0.28211024899712794\n",
      "Epoch: 49; total_step: 5750, loss: 0.9343796015743466, nll: 0.2572246484627299\n",
      "Epoch: 50; total_step: 5800, loss: 0.9748312135272356, nll: 0.28495040572539915\n",
      "Epoch: 50; total_step: 5850, loss: 0.9272146350393314, nll: 0.24541652698961486\n",
      "Epoch: 50; total_step: 5900, loss: 0.9602141937039426, nll: 0.27498822833012904\n",
      "Epoch: 51; total_step: 5950, loss: 0.9292947975539478, nll: 0.2546965235000792\n",
      "Epoch: 51; total_step: 6000, loss: 0.9185466805832523, nll: 0.2500356741591076\n",
      "Epoch: 52; total_step: 6050, loss: 0.9711139921314856, nll: 0.27983779399794667\n",
      "Epoch: 52; total_step: 6100, loss: 0.9106241143863524, nll: 0.2424990878652319\n",
      "Epoch: 53; total_step: 6150, loss: 0.9653309030098418, nll: 0.2877768404484776\n",
      "Epoch: 53; total_step: 6200, loss: 0.9395824108834113, nll: 0.25959380315002245\n",
      "Epoch: 53; total_step: 6250, loss: 0.9658348833225622, nll: 0.2785530669439662\n",
      "Epoch: 54; total_step: 6300, loss: 0.9604433747656965, nll: 0.27392988634010973\n",
      "Epoch: 54; total_step: 6350, loss: 0.965367512782983, nll: 0.2728564488608891\n",
      "Epoch: 55; total_step: 6400, loss: 0.9070502794029023, nll: 0.232973302776986\n",
      "Epoch: 55; total_step: 6450, loss: 0.9240619202133915, nll: 0.24758787820514805\n",
      "Epoch: 56; total_step: 6500, loss: 0.9131473986879274, nll: 0.2377447141691979\n",
      "Epoch: 56; total_step: 6550, loss: 0.9526898886687917, nll: 0.27146675046094526\n",
      "Epoch: 56; total_step: 6600, loss: 0.9127208419596042, nll: 0.23213404782133776\n",
      "Epoch: 57; total_step: 6650, loss: 0.92649410509416, nll: 0.24760437756035256\n",
      "Epoch: 57; total_step: 6700, loss: 1.010311399975936, nll: 0.31060574852432155\n",
      "Epoch: 58; total_step: 6750, loss: 0.9266307918854113, nll: 0.2509475593795122\n",
      "Epoch: 58; total_step: 6800, loss: 0.9716721045125608, nll: 0.2861852940670886\n",
      "Epoch: 59; total_step: 6850, loss: 0.9355736104258594, nll: 0.2597421104062561\n",
      "Epoch: 59; total_step: 6900, loss: 1.0031666398974102, nll: 0.3062341296264852\n",
      "Epoch: 59; total_step: 6950, loss: 0.9454804012359986, nll: 0.2592399308375506\n",
      "Epoch: 60; total_step: 7000, loss: 0.9718455000854896, nll: 0.2870135850143845\n",
      "Epoch: 60; total_step: 7050, loss: 0.9211432836069978, nll: 0.2426207794304803\n",
      "Epoch: 61; total_step: 7100, loss: 0.9782508659849234, nll: 0.2927569040461094\n",
      "Epoch: 61; total_step: 7150, loss: 0.9161482880454954, nll: 0.24011075990191796\n",
      "Epoch: 62; total_step: 7200, loss: 0.9244074832517443, nll: 0.2480396249875117\n",
      "Epoch: 62; total_step: 7250, loss: 0.905939508391096, nll: 0.22963756800552965\n",
      "Epoch: 62; total_step: 7300, loss: 0.8964637450610641, nll: 0.22038801441776648\n",
      "Epoch: 63; total_step: 7350, loss: 0.9806128694608449, nll: 0.2939248993719611\n",
      "Epoch: 63; total_step: 7400, loss: 0.9844092927252528, nll: 0.2941055047874008\n",
      "Epoch: 64; total_step: 7450, loss: 0.9685913859658888, nll: 0.27553507750560186\n",
      "Epoch: 64; total_step: 7500, loss: 0.9249252734380449, nll: 0.24889915619193634\n",
      "Epoch: 65; total_step: 7550, loss: 0.9118493305463798, nll: 0.2377230411258933\n",
      "Epoch: 65; total_step: 7600, loss: 0.9512681602461139, nll: 0.2650961189557959\n",
      "Epoch: 65; total_step: 7650, loss: 0.9934602662258487, nll: 0.30251149539306516\n",
      "Epoch: 66; total_step: 7700, loss: 0.9335054439832061, nll: 0.2571228898197885\n",
      "Epoch: 66; total_step: 7750, loss: 0.9233514360165002, nll: 0.24839022326118693\n",
      "Epoch: 67; total_step: 7800, loss: 0.9361049217793016, nll: 0.26062314302482015\n",
      "Epoch: 67; total_step: 7850, loss: 0.9665456028442156, nll: 0.2819682866941099\n",
      "Epoch: 68; total_step: 7900, loss: 0.9373529893045683, nll: 0.2574628688433735\n",
      "Epoch: 68; total_step: 7950, loss: 0.9501935629887854, nll: 0.26396669528937095\n",
      "Epoch: 68; total_step: 8000, loss: 0.9187547689259818, nll: 0.23642518144105226\n",
      "Epoch: 69; total_step: 8050, loss: 0.9343340929532054, nll: 0.252915805160508\n",
      "Epoch: 69; total_step: 8100, loss: 0.9384346719701715, nll: 0.25223736668738\n",
      "Epoch: 70; total_step: 8150, loss: 0.922587070157695, nll: 0.24091981745679092\n",
      "Epoch: 70; total_step: 8200, loss: 0.9362803162817722, nll: 0.25472007821938913\n",
      "Epoch: 71; total_step: 8250, loss: 0.9323418786520681, nll: 0.24895083828702827\n",
      "Epoch: 71; total_step: 8300, loss: 0.9565790849842015, nll: 0.27233775985065933\n",
      "Epoch: 71; total_step: 8350, loss: 0.9539348690597428, nll: 0.2697158668078908\n",
      "Epoch: 72; total_step: 8400, loss: 0.9413592829632395, nll: 0.2547833943160837\n",
      "Epoch: 72; total_step: 8450, loss: 0.9096830599073714, nll: 0.23448268767773076\n",
      "Epoch: 73; total_step: 8500, loss: 0.9180817795792787, nll: 0.23595057786423196\n",
      "Epoch: 73; total_step: 8550, loss: 0.9559610023265311, nll: 0.27162797092223284\n",
      "Epoch: 74; total_step: 8600, loss: 0.9246480191156733, nll: 0.24329036604711174\n",
      "Epoch: 74; total_step: 8650, loss: 1.0389276762744721, nll: 0.33839811983589\n",
      "Epoch: 75; total_step: 8700, loss: 0.9599038668720239, nll: 0.27490920573086364\n",
      "Epoch: 75; total_step: 8750, loss: 0.9112563614972987, nll: 0.23251860934472182\n",
      "Epoch: 75; total_step: 8800, loss: 0.9230437615089703, nll: 0.2406321756062058\n",
      "Epoch: 76; total_step: 8850, loss: 0.9412226064911069, nll: 0.2624384864289265\n",
      "Epoch: 76; total_step: 8900, loss: 0.9299998622352708, nll: 0.24653657959581174\n",
      "Epoch: 77; total_step: 8950, loss: 0.9768139537128256, nll: 0.2966437926454775\n",
      "Epoch: 77; total_step: 9000, loss: 0.9536401585606059, nll: 0.26431552000597686\n",
      "Epoch: 78; total_step: 9050, loss: 0.8985424176884467, nll: 0.2245381882632253\n",
      "Epoch: 78; total_step: 9100, loss: 0.9754984694189834, nll: 0.28611889446107647\n",
      "Epoch: 78; total_step: 9150, loss: 0.9088741315515895, nll: 0.2354664754171577\n",
      "Epoch: 79; total_step: 9200, loss: 0.8966661106585817, nll: 0.22577042057129512\n",
      "Epoch: 79; total_step: 9250, loss: 0.92587386636123, nll: 0.23830871197853423\n",
      "Epoch: 80; total_step: 9300, loss: 0.8889711725645225, nll: 0.21346987653471425\n",
      "Epoch: 80; total_step: 9350, loss: 0.8500714631320584, nll: 0.18283325072658058\n",
      "Epoch: 81; total_step: 9400, loss: 0.9367479002832834, nll: 0.2527413968733028\n",
      "Epoch: 81; total_step: 9450, loss: 0.9212077680356385, nll: 0.23852020024033127\n",
      "Epoch: 81; total_step: 9500, loss: 0.8992757237937228, nll: 0.22902337069065296\n",
      "Epoch: 82; total_step: 9550, loss: 0.9320364006364161, nll: 0.25024313069352344\n",
      "Epoch: 82; total_step: 9600, loss: 0.9916040824499043, nll: 0.2969189676836967\n",
      "Epoch: 83; total_step: 9650, loss: 0.9009378760449492, nll: 0.22923499212313783\n",
      "Epoch: 83; total_step: 9700, loss: 0.9853863735035102, nll: 0.28880907056071614\n",
      "Epoch: 84; total_step: 9750, loss: 0.9780955309346965, nll: 0.28518495803885563\n",
      "Epoch: 84; total_step: 9800, loss: 0.9135994917984114, nll: 0.23589607541754326\n",
      "Epoch: 84; total_step: 9850, loss: 0.9587580586136509, nll: 0.26175526629400325\n",
      "Epoch: 85; total_step: 9900, loss: 0.9121266669073035, nll: 0.23393076248697944\n",
      "Epoch: 85; total_step: 9950, loss: 0.9487914314474472, nll: 0.26612575749056017\n",
      "Epoch: 86; total_step: 10000, loss: 0.9208143154140253, nll: 0.23814548695045784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86; total_step: 10050, loss: 0.949318373185752, nll: 0.26656497379845007\n",
      "Epoch: 87; total_step: 10100, loss: 0.9508156170803036, nll: 0.2636665323339685\n",
      "Epoch: 87; total_step: 10150, loss: 0.9161823652418905, nll: 0.23945324037974397\n",
      "Epoch: 87; total_step: 10200, loss: 0.9776420967811593, nll: 0.2808393219897056\n",
      "Epoch: 88; total_step: 10250, loss: 0.9488860061051805, nll: 0.26578054803700446\n",
      "Epoch: 88; total_step: 10300, loss: 0.9167577537761356, nll: 0.24069635385202\n",
      "Epoch: 89; total_step: 10350, loss: 0.9236188733873494, nll: 0.24834209503629032\n",
      "Epoch: 89; total_step: 10400, loss: 0.9563813673459732, nll: 0.2580262920012555\n",
      "Epoch: 90; total_step: 10450, loss: 0.9141946917726824, nll: 0.2346206732162872\n",
      "Epoch: 90; total_step: 10500, loss: 0.9667445556422742, nll: 0.2777008644322143\n",
      "Epoch: 90; total_step: 10550, loss: 0.9532132950934878, nll: 0.26454712536071456\n",
      "Epoch: 91; total_step: 10600, loss: 0.9159104734295851, nll: 0.23425026204353316\n",
      "Epoch: 91; total_step: 10650, loss: 0.9642169347554032, nll: 0.2743628540738547\n",
      "Epoch: 92; total_step: 10700, loss: 0.9269487151063797, nll: 0.2434194918076799\n",
      "Epoch: 92; total_step: 10750, loss: 0.9429818751897935, nll: 0.2564595128420335\n",
      "Epoch: 93; total_step: 10800, loss: 0.9365964166693272, nll: 0.26010381665659993\n",
      "Epoch: 93; total_step: 10850, loss: 0.9053928154512557, nll: 0.22867336539802416\n",
      "Epoch: 93; total_step: 10900, loss: 0.916686673501573, nll: 0.23283313194764302\n",
      "Epoch: 94; total_step: 10950, loss: 0.940784068921671, nll: 0.24986155035366875\n",
      "Epoch: 94; total_step: 11000, loss: 1.007722268764053, nll: 0.30422359188847525\n",
      "Epoch: 95; total_step: 11050, loss: 0.8900014816748381, nll: 0.21395895975069232\n",
      "Epoch: 95; total_step: 11100, loss: 0.9548882557914178, nll: 0.262078452534859\n",
      "Epoch: 96; total_step: 11150, loss: 0.9570157146817537, nll: 0.27264834846960273\n",
      "Epoch: 96; total_step: 11200, loss: 0.9142717278292546, nll: 0.23331913792117723\n",
      "Epoch: 96; total_step: 11250, loss: 0.9216541251300104, nll: 0.24153164512025832\n",
      "Epoch: 97; total_step: 11300, loss: 0.9218279121325991, nll: 0.23441808740350759\n",
      "Epoch: 97; total_step: 11350, loss: 0.961752245114477, nll: 0.26942176335770235\n",
      "Epoch: 98; total_step: 11400, loss: 0.8789113226195914, nll: 0.20977356286528578\n",
      "Epoch: 98; total_step: 11450, loss: 0.8950646251745383, nll: 0.22082397984432306\n",
      "Epoch: 99; total_step: 11500, loss: 0.878022747757362, nll: 0.2051473946686864\n",
      "Epoch: 99; total_step: 11550, loss: 0.9818251221096157, nll: 0.28332468280749\n",
      "Done! loss: 0.8764239312904586\n",
      "\n",
      "Done Training!\n"
     ]
    }
   ],
   "source": [
    "model_t,likelihood_t = traditional_vi.train_gp(train_dataset,dim,\n",
    "                                                   num_inducing=num_inducing,\n",
    "                                                   minibatch_size=minibatch_size,\n",
    "                                                   num_epochs=num_epochs,\n",
    "                                                   use_ngd=use_ngd, use_ciq=use_ciq,\n",
    "                                                   learning_rate_hypers=learning_rate_hypers,\n",
    "                                                   learning_rate_ngd=learning_rate_ngd,\n",
    "                                                   lr_sched=lr_sched,\n",
    "                                                   num_contour_quadrature=num_contour_quadrature,gamma=gamma, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_t, variances_t = traditional_vi.eval_gp(test_dataset, model_t, likelihood_t, minibatch_size=n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 14400 testing points, MSE: 9.7147e-02, nll: 2.6375e-01.\n",
      "Training time: 22806.69 sec, testing time: 20.81 sec\n"
     ]
    }
   ],
   "source": [
    "# compute MSE\n",
    "#test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y[0],means_t)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means_t, variances_t.sqrt()).log_prob(test_y[0]).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein\n",
    "# dfree and svgp\n",
    "# At 9146 testing points, MSE: 5.9555e-01, nll: 1.1599e+00.\n",
    "# At 9146 testing points, MSE: 6.2736e-01, nll: 1.1856e+00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forest fire\n",
    "\n",
    "# At 104 testing points, MSE: 3.0218e+00, nll: 4.2752e+00.\n",
    "#Training time: 837.60 sec, testing time: 0.31 sec\n",
    "\n",
    "#At 104 testing points, MSE: 2.8974e+00, nll: 3.5117e+00.\n",
    "#Training time: 837.60 sec, testing time: 0.31 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#At 14400 testing points, MSE: 8.9581e-02, nll: 2.0471e-01.\n",
    "#At 14400 testing points, MSE: 9.7147e-02, nll: 2.6375e-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
