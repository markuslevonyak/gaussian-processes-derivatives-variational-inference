{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import random\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../directionalvi/utils\")\n",
    "sys.path.append(\"../directionalvi\")\n",
    "import traditional_vi\n",
    "from RBFKernelDirectionalGrad import RBFKernelDirectionalGrad\n",
    "#from DirectionalGradVariationalStrategy import DirectionalGradVariationalStrategy\n",
    "from dfree_directional_vi import train_gp, eval_gp\n",
    "from metrics import MSE\n",
    "import testfun\n",
    "from csv_dataset import csv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n",
      "[8]\n"
     ]
    }
   ],
   "source": [
    "dataset = csv_dataset(\"../experiments/real_data/kin40k.csv\", gradients=False, rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is:  40000\n",
      "dims is:  8\n"
     ]
    }
   ],
   "source": [
    "# data parameters\n",
    "n   = dataset.n\n",
    "print(\"n is: \", n)\n",
    "dim = dataset.dim\n",
    "print(\"dims is: \", dim)\n",
    "\n",
    "# training params\n",
    "num_inducing = 500\n",
    "num_directions = 1\n",
    "minibatch_size = 200\n",
    "num_epochs = 100\n",
    "\n",
    "# seed\n",
    "torch.random.manual_seed(0)\n",
    "# use tqdm or just have print statements\n",
    "tqdm = False\n",
    "# use data to initialize inducing stuff\n",
    "inducing_data_initialization = False\n",
    "# use natural gradients and/or CIQ\n",
    "use_ngd = False\n",
    "use_ciq = False\n",
    "num_contour_quadrature=15\n",
    "# learning rate\n",
    "learning_rate_hypers = 0.01\n",
    "learning_rate_ngd    = 0.1\n",
    "gamma  = 10.0\n",
    "#levels = np.array([20,150,300])\n",
    "#def lr_sched(epoch):\n",
    "#  a = np.sum(levels > epoch)\n",
    "#  return (1./gamma)**a\n",
    "lr_sched = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "n_train = int(0.8*dataset.n)\n",
    "n_test  = n - n_train\n",
    "train_dataset,test_dataset = torch.utils.data.random_split(dataset,[n_train,n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=n_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [item[1] for item in test_loader]\n",
    "test_x = [item[0] for item in test_loader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D-Free Grad SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---DirectionalGradVGP---\n",
      "Start training with 40000 trainig data of dim 8\n",
      "VI setups: 500 inducing points, 1 inducing directions\n",
      "All parameters to learn:\n",
      "      variational_strategy.inducing_points\n",
      "      torch.Size([500, 8])\n",
      "      variational_strategy.inducing_directions\n",
      "      torch.Size([500, 8])\n",
      "      variational_strategy._variational_distribution.variational_mean\n",
      "      torch.Size([1000])\n",
      "      variational_strategy._variational_distribution.chol_variational_covar\n",
      "      torch.Size([1000, 1000])\n",
      "      mean_module.constant\n",
      "      torch.Size([1])\n",
      "      covar_module.raw_outputscale\n",
      "      torch.Size([])\n",
      "      covar_module.base_kernel.raw_lengthscale\n",
      "      torch.Size([1, 1])\n",
      "      noise_covar.raw_noise\n",
      "      torch.Size([1])\n",
      "Total number of parameters:  1009004.0\n",
      "Epoch: 0; total_step: 0, loss: 2.3583228058187573, nll: 1.3929881315318045\n",
      "Epoch: 0; total_step: 50, loss: 1.707945131244776, nll: 1.2066330661288887\n",
      "Epoch: 0; total_step: 100, loss: 1.5104992874536232, nll: 0.9781890618114101\n",
      "Epoch: 0; total_step: 150, loss: 1.2838869635011356, nll: 0.7242257849749203\n",
      "Epoch: 1; total_step: 200, loss: 1.1339601377889799, nll: 0.5281692064989426\n",
      "Epoch: 1; total_step: 250, loss: 1.1523192985672948, nll: 0.5293885062722739\n",
      "Epoch: 1; total_step: 300, loss: 1.0648692974488467, nll: 0.46201212250209683\n",
      "Epoch: 2; total_step: 350, loss: 0.9700000361420398, nll: 0.3553424950453642\n",
      "Epoch: 2; total_step: 400, loss: 0.9843903741841064, nll: 0.4040628649074969\n",
      "Epoch: 2; total_step: 450, loss: 0.8900774098558429, nll: 0.27989183339033974\n",
      "Epoch: 3; total_step: 500, loss: 0.9803035624645773, nll: 0.27338587593922437\n",
      "Epoch: 3; total_step: 550, loss: 0.9194288180796144, nll: 0.3252265913739514\n",
      "Epoch: 3; total_step: 600, loss: 0.8091773815065545, nll: 0.19813906500659428\n",
      "Epoch: 4; total_step: 650, loss: 0.8756714729125313, nll: 0.26413348280461263\n",
      "Epoch: 4; total_step: 700, loss: 0.9335443555126863, nll: 0.25912107784359656\n",
      "Epoch: 4; total_step: 750, loss: 0.9027008033265806, nll: 0.3375391353468574\n",
      "Epoch: 5; total_step: 800, loss: 0.8254590481067186, nll: 0.22709366424589\n",
      "Epoch: 5; total_step: 850, loss: 0.850436164566177, nll: 0.20616838906997978\n",
      "Epoch: 5; total_step: 900, loss: 0.9168263580888609, nll: 0.22094481587808343\n",
      "Epoch: 5; total_step: 950, loss: 0.8301035044790968, nll: 0.1957699726230662\n",
      "Epoch: 6; total_step: 1000, loss: 0.8181112577824879, nll: 0.2850580612163093\n",
      "Epoch: 6; total_step: 1050, loss: 0.792759513746381, nll: 0.23883135838111919\n",
      "Epoch: 6; total_step: 1100, loss: 0.8411512941749522, nll: 0.25692210927740544\n",
      "Epoch: 7; total_step: 1150, loss: 0.7508986549181644, nll: 0.14891115668406207\n",
      "Epoch: 7; total_step: 1200, loss: 0.7445471356208251, nll: 0.18783024303958157\n",
      "Epoch: 7; total_step: 1250, loss: 0.7282888953310311, nll: 0.15818110368357818\n",
      "Epoch: 8; total_step: 1300, loss: 0.8157606359093521, nll: 0.22328863853414757\n",
      "Epoch: 8; total_step: 1350, loss: 0.8061420315014948, nll: 0.22441560376864775\n",
      "Epoch: 8; total_step: 1400, loss: 0.7616144496650457, nll: 0.09545185269258845\n",
      "Epoch: 9; total_step: 1450, loss: 0.7059117780501941, nll: 0.044976141600340414\n",
      "Epoch: 9; total_step: 1500, loss: 0.6641570721610344, nll: 0.06955400231514092\n",
      "Epoch: 9; total_step: 1550, loss: 0.6767677619485152, nll: 0.13389551094037078\n",
      "Epoch: 10; total_step: 1600, loss: 0.7778343841831798, nll: 0.2015319652702383\n",
      "Epoch: 10; total_step: 1650, loss: 0.7206011739928626, nll: 0.1905669281678668\n",
      "Epoch: 10; total_step: 1700, loss: 0.7679964637851832, nll: 0.05217504786639722\n",
      "Epoch: 10; total_step: 1750, loss: 0.7150180166356597, nll: 0.09955465811484789\n",
      "Epoch: 11; total_step: 1800, loss: 0.8518642500146476, nll: 0.30011757891580976\n",
      "Epoch: 11; total_step: 1850, loss: 0.8332458793464694, nll: 0.28839601156537503\n",
      "Epoch: 11; total_step: 1900, loss: 0.6289826127546736, nll: -0.020152519766690212\n",
      "Epoch: 12; total_step: 1950, loss: 0.7797962468742032, nll: 0.17832309431759336\n",
      "Epoch: 12; total_step: 2000, loss: 0.7249004146534918, nll: 0.12689322127126662\n",
      "Epoch: 12; total_step: 2050, loss: 0.6826919362360769, nll: 0.10569692894777093\n",
      "Epoch: 13; total_step: 2100, loss: 0.5665297575674173, nll: 0.005232693947227189\n",
      "Epoch: 13; total_step: 2150, loss: 0.7388993341536039, nll: 0.09932464718463706\n",
      "Epoch: 13; total_step: 2200, loss: 0.7162512398484085, nll: 0.14113429155548585\n",
      "Epoch: 14; total_step: 2250, loss: 0.6623343313694003, nll: 0.07889825967761273\n",
      "Epoch: 14; total_step: 2300, loss: 0.7516114340743628, nll: -0.00012485289110512277\n",
      "Epoch: 14; total_step: 2350, loss: 0.6306530085372002, nll: 0.09284200607546617\n",
      "Epoch: 15; total_step: 2400, loss: 0.6517114765405019, nll: 0.11383809981910156\n",
      "Epoch: 15; total_step: 2450, loss: 0.5947708627958718, nll: -0.0017218581756759622\n",
      "Epoch: 15; total_step: 2500, loss: 0.5505766643532137, nll: -0.08327120603316397\n",
      "Epoch: 15; total_step: 2550, loss: 0.7046532279955287, nll: 0.17320133798522272\n",
      "Epoch: 16; total_step: 2600, loss: 0.6329043614678276, nll: 0.01622221244510806\n",
      "Epoch: 16; total_step: 2650, loss: 0.6181113221513966, nll: -0.039227876630171285\n",
      "Epoch: 16; total_step: 2700, loss: 0.7292633774752317, nll: 0.04624271547075358\n",
      "Epoch: 17; total_step: 2750, loss: 0.693733362608918, nll: 0.1430442750495696\n",
      "Epoch: 17; total_step: 2800, loss: 0.5944218114511481, nll: -0.021407701326371213\n",
      "Epoch: 17; total_step: 2850, loss: 0.7248948662410167, nll: 0.08904101592252095\n",
      "Epoch: 18; total_step: 2900, loss: 0.6265690510685011, nll: 0.01670285815384462\n",
      "Epoch: 18; total_step: 2950, loss: 0.8258299890129838, nll: 0.2912080773857553\n",
      "Epoch: 18; total_step: 3000, loss: 0.680139711706725, nll: 0.08408642551164702\n",
      "Epoch: 19; total_step: 3050, loss: 0.6277791981990647, nll: 0.04799623469224676\n",
      "Epoch: 19; total_step: 3100, loss: 0.6768298709730811, nll: -0.029912531482778535\n",
      "Epoch: 19; total_step: 3150, loss: 0.7022463332696476, nll: 0.06383941317146713\n",
      "Epoch: 20; total_step: 3200, loss: 0.5787976853757312, nll: -0.06611534230821474\n",
      "Epoch: 20; total_step: 3250, loss: 0.6897479740418575, nll: 0.10619297061694975\n",
      "Epoch: 20; total_step: 3300, loss: 0.6467367654164782, nll: 0.07241233944579939\n",
      "Epoch: 20; total_step: 3350, loss: 0.6453559229311142, nll: 0.06898981192004638\n",
      "Epoch: 21; total_step: 3400, loss: 0.6921383389320553, nll: 0.15936162656672614\n",
      "Epoch: 21; total_step: 3450, loss: 0.6641237114305615, nll: 0.05259407600773794\n",
      "Epoch: 21; total_step: 3500, loss: 0.5991506149999464, nll: 0.03669260654396425\n",
      "Epoch: 22; total_step: 3550, loss: 0.5691153871813863, nll: -0.007010193151274216\n",
      "Epoch: 22; total_step: 3600, loss: 0.5785893685050797, nll: -0.022733371362510964\n",
      "Epoch: 22; total_step: 3650, loss: 0.6637246456702046, nll: 0.09374942308900211\n",
      "Epoch: 23; total_step: 3700, loss: 0.585243934888747, nll: -0.005852517526259158\n",
      "Epoch: 23; total_step: 3750, loss: 0.528231261696297, nll: -0.05516901946227721\n",
      "Epoch: 23; total_step: 3800, loss: 0.5669465415071566, nll: -0.06208865322722122\n",
      "Epoch: 24; total_step: 3850, loss: 0.6272763700229815, nll: 0.018916223169832505\n",
      "Epoch: 24; total_step: 3900, loss: 0.6429772001775939, nll: -0.024385049035694634\n",
      "Epoch: 24; total_step: 3950, loss: 0.5719392702123546, nll: -0.04841355600199368\n",
      "Epoch: 25; total_step: 4000, loss: 0.5869997399548632, nll: -0.055344260736332244\n",
      "Epoch: 25; total_step: 4050, loss: 0.7029101797865647, nll: 0.15952861159945741\n",
      "Epoch: 25; total_step: 4100, loss: 0.7668183603834308, nll: 0.05438506019075142\n",
      "Epoch: 25; total_step: 4150, loss: 0.6452057375002311, nll: 0.05509841465336276\n",
      "Epoch: 26; total_step: 4200, loss: 0.5575530412402583, nll: -0.0074537313219449515\n",
      "Epoch: 26; total_step: 4250, loss: 0.5613578466234003, nll: -0.08114263280140964\n",
      "Epoch: 26; total_step: 4300, loss: 0.6665951961659548, nll: 0.07313999368757898\n",
      "Epoch: 27; total_step: 4350, loss: 0.659515682511742, nll: 0.12394126103849973\n",
      "Epoch: 27; total_step: 4400, loss: 0.6734830284474964, nll: 0.017117148826397408\n",
      "Epoch: 27; total_step: 4450, loss: 0.6125905510303516, nll: 0.02999862241626344\n",
      "Epoch: 28; total_step: 4500, loss: 0.6093194725952127, nll: -0.027552086795864787\n",
      "Epoch: 28; total_step: 4550, loss: 0.535709636976838, nll: -0.07964458857357211\n",
      "Epoch: 28; total_step: 4600, loss: 0.6527796081244773, nll: 0.1070386014940816\n",
      "Epoch: 29; total_step: 4650, loss: 0.5822034934070555, nll: -0.0012849730077610655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29; total_step: 4700, loss: 0.5429617104588167, nll: -0.1343379990317302\n",
      "Epoch: 29; total_step: 4750, loss: 0.7516069027322844, nll: 0.22613092887109595\n",
      "Epoch: 30; total_step: 4800, loss: 0.6201627862872725, nll: 0.14684258623605037\n",
      "Epoch: 30; total_step: 4850, loss: 0.5505099981111404, nll: 0.0075199864000499335\n",
      "Epoch: 30; total_step: 4900, loss: 0.6105842906172958, nll: -0.02006576932385422\n",
      "Epoch: 30; total_step: 4950, loss: 0.5309468367620472, nll: -0.08067179105470602\n",
      "Epoch: 31; total_step: 5000, loss: 0.5761926240967695, nll: 0.04654691550475429\n",
      "Epoch: 31; total_step: 5050, loss: 0.6582110252818575, nll: 0.1205556700821975\n",
      "Epoch: 31; total_step: 5100, loss: 0.5412674871328451, nll: -0.016346521774201834\n",
      "Epoch: 32; total_step: 5150, loss: 0.46626278020266637, nll: -0.11242512790312381\n",
      "Epoch: 32; total_step: 5200, loss: 0.6438555378279649, nll: 0.10343979743750417\n",
      "Epoch: 32; total_step: 5250, loss: 0.5626047948747147, nll: 0.05963453602746371\n",
      "Epoch: 33; total_step: 5300, loss: 0.5090663115594758, nll: -0.10384573505861326\n",
      "Epoch: 33; total_step: 5350, loss: 0.4393669737139953, nll: -0.14328135069780065\n",
      "Epoch: 33; total_step: 5400, loss: 0.6170367287242381, nll: 0.019551251854570014\n",
      "Epoch: 34; total_step: 5450, loss: 0.6923852921497945, nll: -0.04151332202455878\n",
      "Epoch: 34; total_step: 5500, loss: 0.6099182769124062, nll: -0.0753035737175632\n",
      "Epoch: 34; total_step: 5550, loss: 0.6669662460225502, nll: 0.01775616859072624\n",
      "Epoch: 35; total_step: 5600, loss: 0.5764307072640826, nll: -0.07328962497021264\n",
      "Epoch: 35; total_step: 5650, loss: 0.5906526534557976, nll: 0.08977870569381187\n",
      "Epoch: 35; total_step: 5700, loss: 0.7503731147909893, nll: 0.14019734661850689\n",
      "Epoch: 35; total_step: 5750, loss: 0.6490655152112802, nll: 0.0564021300486968\n",
      "Epoch: 36; total_step: 5800, loss: 0.565158292223779, nll: -0.008531017267394336\n",
      "Epoch: 36; total_step: 5850, loss: 0.5251487927757277, nll: -0.15927546306675444\n",
      "Epoch: 36; total_step: 5900, loss: 0.5852260572209564, nll: 0.0040310021890376645\n",
      "Epoch: 37; total_step: 5950, loss: 0.6003486718070966, nll: -0.007966639056811968\n",
      "Epoch: 37; total_step: 6000, loss: 0.48348640444728214, nll: -0.11809256981335123\n",
      "Epoch: 37; total_step: 6050, loss: 0.4758769174823408, nll: -0.1894382651540069\n",
      "Epoch: 38; total_step: 6100, loss: 0.5551909828312199, nll: -0.019082412597365313\n",
      "Epoch: 38; total_step: 6150, loss: 0.491527837855478, nll: -0.08450492537996837\n",
      "Epoch: 38; total_step: 6200, loss: 0.523229195740814, nll: -0.162132234842385\n",
      "Epoch: 39; total_step: 6250, loss: 0.5349378346013863, nll: -0.06784991961011469\n",
      "Epoch: 39; total_step: 6300, loss: 0.491514894500005, nll: -0.12266406373525289\n",
      "Epoch: 39; total_step: 6350, loss: 0.5462654970803729, nll: -0.037736197671192545\n",
      "Epoch: 40; total_step: 6400, loss: 0.5278497792929269, nll: -0.0907277472153908\n",
      "Epoch: 40; total_step: 6450, loss: 0.5457150183932495, nll: -0.1015535057808016\n",
      "Epoch: 40; total_step: 6500, loss: 0.4797842434236996, nll: -0.1150465261273256\n",
      "Epoch: 40; total_step: 6550, loss: 0.5941298608030583, nll: -0.09975208729358281\n",
      "Epoch: 41; total_step: 6600, loss: 0.6648893920168928, nll: 0.12973414398779373\n",
      "Epoch: 41; total_step: 6650, loss: 0.5362686877276387, nll: -0.05609397792483674\n",
      "Epoch: 41; total_step: 6700, loss: 0.447171628416307, nll: -0.1281972123924808\n",
      "Epoch: 42; total_step: 6750, loss: 0.5432735309230204, nll: -0.09392814173374792\n",
      "Epoch: 42; total_step: 6800, loss: 0.4500093221770497, nll: -0.14837585713678564\n",
      "Epoch: 42; total_step: 6850, loss: 0.6818536680148968, nll: 0.1579238256188426\n",
      "Epoch: 43; total_step: 6900, loss: 0.5012317995082487, nll: -0.04998286702178773\n",
      "Epoch: 43; total_step: 6950, loss: 0.6274369255315984, nll: -0.06154502685726206\n",
      "Epoch: 43; total_step: 7000, loss: 0.6370860901089885, nll: 0.05184598293080352\n",
      "Epoch: 44; total_step: 7050, loss: 0.5309609572901393, nll: -0.09685531048627133\n",
      "Epoch: 44; total_step: 7100, loss: 0.5039315898558889, nll: -0.01635744123015221\n",
      "Epoch: 44; total_step: 7150, loss: 0.6028839906671284, nll: -0.1044146025912801\n",
      "Epoch: 45; total_step: 7200, loss: 0.5181329621598575, nll: -0.09858473191956196\n",
      "Epoch: 45; total_step: 7250, loss: 0.5379265706103946, nll: -0.05461856158865496\n",
      "Epoch: 45; total_step: 7300, loss: 0.49856138148753315, nll: -0.10431405158315028\n",
      "Epoch: 45; total_step: 7350, loss: 0.5710595995531651, nll: -0.09061694539601906\n",
      "Epoch: 46; total_step: 7400, loss: 0.5942863915070743, nll: -0.10382216245350516\n",
      "Epoch: 46; total_step: 7450, loss: 0.5054507951623943, nll: -0.1324166519158503\n",
      "Epoch: 46; total_step: 7500, loss: 0.5013406494457622, nll: -0.0796395512125847\n",
      "Epoch: 47; total_step: 7550, loss: 0.6234263418933125, nll: 0.11915733595768557\n",
      "Epoch: 47; total_step: 7600, loss: 0.465815159596936, nll: -0.14132821369849188\n",
      "Epoch: 47; total_step: 7650, loss: 0.6252365037121496, nll: 0.11825794565397447\n",
      "Epoch: 48; total_step: 7700, loss: 0.5225318091913145, nll: -0.24109684159145534\n",
      "Epoch: 48; total_step: 7750, loss: 0.5912633345427927, nll: 0.0607771864738831\n",
      "Epoch: 48; total_step: 7800, loss: 0.4830071401788274, nll: -0.19276723921812672\n",
      "Epoch: 49; total_step: 7850, loss: 0.5703570035672054, nll: -0.04660163890602122\n",
      "Epoch: 49; total_step: 7900, loss: 0.5241575779332539, nll: -0.029202193682406098\n",
      "Epoch: 49; total_step: 7950, loss: 0.4662270650857188, nll: -0.1793529598351504\n",
      "Epoch: 50; total_step: 8000, loss: 0.5192286774465364, nll: -0.08461154713951398\n",
      "Epoch: 50; total_step: 8050, loss: 0.43428125801823064, nll: -0.08174053013083483\n",
      "Epoch: 50; total_step: 8100, loss: 0.6214411163490348, nll: 0.05785922407742749\n",
      "Epoch: 50; total_step: 8150, loss: 0.5719885205922967, nll: -0.08225078200025408\n",
      "Epoch: 51; total_step: 8200, loss: 0.3849539735042943, nll: -0.2483907097846684\n",
      "Epoch: 51; total_step: 8250, loss: 0.45468002143266895, nll: -0.16216238933275381\n",
      "Epoch: 51; total_step: 8300, loss: 0.5340075799863904, nll: -0.0364565242285731\n",
      "Epoch: 52; total_step: 8350, loss: 0.5668793962276316, nll: -0.1340368955293873\n",
      "Epoch: 52; total_step: 8400, loss: 0.543374665163482, nll: -0.058664145574264207\n",
      "Epoch: 52; total_step: 8450, loss: 0.5209544742030379, nll: -0.01918448223946867\n",
      "Epoch: 53; total_step: 8500, loss: 0.4806229315840925, nll: -0.045479597691279225\n",
      "Epoch: 53; total_step: 8550, loss: 0.4505060785639441, nll: -0.12799020217331114\n",
      "Epoch: 53; total_step: 8600, loss: 0.4076337677698782, nll: -0.24721348612491859\n",
      "Epoch: 54; total_step: 8650, loss: 0.4640016252372169, nll: -0.13983447430431645\n",
      "Epoch: 54; total_step: 8700, loss: 0.570591191820912, nll: -0.08128424504033158\n",
      "Epoch: 54; total_step: 8750, loss: 0.5125663864564991, nll: -0.12532641233273784\n",
      "Epoch: 55; total_step: 8800, loss: 0.41766075574062106, nll: -0.1640571132159038\n",
      "Epoch: 55; total_step: 8850, loss: 0.5037837262766054, nll: -0.13067100437231402\n",
      "Epoch: 55; total_step: 8900, loss: 0.4613084657681643, nll: -0.09457927382311286\n",
      "Epoch: 55; total_step: 8950, loss: 0.47119615482753846, nll: -0.1982967995243909\n",
      "Epoch: 56; total_step: 9000, loss: 0.48558526849604855, nll: -0.07126351587279225\n",
      "Epoch: 56; total_step: 9050, loss: 0.4714841040520165, nll: -0.19085497423806522\n",
      "Epoch: 56; total_step: 9100, loss: 0.45981225907643486, nll: -0.13326605930669783\n",
      "Epoch: 57; total_step: 9150, loss: 0.4921436771237248, nll: -0.10889223053183064\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "print(\"\\n\\n---DirectionalGradVGP---\")\n",
    "print(f\"Start training with {n} trainig data of dim {dim}\")\n",
    "print(f\"VI setups: {num_inducing} inducing points, {num_directions} inducing directions\")\n",
    "args={\"verbose\":True}\n",
    "t1 = time.time()\t\n",
    "model,likelihood = train_gp(train_dataset,\n",
    "                      num_inducing=num_inducing,\n",
    "                      num_directions=num_directions,\n",
    "                      minibatch_size = minibatch_size,\n",
    "                      minibatch_dim = num_directions,\n",
    "                      num_epochs =num_epochs, \n",
    "                      learning_rate_hypers=learning_rate_hypers,\n",
    "                      learning_rate_ngd=learning_rate_ngd,\n",
    "                      inducing_data_initialization=inducing_data_initialization,\n",
    "                      use_ngd = use_ngd,\n",
    "                      use_ciq = use_ciq,\n",
    "                      lr_sched=lr_sched,\n",
    "                      num_contour_quadrature=num_contour_quadrature,\n",
    "                      tqdm=tqdm,**args\n",
    "                      )\n",
    "t2 = time.time()\t\n",
    "\n",
    "# save the model\n",
    "# torch.save(model.state_dict(), \"../data/test_dvi_basic.model\")\n",
    "\n",
    "# test\n",
    "means, variances = eval_gp( test_dataset,model,likelihood,\n",
    "                            num_directions=num_directions,\n",
    "                            minibatch_size=n_test,\n",
    "                            minibatch_dim=num_directions)\n",
    "t3 = time.time()\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute MSE\n",
    "#test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y[0],means)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means, variances.sqrt()).log_prob(test_y[0]).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")\n",
    "\n",
    "#plot=1\n",
    "#if plot == 1:\n",
    "#    from mpl_toolkits.mplot3d import axes3d\n",
    "#    import matplotlib.pyplot as plt\n",
    "#    fig = plt.figure(figsize=(12,6))\n",
    "#    ax = fig.add_subplot(111, projection='3d')\n",
    "#    ax.scatter(test_x[0][:,0],test_x[:,1],test_y, color='k')\n",
    "#    ax.scatter(test_x[0][:,0],test_x[:,1],means, color='b')\n",
    "#    plt.title(\"f(x,y) variational fit; actual curve is black, variational is blue\")\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "#num_inducing = 50\n",
    "#num_directions = 6\n",
    "#minibatch_size = 200\n",
    "#num_epochs = 100\n",
    "\n",
    "\n",
    "# 2 directions\n",
    "#At 104 testing points, MSE: 2.9133e+00, nll: 3.3945e+00. \n",
    "# 3 directions\n",
    "#At 104 testing points, MSE: 2.9455e+00, nll: 3.3617e+00.\n",
    "#Training time: 70.29 sec, testing time: 0.10 sec\n",
    "# 4 directions\n",
    "#At 104 testing points, MSE: 2.9810e+00, nll: 3.0743e+00.\n",
    "#Training time: 57.68 sec, testing time: 0.08 sec\n",
    "# 5 directions\n",
    "#At 104 testing points, MSE: 2.9440e+00, nll: 3.6124e+00.\n",
    "#Training time: 104.46 sec, testing time: 0.12 sec\n",
    "# 6 directions\n",
    "#At 104 testing points, MSE: 2.9795e+00, nll: 3.1092e+00.\n",
    "#Training time: 127.73 sec, testing time: 0.10 sec\n",
    "# 7 directions\n",
    "#At 104 testing points, MSE: 2.9272e+00, nll: 3.6537e+00.\n",
    "#Training time: 153.38 sec, testing time: 0.12 sec\n",
    "# 8 directions\n",
    "#At 104 testing points, MSE: 2.9503e+00, nll: 3.3300e+00.\n",
    "#Training time: 173.86 sec, testing time: 0.15 sec\n",
    "# 9 directions\n",
    "# 10 directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional SVGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t,likelihood_t = traditional_vi.train_gp(train_dataset,dim,\n",
    "                                                   num_inducing=num_inducing,\n",
    "                                                   minibatch_size=minibatch_size,\n",
    "                                                   num_epochs=num_epochs,\n",
    "                                                   use_ngd=use_ngd, use_ciq=use_ciq,\n",
    "                                                   learning_rate_hypers=learning_rate_hypers,\n",
    "                                                   learning_rate_ngd=learning_rate_ngd,\n",
    "                                                   lr_sched=lr_sched,\n",
    "                                                   num_contour_quadrature=num_contour_quadrature,gamma=gamma, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_t, variances_t = traditional_vi.eval_gp(test_dataset, model_t, likelihood_t, minibatch_size=n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute MSE\n",
    "#test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y[0],means_t)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means_t, variances_t.sqrt()).log_prob(test_y[0]).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
