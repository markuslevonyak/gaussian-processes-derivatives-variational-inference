{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import tqdm\n",
    "import random\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../directionalvi/utils\")\n",
    "sys.path.append(\"../directionalvi\")\n",
    "from RBFKernelDirectionalGrad import RBFKernelDirectionalGrad\n",
    "#from DirectionalGradVariationalStrategy import DirectionalGradVariationalStrategy\n",
    "from dfree_directional_vi import train_gp, eval_gp\n",
    "from metrics import MSE\n",
    "import testfun\n",
    "from csv_dataset import csv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8]\n",
      "[9]\n"
     ]
    }
   ],
   "source": [
    "dataset = csv_dataset(\"../experiments/real_data/CASP.csv\", gradients=False, rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is:  45730\n",
      "dims is:  9\n"
     ]
    }
   ],
   "source": [
    "# data parameters\n",
    "n   = dataset.n\n",
    "print(\"n is: \", n)\n",
    "dim = dataset.dim\n",
    "print(\"dims is: \", dim)\n",
    "\n",
    "\n",
    "# training params\n",
    "num_inducing = 20\n",
    "num_directions = 2\n",
    "minibatch_size = 200\n",
    "num_epochs = 400\n",
    "\n",
    "# seed\n",
    "torch.random.manual_seed(0)\n",
    "# use tqdm or just have print statements\n",
    "tqdm = False\n",
    "# use data to initialize inducing stuff\n",
    "inducing_data_initialization = False\n",
    "# use natural gradients and/or CIQ\n",
    "use_ngd = False\n",
    "use_ciq = False\n",
    "num_contour_quadrature=15\n",
    "# learning rate\n",
    "learning_rate_hypers = 0.01\n",
    "learning_rate_ngd    = 0.1\n",
    "gamma  = 10.0\n",
    "#levels = np.array([20,150,300])\n",
    "#def lr_sched(epoch):\n",
    "#  a = np.sum(levels > epoch)\n",
    "#  return (1./gamma)**a\n",
    "lr_sched = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "n_train = int(0.8*dataset.n)\n",
    "n_test  = n - n_train\n",
    "train_dataset,test_dataset = torch.utils.data.random_split(dataset,[n_train,n_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=n_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---DirectionalGradVGP---\n",
      "Start training with 45730 trainig data of dim 9\n",
      "VI setups: 20 inducing points, 2 inducing directions\n",
      "All parameters to learn:\n",
      "      variational_strategy.inducing_points\n",
      "      torch.Size([20, 9])\n",
      "      variational_strategy.inducing_directions\n",
      "      torch.Size([40, 9])\n",
      "      variational_strategy._variational_distribution.variational_mean\n",
      "      torch.Size([60])\n",
      "      variational_strategy._variational_distribution.chol_variational_covar\n",
      "      torch.Size([60, 60])\n",
      "      mean_module.constant\n",
      "      torch.Size([1])\n",
      "      covar_module.raw_outputscale\n",
      "      torch.Size([])\n",
      "      covar_module.base_kernel.raw_lengthscale\n",
      "      torch.Size([1, 1])\n",
      "      noise_covar.raw_noise\n",
      "      torch.Size([1])\n",
      "Total number of parameters:  4204.0\n",
      "Epoch: 0; total_step: 0, loss: 2.48255889340812, nll: 1.466237968519302\n",
      "Epoch: 0; total_step: 50, loss: 1.8813469458247452, nll: 1.3391872372182174\n",
      "Epoch: 0; total_step: 100, loss: 1.7913530470135421, nll: 1.2427956916297787\n",
      "Epoch: 0; total_step: 150, loss: 1.7259671105697163, nll: 1.2413696064376651\n",
      "Epoch: 1; total_step: 200, loss: 1.8058431684883756, nll: 1.335351263613548\n",
      "Epoch: 1; total_step: 250, loss: 1.6797922124637825, nll: 1.1626301125609821\n",
      "Epoch: 1; total_step: 300, loss: 1.684203168176814, nll: 1.1536405095743567\n",
      "Epoch: 1; total_step: 350, loss: 1.8478136535375977, nll: 1.4257247360967282\n",
      "Epoch: 2; total_step: 400, loss: 1.7494839124653618, nll: 1.2075006659343157\n",
      "Epoch: 2; total_step: 450, loss: 1.7835170454820224, nll: 1.2727055384749673\n",
      "Epoch: 2; total_step: 500, loss: 1.7509743841049814, nll: 1.3425881367826666\n",
      "Epoch: 3; total_step: 550, loss: 1.8006882110987459, nll: 1.3110105945697261\n",
      "Epoch: 3; total_step: 600, loss: 1.6795394096349572, nll: 1.1818853246676142\n",
      "Epoch: 3; total_step: 650, loss: 1.7691535675078165, nll: 1.1544180078210897\n",
      "Epoch: 3; total_step: 700, loss: 1.816251852659242, nll: 1.2967519809948114\n",
      "Epoch: 4; total_step: 750, loss: 1.7111181755251197, nll: 1.220514972302111\n",
      "Epoch: 4; total_step: 800, loss: 1.6661007120511595, nll: 1.0913939284892675\n",
      "Epoch: 4; total_step: 850, loss: 1.710326142012077, nll: 1.1118305669603377\n",
      "Epoch: 4; total_step: 900, loss: 1.6468701848725351, nll: 1.091346918968853\n",
      "Epoch: 5; total_step: 950, loss: 1.736307843200712, nll: 1.2812464763225957\n",
      "Epoch: 5; total_step: 1000, loss: 1.7761978101447888, nll: 1.30118650795421\n",
      "Epoch: 5; total_step: 1050, loss: 1.7550801350246912, nll: 1.0656817118584812\n",
      "Epoch: 6; total_step: 1100, loss: 1.7901860449610814, nll: 1.2636487918993062\n",
      "Epoch: 6; total_step: 1150, loss: 1.729641648317607, nll: 1.1837411476118531\n",
      "Epoch: 6; total_step: 1200, loss: 1.7029204147110375, nll: 1.0851027433259894\n",
      "Epoch: 6; total_step: 1250, loss: 1.7076089273444837, nll: 1.2860600601448346\n",
      "Epoch: 7; total_step: 1300, loss: 1.6809897865633991, nll: 1.112774506134341\n",
      "Epoch: 7; total_step: 1350, loss: 1.689097323143161, nll: 1.1756391695825739\n",
      "Epoch: 7; total_step: 1400, loss: 1.7094791718804823, nll: 1.2340198692816917\n",
      "Epoch: 7; total_step: 1450, loss: 1.7520670521452013, nll: 1.1027137103403357\n",
      "Epoch: 8; total_step: 1500, loss: 1.733320168379608, nll: 1.1231924980290933\n",
      "Epoch: 8; total_step: 1550, loss: 1.796938706170926, nll: 1.2400808432801966\n",
      "Epoch: 8; total_step: 1600, loss: 1.7230150376710949, nll: 1.2893802329709498\n",
      "Epoch: 9; total_step: 1650, loss: 1.723206252664059, nll: 1.117174044694547\n",
      "Epoch: 9; total_step: 1700, loss: 1.6484295409520533, nll: 1.275498598872103\n",
      "Epoch: 9; total_step: 1750, loss: 1.668389880343944, nll: 1.1970467733840402\n",
      "Epoch: 9; total_step: 1800, loss: 1.7314957360493852, nll: 1.3300684313721287\n",
      "Epoch: 10; total_step: 1850, loss: 1.75267437375384, nll: 1.464785826569839\n",
      "Epoch: 10; total_step: 1900, loss: 1.8412305406916862, nll: 1.4632854974822576\n",
      "Epoch: 10; total_step: 1950, loss: 1.7457057001570104, nll: 1.2693788100686552\n",
      "Epoch: 10; total_step: 2000, loss: 1.7499722605782466, nll: 1.2311990367957752\n",
      "Epoch: 11; total_step: 2050, loss: 1.6605541380560442, nll: 1.2190358879422185\n",
      "Epoch: 11; total_step: 2100, loss: 1.6720869711656787, nll: 1.158846906030869\n",
      "Epoch: 11; total_step: 2150, loss: 1.7477338952481858, nll: 1.1879192780283088\n",
      "Epoch: 12; total_step: 2200, loss: 1.7231905834424868, nll: 1.204394567636748\n",
      "Epoch: 12; total_step: 2250, loss: 1.6893347502122151, nll: 1.266141929881445\n",
      "Epoch: 12; total_step: 2300, loss: 1.7277019572347445, nll: 1.324975453997685\n",
      "Epoch: 12; total_step: 2350, loss: 1.6870430162357202, nll: 1.0977637332179409\n",
      "Epoch: 13; total_step: 2400, loss: 1.7751335318021446, nll: 1.2472975102997508\n",
      "Epoch: 13; total_step: 2450, loss: 1.8560104155905122, nll: 1.3672736411869508\n",
      "Epoch: 13; total_step: 2500, loss: 1.7844420175770928, nll: 1.2136700295259368\n",
      "Epoch: 13; total_step: 2550, loss: 1.7085781319993956, nll: 1.336783413009563\n",
      "Epoch: 14; total_step: 2600, loss: 1.6346580496394114, nll: 1.131254816104584\n",
      "Epoch: 14; total_step: 2650, loss: 1.7944527059180744, nll: 1.2821963944274257\n",
      "Epoch: 14; total_step: 2700, loss: 1.6858604982684648, nll: 1.2838408742038372\n",
      "Epoch: 15; total_step: 2750, loss: 1.6242952317116375, nll: 1.1893477603782743\n",
      "Epoch: 15; total_step: 2800, loss: 1.7725015052580966, nll: 1.174456974245027\n",
      "Epoch: 15; total_step: 2850, loss: 1.7186299233999154, nll: 1.1819448641690953\n",
      "Epoch: 15; total_step: 2900, loss: 1.6814636693559022, nll: 1.128731134950018\n",
      "Epoch: 16; total_step: 2950, loss: 1.7594540464840933, nll: 1.2281601959416473\n",
      "Epoch: 16; total_step: 3000, loss: 1.6706501168180308, nll: 1.2095103906702511\n",
      "Epoch: 16; total_step: 3050, loss: 1.6768588524336274, nll: 1.2178142261397529\n",
      "Epoch: 16; total_step: 3100, loss: 1.803127340525749, nll: 1.3958819231256347\n",
      "Epoch: 17; total_step: 3150, loss: 1.732502310759741, nll: 1.344419436834317\n",
      "Epoch: 17; total_step: 3200, loss: 1.7130400326372075, nll: 1.1934268227011111\n",
      "Epoch: 17; total_step: 3250, loss: 1.7185031997966524, nll: 1.3010748663630924\n",
      "Epoch: 18; total_step: 3300, loss: 1.637812643833214, nll: 1.1702588025752445\n",
      "Epoch: 18; total_step: 3350, loss: 1.7189553684512202, nll: 1.1684849681509264\n",
      "Epoch: 18; total_step: 3400, loss: 1.8041235474400055, nll: 1.3190188933613762\n",
      "Epoch: 18; total_step: 3450, loss: 1.664223621913037, nll: 1.1097445348000932\n",
      "Epoch: 19; total_step: 3500, loss: 1.7114522515944952, nll: 1.1790916797963353\n",
      "Epoch: 19; total_step: 3550, loss: 1.6565861168348255, nll: 1.1377269412938404\n",
      "Epoch: 19; total_step: 3600, loss: 1.8012100937787667, nll: 1.3253296203783318\n",
      "Epoch: 19; total_step: 3650, loss: 1.6680009101845785, nll: 1.1769649996775688\n",
      "Epoch: 20; total_step: 3700, loss: 1.7261338530779957, nll: 1.206786993284257\n",
      "Epoch: 20; total_step: 3750, loss: 1.6774657868118967, nll: 1.1579633470916362\n",
      "Epoch: 20; total_step: 3800, loss: 1.7658423555828962, nll: 1.2408877300883194\n",
      "Epoch: 21; total_step: 3850, loss: 1.7038882972526477, nll: 1.2405784030542082\n",
      "Epoch: 21; total_step: 3900, loss: 1.713507581064269, nll: 1.1861518128620534\n",
      "Epoch: 21; total_step: 3950, loss: 1.696971255972649, nll: 1.2410173901659245\n",
      "Epoch: 21; total_step: 4000, loss: 1.7047330794825208, nll: 1.2587158687079094\n",
      "Epoch: 22; total_step: 4050, loss: 1.6732687023261468, nll: 1.193669632459944\n",
      "Epoch: 22; total_step: 4100, loss: 1.6633212526828396, nll: 1.1273751818661195\n",
      "Epoch: 22; total_step: 4150, loss: 1.7342787859146258, nll: 1.2629503257603532\n",
      "Epoch: 22; total_step: 4200, loss: 1.656963991268923, nll: 1.2327504795755913\n",
      "Epoch: 23; total_step: 4250, loss: 1.6917077734867059, nll: 1.1091166989475567\n",
      "Epoch: 23; total_step: 4300, loss: 1.6527608603292925, nll: 1.0947439682023654\n",
      "Epoch: 23; total_step: 4350, loss: 1.7296693911919374, nll: 1.210114307282548\n",
      "Epoch: 24; total_step: 4400, loss: 1.778173025669097, nll: 1.2785062285638205\n",
      "Epoch: 24; total_step: 4450, loss: 1.7035380042200003, nll: 1.1123104601224525\n",
      "Epoch: 24; total_step: 4500, loss: 1.7097242013813057, nll: 1.2779410423745006\n",
      "Epoch: 24; total_step: 4550, loss: 1.6974031029687238, nll: 1.3401565248581495\n",
      "Epoch: 25; total_step: 4600, loss: 1.7214064464818986, nll: 1.1198977834670825\n",
      "Epoch: 25; total_step: 4650, loss: 1.7693220116175294, nll: 1.319201652854972\n",
      "Epoch: 25; total_step: 4700, loss: 1.698167596282999, nll: 1.2178273966251474\n",
      "Epoch: 25; total_step: 4750, loss: 1.7163633968476961, nll: 1.2054021552082987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26; total_step: 4800, loss: 1.7448775070806206, nll: 1.228376428952464\n",
      "Epoch: 26; total_step: 4850, loss: 1.7295344077222117, nll: 1.1685200588841367\n",
      "Epoch: 26; total_step: 4900, loss: 1.811709760842075, nll: 1.382430054376861\n",
      "Epoch: 27; total_step: 4950, loss: 1.692392587123844, nll: 1.1861558559440724\n",
      "Epoch: 27; total_step: 5000, loss: 1.7427730605154255, nll: 1.2575125157075808\n",
      "Epoch: 27; total_step: 5050, loss: 1.6830897841881893, nll: 1.1871210224906055\n",
      "Epoch: 27; total_step: 5100, loss: 1.666366889159417, nll: 1.2764668212755736\n",
      "Epoch: 28; total_step: 5150, loss: 1.6941104279969128, nll: 1.138501688200133\n",
      "Epoch: 28; total_step: 5200, loss: 1.7348677357795794, nll: 1.0439591575144858\n",
      "Epoch: 28; total_step: 5250, loss: 1.748910437134861, nll: 1.2215529890786316\n",
      "Epoch: 28; total_step: 5300, loss: 1.7103513295423136, nll: 1.3135744118448225\n",
      "Epoch: 29; total_step: 5350, loss: 1.7611931711175912, nll: 1.3148821875204073\n",
      "Epoch: 29; total_step: 5400, loss: 1.6237685446817047, nll: 1.0940159156071525\n",
      "Epoch: 29; total_step: 5450, loss: 1.7356813821949921, nll: 1.0731869877630809\n",
      "Epoch: 30; total_step: 5500, loss: 1.6681880174487533, nll: 1.1982911548937136\n",
      "Epoch: 30; total_step: 5550, loss: 1.6813660450188723, nll: 1.1921597421106316\n",
      "Epoch: 30; total_step: 5600, loss: 1.797991975787543, nll: 1.3019410791067156\n",
      "Epoch: 30; total_step: 5650, loss: 1.6888344705719458, nll: 1.3025709638195526\n",
      "Epoch: 31; total_step: 5700, loss: 1.7618728294988868, nll: 1.1163074144329541\n",
      "Epoch: 31; total_step: 5750, loss: 1.676828643637293, nll: 1.1238038328524698\n",
      "Epoch: 31; total_step: 5800, loss: 1.7245381905552468, nll: 1.2498919845016303\n",
      "Epoch: 31; total_step: 5850, loss: 1.82613965050705, nll: 1.3450484590833167\n",
      "Epoch: 32; total_step: 5900, loss: 1.710414013773207, nll: 1.1541596076743736\n",
      "Epoch: 32; total_step: 5950, loss: 1.7396694643400952, nll: 1.192970511147382\n",
      "Epoch: 32; total_step: 6000, loss: 1.705560239181247, nll: 1.249105604441299\n",
      "Epoch: 33; total_step: 6050, loss: 1.5537607771968727, nll: 1.131309687804067\n",
      "Epoch: 33; total_step: 6100, loss: 1.7197581749239148, nll: 1.2250200271373224\n",
      "Epoch: 33; total_step: 6150, loss: 1.7392690072144932, nll: 1.2206909317027923\n",
      "Epoch: 33; total_step: 6200, loss: 1.6998529224963028, nll: 1.1482578852377707\n",
      "Epoch: 34; total_step: 6250, loss: 1.6556124501345422, nll: 1.0863943724280039\n",
      "Epoch: 34; total_step: 6300, loss: 1.7010258693591793, nll: 1.1938156908706141\n",
      "Epoch: 34; total_step: 6350, loss: 1.7505236011787042, nll: 1.2681657060914224\n",
      "Epoch: 34; total_step: 6400, loss: 1.644081592130139, nll: 1.1558928994397937\n",
      "Epoch: 35; total_step: 6450, loss: 1.6845054875527796, nll: 1.1333635293792748\n",
      "Epoch: 35; total_step: 6500, loss: 1.7071406586575817, nll: 1.2387780439593972\n",
      "Epoch: 35; total_step: 6550, loss: 1.7196511301377004, nll: 1.211999044322968\n",
      "Epoch: 36; total_step: 6600, loss: 1.65542832398895, nll: 1.162442458579561\n",
      "Epoch: 36; total_step: 6650, loss: 1.6965561872766974, nll: 1.2715207055583393\n",
      "Epoch: 36; total_step: 6700, loss: 1.6499114726131596, nll: 1.0659002205019803\n",
      "Epoch: 36; total_step: 6750, loss: 1.7290975626917668, nll: 1.1841746526463672\n",
      "Epoch: 37; total_step: 6800, loss: 1.6986099380514574, nll: 1.2361909982788206\n",
      "Epoch: 37; total_step: 6850, loss: 1.6678293548245164, nll: 1.1527886632962323\n",
      "Epoch: 37; total_step: 6900, loss: 1.6568549536035448, nll: 1.1714587582263025\n",
      "Epoch: 37; total_step: 6950, loss: 1.78019521772013, nll: 1.2230758826378978\n",
      "Epoch: 38; total_step: 7000, loss: 1.6734603026101587, nll: 1.303456884679882\n",
      "Epoch: 38; total_step: 7050, loss: 1.6634601517332726, nll: 1.1735764098651316\n",
      "Epoch: 38; total_step: 7100, loss: 1.7043529803081305, nll: 1.328366649424933\n",
      "Epoch: 39; total_step: 7150, loss: 1.7440154766928335, nll: 1.1892270454464633\n",
      "Epoch: 39; total_step: 7200, loss: 1.6413415565151543, nll: 1.2448972888055625\n",
      "Epoch: 39; total_step: 7250, loss: 1.7044064462613966, nll: 1.1886485098956332\n",
      "Epoch: 39; total_step: 7300, loss: 1.7337265590233153, nll: 1.1645544100076557\n",
      "Epoch: 40; total_step: 7350, loss: 1.7706471520514782, nll: 1.3951515035124438\n",
      "Epoch: 40; total_step: 7400, loss: 1.8538562486088006, nll: 1.320083112549527\n",
      "Epoch: 40; total_step: 7450, loss: 1.7288335287832168, nll: 1.2090902919995632\n",
      "Epoch: 40; total_step: 7500, loss: 1.6073577731899036, nll: 1.054240799820004\n",
      "Epoch: 41; total_step: 7550, loss: 1.70820468941534, nll: 1.325902643661925\n",
      "Epoch: 41; total_step: 7600, loss: 1.6899248466366796, nll: 1.2281820778011248\n",
      "Epoch: 41; total_step: 7650, loss: 1.680636724652283, nll: 1.3097874714013051\n",
      "Epoch: 42; total_step: 7700, loss: 1.6902964258198634, nll: 1.0942529198988624\n",
      "Epoch: 42; total_step: 7750, loss: 1.6958214738914423, nll: 1.190347301274674\n",
      "Epoch: 42; total_step: 7800, loss: 1.7026088724987187, nll: 1.2285355834740403\n",
      "Epoch: 42; total_step: 7850, loss: 1.752653443369943, nll: 1.155936633168177\n",
      "Epoch: 43; total_step: 7900, loss: 1.7869072658774698, nll: 1.2614022122470112\n",
      "Epoch: 43; total_step: 7950, loss: 1.6872414557404005, nll: 1.150514151348979\n",
      "Epoch: 43; total_step: 8000, loss: 1.7200369185168978, nll: 1.1581118216993402\n",
      "Epoch: 43; total_step: 8050, loss: 1.7582506233180966, nll: 1.202904825875002\n",
      "Epoch: 44; total_step: 8100, loss: 1.6583617775812156, nll: 1.1170204779002073\n",
      "Epoch: 44; total_step: 8150, loss: 1.7265099033246003, nll: 1.2746933872075925\n",
      "Epoch: 44; total_step: 8200, loss: 1.8624199878905319, nll: 1.3380055705979292\n",
      "Epoch: 45; total_step: 8250, loss: 1.7448184419609083, nll: 1.1345595705155929\n",
      "Epoch: 45; total_step: 8300, loss: 1.6758981268582358, nll: 1.2693991348107163\n",
      "Epoch: 45; total_step: 8350, loss: 1.7647635824225045, nll: 1.1574691423228303\n",
      "Epoch: 45; total_step: 8400, loss: 1.7055983511739599, nll: 1.2452431527762142\n",
      "Epoch: 46; total_step: 8450, loss: 1.693974482103468, nll: 1.0800997017548066\n",
      "Epoch: 46; total_step: 8500, loss: 1.7463315195186684, nll: 1.265432543287843\n",
      "Epoch: 46; total_step: 8550, loss: 1.6889906142486177, nll: 1.2231324887599346\n",
      "Epoch: 46; total_step: 8600, loss: 1.6926010478244173, nll: 1.116825915061687\n",
      "Epoch: 47; total_step: 8650, loss: 1.6344838824217265, nll: 1.0439647857620287\n",
      "Epoch: 47; total_step: 8700, loss: 1.7280321487378794, nll: 1.1873078355277245\n",
      "Epoch: 47; total_step: 8750, loss: 1.6463267987150685, nll: 1.118435746385095\n",
      "Epoch: 48; total_step: 8800, loss: 1.6883439222673018, nll: 1.0754093729124046\n",
      "Epoch: 48; total_step: 8850, loss: 1.7900161385412787, nll: 1.2917252282825278\n",
      "Epoch: 48; total_step: 8900, loss: 1.7050452826080178, nll: 1.12214795358287\n",
      "Epoch: 48; total_step: 8950, loss: 1.731878418564346, nll: 1.1984211935089089\n",
      "Epoch: 49; total_step: 9000, loss: 1.6674822651817995, nll: 1.2473542584947845\n",
      "Epoch: 49; total_step: 9050, loss: 1.6354909079152522, nll: 1.1317559634819794\n",
      "Epoch: 49; total_step: 9100, loss: 1.6875680783433757, nll: 1.1972631058709882\n",
      "Epoch: 50; total_step: 9150, loss: 1.675310747836765, nll: 1.1956349542196045\n",
      "Epoch: 50; total_step: 9200, loss: 1.7191148347722278, nll: 1.2591094520084531\n",
      "Epoch: 50; total_step: 9250, loss: 1.7347445270952446, nll: 1.2650628976073621\n",
      "Epoch: 50; total_step: 9300, loss: 1.6441559637149181, nll: 1.1043653626543006\n",
      "Epoch: 51; total_step: 9350, loss: 1.7458179762733754, nll: 1.2750394607877193\n",
      "Epoch: 51; total_step: 9400, loss: 1.7461950325180906, nll: 1.26729670395555\n",
      "Epoch: 51; total_step: 9450, loss: 1.6542819385445728, nll: 1.1173987617983154\n",
      "Epoch: 51; total_step: 9500, loss: 1.633010334747069, nll: 1.1961604287173846\n",
      "Epoch: 52; total_step: 9550, loss: 1.7614122006198099, nll: 1.2242674934530067\n",
      "Epoch: 52; total_step: 9600, loss: 1.6490347328248718, nll: 1.1749698457128812\n",
      "Epoch: 52; total_step: 9650, loss: 1.716639987312692, nll: 1.0431715476639127\n",
      "Epoch: 53; total_step: 9700, loss: 1.6962965997928876, nll: 1.1470968368699779\n",
      "Epoch: 53; total_step: 9750, loss: 1.6272081353469188, nll: 1.0850348460817059\n",
      "Epoch: 53; total_step: 9800, loss: 1.6437490230198324, nll: 1.1653655661335\n",
      "Epoch: 53; total_step: 9850, loss: 1.758430042937111, nll: 1.194916267133295\n",
      "Epoch: 54; total_step: 9900, loss: 1.5520945541599058, nll: 1.1513125031184153\n",
      "Epoch: 54; total_step: 9950, loss: 1.6414945876461693, nll: 1.1266502173857311\n",
      "Epoch: 54; total_step: 10000, loss: 1.6636359146282367, nll: 1.1262656029741258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54; total_step: 10050, loss: 1.683944287462075, nll: 1.1455930719718024\n",
      "Epoch: 55; total_step: 10100, loss: 1.7241085559416638, nll: 1.2253638806913039\n",
      "Epoch: 55; total_step: 10150, loss: 1.6913757986355749, nll: 1.1715421089006646\n",
      "Epoch: 55; total_step: 10200, loss: 1.7375651658250524, nll: 1.2774907954040842\n",
      "Epoch: 56; total_step: 10250, loss: 1.755276766986123, nll: 1.2822625603634665\n",
      "Epoch: 56; total_step: 10300, loss: 1.7447717550050812, nll: 1.2701551705130676\n",
      "Epoch: 56; total_step: 10350, loss: 1.6392187509639167, nll: 1.1063815864500415\n",
      "Epoch: 56; total_step: 10400, loss: 1.7343976360619784, nll: 1.239116003956521\n",
      "Epoch: 57; total_step: 10450, loss: 1.6621883878759558, nll: 1.0972228048560044\n",
      "Epoch: 57; total_step: 10500, loss: 1.7868958575066693, nll: 1.3436551498300513\n",
      "Epoch: 57; total_step: 10550, loss: 1.626368565383674, nll: 1.0973712976199022\n",
      "Epoch: 57; total_step: 10600, loss: 1.6324383978841366, nll: 1.0990986913284568\n",
      "Epoch: 58; total_step: 10650, loss: 1.683897215241313, nll: 1.209828769053928\n",
      "Epoch: 58; total_step: 10700, loss: 1.7526584730890078, nll: 1.3037216822438786\n",
      "Epoch: 58; total_step: 10750, loss: 1.705051911791536, nll: 1.26334895188832\n",
      "Epoch: 59; total_step: 10800, loss: 1.7529632325980549, nll: 1.201913971014146\n",
      "Epoch: 59; total_step: 10850, loss: 1.673921345526791, nll: 1.073417944413234\n",
      "Epoch: 59; total_step: 10900, loss: 1.6692099536036165, nll: 1.1152750739408714\n",
      "Epoch: 59; total_step: 10950, loss: 1.7342303212541115, nll: 1.2584438231100992\n",
      "Epoch: 60; total_step: 11000, loss: 1.694811903262618, nll: 1.1095782661379336\n",
      "Epoch: 60; total_step: 11050, loss: 1.6776338191393967, nll: 1.2030460131505247\n",
      "Epoch: 60; total_step: 11100, loss: 1.7283613146014363, nll: 1.177041386464468\n",
      "Epoch: 60; total_step: 11150, loss: 1.7048869801026614, nll: 1.1708579033727065\n",
      "Epoch: 61; total_step: 11200, loss: 1.8197162275622736, nll: 1.370065501545654\n",
      "Epoch: 61; total_step: 11250, loss: 1.6621130498367735, nll: 1.1710264195554991\n",
      "Epoch: 61; total_step: 11300, loss: 1.6852191166647645, nll: 1.1302781153291115\n",
      "Epoch: 62; total_step: 11350, loss: 1.7150213698225045, nll: 1.1797489216812163\n",
      "Epoch: 62; total_step: 11400, loss: 1.8339888215311033, nll: 1.3208370829912313\n",
      "Epoch: 62; total_step: 11450, loss: 1.6824841093076695, nll: 1.260352421631937\n",
      "Epoch: 62; total_step: 11500, loss: 1.6651191047988072, nll: 1.2136911270823316\n",
      "Epoch: 63; total_step: 11550, loss: 1.7796691416438772, nll: 1.1748476971422062\n",
      "Epoch: 63; total_step: 11600, loss: 1.6154826155652995, nll: 1.1367975611932586\n",
      "Epoch: 63; total_step: 11650, loss: 1.6747218612299704, nll: 1.0911711336277985\n",
      "Epoch: 63; total_step: 11700, loss: 1.645826916038784, nll: 1.1252955671159026\n",
      "Epoch: 64; total_step: 11750, loss: 1.7242650357676021, nll: 1.1589018669438076\n",
      "Epoch: 64; total_step: 11800, loss: 1.6872664743009422, nll: 1.1571097057317008\n",
      "Epoch: 64; total_step: 11850, loss: 1.654395883900516, nll: 1.0906977961452657\n",
      "Epoch: 65; total_step: 11900, loss: 1.6821407016756735, nll: 1.1810256659851766\n",
      "Epoch: 65; total_step: 11950, loss: 1.6410439276305255, nll: 0.9988994705975227\n",
      "Epoch: 65; total_step: 12000, loss: 1.7623966989003081, nll: 1.2569140883540924\n",
      "Epoch: 65; total_step: 12050, loss: 1.7045085304978098, nll: 1.260562933928201\n",
      "Epoch: 66; total_step: 12100, loss: 1.698605373350901, nll: 1.1725421279693535\n",
      "Epoch: 66; total_step: 12150, loss: 1.7297894878995168, nll: 1.207380429015382\n",
      "Epoch: 66; total_step: 12200, loss: 1.6871515574886466, nll: 1.2240620692835587\n",
      "Epoch: 66; total_step: 12250, loss: 1.6397977905695222, nll: 1.1962475111580888\n",
      "Epoch: 67; total_step: 12300, loss: 1.6652224927103898, nll: 1.11668127184249\n",
      "Epoch: 67; total_step: 12350, loss: 1.7690392517936102, nll: 1.2486793339949498\n",
      "Epoch: 67; total_step: 12400, loss: 1.6699386412566097, nll: 1.078727120905663\n",
      "Epoch: 68; total_step: 12450, loss: 1.7245428640142697, nll: 1.2441101544790902\n",
      "Epoch: 68; total_step: 12500, loss: 1.6784246110321568, nll: 1.219982076321621\n",
      "Epoch: 68; total_step: 12550, loss: 1.6149400770706257, nll: 1.0578847445245996\n",
      "Epoch: 68; total_step: 12600, loss: 1.7190578676680681, nll: 1.3943579570384856\n",
      "Epoch: 69; total_step: 12650, loss: 1.7233983626710296, nll: 1.235629183665824\n",
      "Epoch: 69; total_step: 12700, loss: 1.7067090573073205, nll: 1.2125419966595428\n",
      "Epoch: 69; total_step: 12750, loss: 1.6229910051844083, nll: 1.185400267770475\n",
      "Epoch: 69; total_step: 12800, loss: 1.663613859991788, nll: 1.3102201424462172\n",
      "Epoch: 70; total_step: 12850, loss: 1.642833813228677, nll: 1.084996395187662\n",
      "Epoch: 70; total_step: 12900, loss: 1.7036601152751496, nll: 1.0864821829839426\n",
      "Epoch: 70; total_step: 12950, loss: 1.7178066708896973, nll: 1.1512523111491468\n",
      "Epoch: 71; total_step: 13000, loss: 1.6804696013587423, nll: 1.1005843434754905\n",
      "Epoch: 71; total_step: 13050, loss: 1.6487187274164798, nll: 1.1405809815436647\n",
      "Epoch: 71; total_step: 13100, loss: 1.7149780314544467, nll: 1.020314626723004\n",
      "Epoch: 71; total_step: 13150, loss: 1.6942533794261825, nll: 1.098422801017826\n",
      "Epoch: 72; total_step: 13200, loss: 1.7239362864131085, nll: 1.1276724479531328\n",
      "Epoch: 72; total_step: 13250, loss: 1.6918126783740284, nll: 1.2595980028915348\n",
      "Epoch: 72; total_step: 13300, loss: 1.576122814247721, nll: 1.0865565399625965\n",
      "Epoch: 72; total_step: 13350, loss: 1.6588907551484013, nll: 1.1289272328896303\n",
      "Epoch: 73; total_step: 13400, loss: 1.7256464034693306, nll: 1.129536571893373\n",
      "Epoch: 73; total_step: 13450, loss: 1.6713619802069823, nll: 1.0959179428152142\n",
      "Epoch: 73; total_step: 13500, loss: 1.679922153677952, nll: 1.238275006175699\n",
      "Epoch: 74; total_step: 13550, loss: 1.7290138979903045, nll: 1.1693230455161798\n",
      "Epoch: 74; total_step: 13600, loss: 1.7032814888724068, nll: 1.2197491779250165\n",
      "Epoch: 74; total_step: 13650, loss: 1.6350500892716906, nll: 1.213135291919644\n",
      "Epoch: 74; total_step: 13700, loss: 1.653573605194228, nll: 1.2066954351850583\n",
      "Epoch: 75; total_step: 13750, loss: 1.6003688458394865, nll: 1.0556682028368656\n",
      "Epoch: 75; total_step: 13800, loss: 1.6557402145236808, nll: 1.058786650100153\n",
      "Epoch: 75; total_step: 13850, loss: 1.7103547083009654, nll: 1.2550463846637594\n",
      "Epoch: 75; total_step: 13900, loss: 1.699433162209661, nll: 1.1681484855196018\n",
      "Epoch: 76; total_step: 13950, loss: 1.7422521617018736, nll: 1.2646676771988579\n",
      "Epoch: 76; total_step: 14000, loss: 1.660313968323633, nll: 1.15574334210243\n",
      "Epoch: 76; total_step: 14050, loss: 1.6707167878733475, nll: 1.052124415979436\n",
      "Epoch: 77; total_step: 14100, loss: 1.7172654919319927, nll: 1.1914419588696605\n",
      "Epoch: 77; total_step: 14150, loss: 1.7121280986845802, nll: 1.245555462276437\n",
      "Epoch: 77; total_step: 14200, loss: 1.7270553043527872, nll: 1.134193195314353\n",
      "Epoch: 77; total_step: 14250, loss: 1.6765433095183229, nll: 1.2771701087894738\n",
      "Epoch: 78; total_step: 14300, loss: 1.6949642713473236, nll: 1.1882883285703931\n",
      "Epoch: 78; total_step: 14350, loss: 1.6948696822986218, nll: 1.1458096064946939\n",
      "Epoch: 78; total_step: 14400, loss: 1.6482492873122105, nll: 1.1225722653622547\n",
      "Epoch: 78; total_step: 14450, loss: 1.6923449453418373, nll: 1.1103625799326684\n",
      "Epoch: 79; total_step: 14500, loss: 1.7305636906569402, nll: 1.2239115919563768\n",
      "Epoch: 79; total_step: 14550, loss: 1.702833339521244, nll: 1.161060927341487\n",
      "Epoch: 79; total_step: 14600, loss: 1.7650551414437978, nll: 1.1813126221693957\n",
      "Epoch: 80; total_step: 14650, loss: 1.6503539769319093, nll: 1.0860985177915006\n",
      "Epoch: 80; total_step: 14700, loss: 1.6196087715768157, nll: 1.158503826098457\n",
      "Epoch: 80; total_step: 14750, loss: 1.6771081328469277, nll: 1.2141508170632775\n",
      "Epoch: 80; total_step: 14800, loss: 1.7052480426894476, nll: 1.1878762705893746\n",
      "Epoch: 81; total_step: 14850, loss: 1.6007048593022435, nll: 1.0910625090996646\n",
      "Epoch: 81; total_step: 14900, loss: 1.665559453640256, nll: 1.1515355421194648\n",
      "Epoch: 81; total_step: 14950, loss: 1.775764206444194, nll: 1.296150569113956\n",
      "Epoch: 81; total_step: 15000, loss: 1.7516440489908465, nll: 1.2437443148289642\n",
      "Epoch: 82; total_step: 15050, loss: 1.6751015110822505, nll: 1.1730971940906494\n",
      "Epoch: 82; total_step: 15100, loss: 1.6584479369337035, nll: 1.1813495029404202\n",
      "Epoch: 82; total_step: 15150, loss: 1.7898079441509254, nll: 1.3988790310902293\n",
      "Epoch: 83; total_step: 15200, loss: 1.7437460624818477, nll: 1.1417097452881406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83; total_step: 15250, loss: 1.642103653343142, nll: 1.1113121257106724\n",
      "Epoch: 83; total_step: 15300, loss: 1.7322053234608799, nll: 1.2253664063789735\n",
      "Epoch: 83; total_step: 15350, loss: 1.6233499505501832, nll: 1.0823552269298509\n",
      "Epoch: 84; total_step: 15400, loss: 1.6259340153113597, nll: 1.119461632570883\n",
      "Epoch: 84; total_step: 15450, loss: 1.7138841837811463, nll: 1.1334451983895553\n",
      "Epoch: 84; total_step: 15500, loss: 1.7489625400313826, nll: 1.0899744846229567\n",
      "Epoch: 84; total_step: 15550, loss: 1.7258607077697001, nll: 1.1745224667347356\n",
      "Epoch: 85; total_step: 15600, loss: 1.713451340484097, nll: 1.215503264052656\n",
      "Epoch: 85; total_step: 15650, loss: 1.6894471738946453, nll: 1.2157102720478359\n",
      "Epoch: 85; total_step: 15700, loss: 1.6481538128073072, nll: 1.1193411432148705\n",
      "Epoch: 86; total_step: 15750, loss: 1.7048552161969206, nll: 1.2918868079802652\n",
      "Epoch: 86; total_step: 15800, loss: 1.686216654788056, nll: 1.1615281163865658\n",
      "Epoch: 86; total_step: 15850, loss: 1.738044850718495, nll: 1.097388758526979\n",
      "Epoch: 86; total_step: 15900, loss: 1.631088875248079, nll: 1.0603903009317817\n",
      "Epoch: 87; total_step: 15950, loss: 1.820929951071284, nll: 1.4646627880568672\n",
      "Epoch: 87; total_step: 16000, loss: 1.7145798898403444, nll: 1.2458899208917986\n",
      "Epoch: 87; total_step: 16050, loss: 1.716703169396258, nll: 1.2795935141938704\n",
      "Epoch: 87; total_step: 16100, loss: 1.688512631665899, nll: 1.1878508154061764\n",
      "Epoch: 88; total_step: 16150, loss: 1.6787608431932364, nll: 1.0915186788371296\n",
      "Epoch: 88; total_step: 16200, loss: 1.683456619669426, nll: 1.0565591005433783\n",
      "Epoch: 88; total_step: 16250, loss: 1.7093418504231082, nll: 1.207382592066137\n",
      "Epoch: 89; total_step: 16300, loss: 1.7607300660045828, nll: 1.0877775608767706\n",
      "Epoch: 89; total_step: 16350, loss: 1.6745536698831769, nll: 1.2557953639711443\n",
      "Epoch: 89; total_step: 16400, loss: 1.6490678181601481, nll: 1.0979179680805495\n",
      "Epoch: 89; total_step: 16450, loss: 1.5527610272269183, nll: 1.0823944869873863\n",
      "Epoch: 90; total_step: 16500, loss: 1.5816534798486543, nll: 1.0176141886051184\n",
      "Epoch: 90; total_step: 16550, loss: 1.7078295554396834, nll: 1.1882569854815326\n",
      "Epoch: 90; total_step: 16600, loss: 1.7273099015918796, nll: 1.1216874956506904\n",
      "Epoch: 90; total_step: 16650, loss: 1.683182659870517, nll: 1.0932140191385336\n",
      "Epoch: 91; total_step: 16700, loss: 1.6704151568283556, nll: 1.158245110030435\n",
      "Epoch: 91; total_step: 16750, loss: 1.6246986573640547, nll: 1.1273395486634714\n",
      "Epoch: 91; total_step: 16800, loss: 1.6528271739663984, nll: 1.092060865628133\n",
      "Epoch: 92; total_step: 16850, loss: 1.6931699207531536, nll: 1.0698317816385665\n",
      "Epoch: 92; total_step: 16900, loss: 1.7072502314818956, nll: 1.3289532466072969\n",
      "Epoch: 92; total_step: 16950, loss: 1.6559641251108987, nll: 1.0775057048830556\n",
      "Epoch: 92; total_step: 17000, loss: 1.6997406545185685, nll: 1.2139541462046133\n",
      "Epoch: 93; total_step: 17050, loss: 1.7372734088698376, nll: 1.0831396443771757\n",
      "Epoch: 93; total_step: 17100, loss: 1.6373706953883451, nll: 1.0493580926009611\n",
      "Epoch: 93; total_step: 17150, loss: 1.7188839869285928, nll: 1.358776319641139\n",
      "Epoch: 93; total_step: 17200, loss: 1.7515809929415393, nll: 1.185236544349854\n",
      "Epoch: 94; total_step: 17250, loss: 1.692937806729152, nll: 1.127813451392914\n",
      "Epoch: 94; total_step: 17300, loss: 1.7614887612374497, nll: 1.3921276056555245\n",
      "Epoch: 94; total_step: 17350, loss: 1.6924972529169968, nll: 1.2694518484660053\n",
      "Epoch: 95; total_step: 17400, loss: 1.6368444804652509, nll: 1.1927099000434782\n",
      "Epoch: 95; total_step: 17450, loss: 1.6319778724483427, nll: 1.1476605863585876\n",
      "Epoch: 95; total_step: 17500, loss: 1.711103821658534, nll: 1.1891917980565383\n",
      "Epoch: 95; total_step: 17550, loss: 1.7164543869480964, nll: 1.2671847446984146\n",
      "Epoch: 96; total_step: 17600, loss: 1.7027707856727679, nll: 1.2824044284763998\n",
      "Epoch: 96; total_step: 17650, loss: 1.6606074542975, nll: 1.117050940092744\n",
      "Epoch: 96; total_step: 17700, loss: 1.62155828055651, nll: 1.030111602778897\n",
      "Epoch: 96; total_step: 17750, loss: 1.664322605497379, nll: 1.18362763634582\n",
      "Epoch: 97; total_step: 17800, loss: 1.7147317723741637, nll: 1.2806670891887417\n",
      "Epoch: 97; total_step: 17850, loss: 1.6631708905853215, nll: 1.1171433465318106\n",
      "Epoch: 97; total_step: 17900, loss: 1.6441980607886089, nll: 1.2239286398357054\n",
      "Epoch: 98; total_step: 17950, loss: 1.6922015293315165, nll: 1.1608760724398965\n",
      "Epoch: 98; total_step: 18000, loss: 1.70361120570363, nll: 1.2242836750411399\n",
      "Epoch: 98; total_step: 18050, loss: 1.6311291543370832, nll: 1.1417041648144999\n",
      "Epoch: 98; total_step: 18100, loss: 1.7055534254230793, nll: 1.137531075678261\n",
      "Epoch: 99; total_step: 18150, loss: 1.7405442975894614, nll: 1.3186963260851519\n",
      "Epoch: 99; total_step: 18200, loss: 1.666703803331326, nll: 1.1377948779755234\n",
      "Epoch: 99; total_step: 18250, loss: 1.7175431501480694, nll: 1.1478126124983952\n",
      "Epoch: 100; total_step: 18300, loss: 1.7555824458644052, nll: 1.2284671179169195\n",
      "Epoch: 100; total_step: 18350, loss: 1.666302136524061, nll: 1.1862417438493573\n",
      "Epoch: 100; total_step: 18400, loss: 1.7516785150841656, nll: 1.1819177441149724\n",
      "Epoch: 100; total_step: 18450, loss: 1.6682721850705113, nll: 1.127637949387345\n",
      "Epoch: 101; total_step: 18500, loss: 1.678921613389282, nll: 1.286236709214211\n",
      "Epoch: 101; total_step: 18550, loss: 1.6580610316922315, nll: 1.1230450200476165\n",
      "Epoch: 101; total_step: 18600, loss: 1.7041982142909484, nll: 1.1149002942458894\n",
      "Epoch: 101; total_step: 18650, loss: 1.7102125066909875, nll: 1.1966228439979674\n",
      "Epoch: 102; total_step: 18700, loss: 1.7488434289441583, nll: 1.2611440792454751\n",
      "Epoch: 102; total_step: 18750, loss: 1.7298356265267327, nll: 1.1286580008906124\n",
      "Epoch: 102; total_step: 18800, loss: 1.6845471910233452, nll: 1.149666899188137\n",
      "Epoch: 103; total_step: 18850, loss: 1.6699921732369043, nll: 1.209471682083639\n",
      "Epoch: 103; total_step: 18900, loss: 1.65337793318269, nll: 1.081253123130061\n",
      "Epoch: 103; total_step: 18950, loss: 1.6379359778015317, nll: 0.9445848818473709\n",
      "Epoch: 103; total_step: 19000, loss: 1.694562842348148, nll: 1.0684944470129938\n",
      "Epoch: 104; total_step: 19050, loss: 1.7168604322926562, nll: 1.209866008878865\n",
      "Epoch: 104; total_step: 19100, loss: 1.6681024497682722, nll: 1.124594716537316\n",
      "Epoch: 104; total_step: 19150, loss: 1.6913035578847502, nll: 1.2320234590007122\n",
      "Epoch: 104; total_step: 19200, loss: 1.6724381768098635, nll: 1.1786347811619573\n",
      "Epoch: 105; total_step: 19250, loss: 1.7656210017540959, nll: 1.2603378475598517\n",
      "Epoch: 105; total_step: 19300, loss: 1.6939596376334303, nll: 1.2231279973303315\n",
      "Epoch: 105; total_step: 19350, loss: 1.6395383985194392, nll: 1.0392442656018197\n",
      "Epoch: 106; total_step: 19400, loss: 1.6360072661785496, nll: 1.1880436767705171\n",
      "Epoch: 106; total_step: 19450, loss: 1.6878093144183888, nll: 1.1272579466519712\n",
      "Epoch: 106; total_step: 19500, loss: 1.6752797681341434, nll: 1.0468563972149394\n",
      "Epoch: 106; total_step: 19550, loss: 1.684351909741774, nll: 1.2172838312865109\n",
      "Epoch: 107; total_step: 19600, loss: 1.626878209131403, nll: 1.1658520764081355\n",
      "Epoch: 107; total_step: 19650, loss: 1.6899322158207708, nll: 1.139365161732771\n",
      "Epoch: 107; total_step: 19700, loss: 1.6401959747748633, nll: 1.1657047020140916\n",
      "Epoch: 107; total_step: 19750, loss: 1.6223832689458286, nll: 1.0669714556413017\n",
      "Epoch: 108; total_step: 19800, loss: 1.6327179461791435, nll: 1.0875373061893967\n",
      "Epoch: 108; total_step: 19850, loss: 1.6692009151535387, nll: 1.2136727421434015\n",
      "Epoch: 108; total_step: 19900, loss: 1.7809788816236047, nll: 1.3303731192832544\n",
      "Epoch: 109; total_step: 19950, loss: 1.6889096410523243, nll: 1.1808205271543035\n",
      "Epoch: 109; total_step: 20000, loss: 1.6404702924003538, nll: 1.1194092810190146\n",
      "Epoch: 109; total_step: 20050, loss: 1.729443377716678, nll: 1.3576031226277234\n",
      "Epoch: 109; total_step: 20100, loss: 1.6679542268282272, nll: 1.2703585897921876\n",
      "Epoch: 110; total_step: 20150, loss: 1.6559900052254275, nll: 1.0539224683742483\n",
      "Epoch: 110; total_step: 20200, loss: 1.6986877701885965, nll: 1.206507750913044\n",
      "Epoch: 110; total_step: 20250, loss: 1.6605151531664446, nll: 1.086374169003589\n",
      "Epoch: 110; total_step: 20300, loss: 1.7592805581601167, nll: 1.3186769743865931\n",
      "Epoch: 111; total_step: 20350, loss: 1.6433139727076795, nll: 1.177929592809352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 111; total_step: 20400, loss: 1.6526005489857227, nll: 1.16984054445232\n",
      "Epoch: 111; total_step: 20450, loss: 1.6718787571053317, nll: 1.1861078752555883\n",
      "Epoch: 112; total_step: 20500, loss: 1.6403043225541574, nll: 1.08286728651369\n",
      "Epoch: 112; total_step: 20550, loss: 1.7473723680390862, nll: 1.3263652871100426\n",
      "Epoch: 112; total_step: 20600, loss: 1.6658656773212916, nll: 1.1074644433451533\n",
      "Epoch: 112; total_step: 20650, loss: 1.6390595373601426, nll: 1.0669749518612999\n",
      "Epoch: 113; total_step: 20700, loss: 1.6756352322305827, nll: 1.217395595878732\n",
      "Epoch: 113; total_step: 20750, loss: 1.6874334797938417, nll: 1.180280770517902\n",
      "Epoch: 113; total_step: 20800, loss: 1.6339642435977704, nll: 1.0903632158203156\n",
      "Epoch: 113; total_step: 20850, loss: 1.6520517608821939, nll: 1.07320693886611\n",
      "Epoch: 114; total_step: 20900, loss: 1.6760921897707726, nll: 1.1495840587679034\n",
      "Epoch: 114; total_step: 20950, loss: 1.6690577292133713, nll: 1.146618734834777\n",
      "Epoch: 114; total_step: 21000, loss: 1.6765913755063884, nll: 1.2846214478568092\n",
      "Epoch: 115; total_step: 21050, loss: 1.698339749825096, nll: 1.2481118525440082\n",
      "Epoch: 115; total_step: 21100, loss: 1.7148225810820912, nll: 1.28046628050618\n",
      "Epoch: 115; total_step: 21150, loss: 1.6604876960589297, nll: 1.219846669554422\n",
      "Epoch: 115; total_step: 21200, loss: 1.714146021147927, nll: 1.2416880673289756\n",
      "Epoch: 116; total_step: 21250, loss: 1.7361520413776657, nll: 1.2208067175395816\n",
      "Epoch: 116; total_step: 21300, loss: 1.757972254118295, nll: 1.0881086764763792\n",
      "Epoch: 116; total_step: 21350, loss: 1.6812518830399636, nll: 1.2568408165875138\n",
      "Epoch: 116; total_step: 21400, loss: 1.7431073019453263, nll: 1.198656783471714\n",
      "Epoch: 117; total_step: 21450, loss: 1.6603130093691805, nll: 1.0360193345677648\n",
      "Epoch: 117; total_step: 21500, loss: 1.6708314036758287, nll: 1.07028242547217\n",
      "Epoch: 117; total_step: 21550, loss: 1.696235732105602, nll: 1.269469104300569\n",
      "Epoch: 118; total_step: 21600, loss: 1.776680570413098, nll: 1.2781455512711948\n",
      "Epoch: 118; total_step: 21650, loss: 1.7164348264998068, nll: 1.1860738917958062\n",
      "Epoch: 118; total_step: 21700, loss: 1.6291097552801677, nll: 1.1042835166051077\n",
      "Epoch: 118; total_step: 21750, loss: 1.676664547453712, nll: 1.1667135235753112\n",
      "Epoch: 119; total_step: 21800, loss: 1.844259306603269, nll: 1.3330172258084683\n",
      "Epoch: 119; total_step: 21850, loss: 1.747825960365199, nll: 1.2233486351773808\n",
      "Epoch: 119; total_step: 21900, loss: 1.6974009916861388, nll: 1.134026806421118\n",
      "Epoch: 119; total_step: 21950, loss: 1.642908293397336, nll: 1.06917620330064\n",
      "Epoch: 120; total_step: 22000, loss: 1.6857314849107072, nll: 1.2286205029264592\n",
      "Epoch: 120; total_step: 22050, loss: 1.7216064527588246, nll: 1.2246023421746983\n",
      "Epoch: 120; total_step: 22100, loss: 1.6746228450514302, nll: 1.0914158992145047\n",
      "Epoch: 121; total_step: 22150, loss: 1.6061916648698085, nll: 1.1066703507810702\n",
      "Epoch: 121; total_step: 22200, loss: 1.6894048834286628, nll: 1.1982178624990276\n",
      "Epoch: 121; total_step: 22250, loss: 1.7206388032150688, nll: 1.2349287120119565\n",
      "Epoch: 121; total_step: 22300, loss: 1.7139229923226025, nll: 1.3727273399270397\n",
      "Epoch: 122; total_step: 22350, loss: 1.722881853116221, nll: 1.1532719293031872\n",
      "Epoch: 122; total_step: 22400, loss: 1.6434745417634244, nll: 1.1320790133945418\n",
      "Epoch: 122; total_step: 22450, loss: 1.670315977832454, nll: 1.2443502213402426\n",
      "Epoch: 122; total_step: 22500, loss: 1.7055987633720266, nll: 1.3380409096722046\n",
      "Epoch: 123; total_step: 22550, loss: 1.6531673685248938, nll: 1.1288172606083209\n",
      "Epoch: 123; total_step: 22600, loss: 1.648746937077376, nll: 1.0625862775715094\n",
      "Epoch: 123; total_step: 22650, loss: 1.740315400730369, nll: 1.2565945865411465\n",
      "Epoch: 124; total_step: 22700, loss: 1.662452661154791, nll: 1.1611680233272825\n",
      "Epoch: 124; total_step: 22750, loss: 1.6324755673889506, nll: 1.1725499166751896\n",
      "Epoch: 124; total_step: 22800, loss: 1.7192724091991247, nll: 1.318466356896892\n",
      "Epoch: 124; total_step: 22850, loss: 1.7250813426390539, nll: 1.2671155690408225\n",
      "Epoch: 125; total_step: 22900, loss: 1.7214067968470368, nll: 1.2425293585787232\n",
      "Epoch: 125; total_step: 22950, loss: 1.647934099037904, nll: 1.108651068550619\n",
      "Epoch: 125; total_step: 23000, loss: 1.6606598770954923, nll: 1.1259997802181785\n",
      "Epoch: 125; total_step: 23050, loss: 1.763660935413112, nll: 1.2089029672009282\n",
      "Epoch: 126; total_step: 23100, loss: 1.6517888657848192, nll: 1.1165704746281653\n",
      "Epoch: 126; total_step: 23150, loss: 1.6436692683463732, nll: 1.2148678021910841\n",
      "Epoch: 126; total_step: 23200, loss: 1.6421184811227965, nll: 1.0589106686566465\n",
      "Epoch: 127; total_step: 23250, loss: 1.6787447098279338, nll: 1.2314871444692215\n",
      "Epoch: 127; total_step: 23300, loss: 1.6205971820954943, nll: 1.1653643601154138\n",
      "Epoch: 127; total_step: 23350, loss: 1.727107646629445, nll: 1.2843834231339601\n",
      "Epoch: 127; total_step: 23400, loss: 1.6582017828383442, nll: 1.2609275701921434\n",
      "Epoch: 128; total_step: 23450, loss: 1.6649759993750348, nll: 1.1756506599272862\n",
      "Epoch: 128; total_step: 23500, loss: 1.7886322750815389, nll: 1.2412654827593854\n",
      "Epoch: 128; total_step: 23550, loss: 1.725657093154494, nll: 1.117095921883697\n",
      "Epoch: 128; total_step: 23600, loss: 1.722662457148881, nll: 1.3115750542168898\n",
      "Epoch: 129; total_step: 23650, loss: 1.602570225553309, nll: 1.0550428075742015\n",
      "Epoch: 129; total_step: 23700, loss: 1.7185420832635294, nll: 1.0731395474500887\n",
      "Epoch: 129; total_step: 23750, loss: 1.6294894703015053, nll: 1.1133908672948818\n",
      "Epoch: 130; total_step: 23800, loss: 1.6682244378444637, nll: 1.1316800516192482\n",
      "Epoch: 130; total_step: 23850, loss: 1.6015576413637576, nll: 1.1355548496735228\n",
      "Epoch: 130; total_step: 23900, loss: 1.7264948914969234, nll: 1.2549325747612836\n",
      "Epoch: 130; total_step: 23950, loss: 1.689382026075255, nll: 1.2643495827393203\n",
      "Epoch: 131; total_step: 24000, loss: 1.6208600304367733, nll: 1.093950133225611\n",
      "Epoch: 131; total_step: 24050, loss: 1.7567437063564344, nll: 1.3175488087545124\n",
      "Epoch: 131; total_step: 24100, loss: 1.5907645031703093, nll: 1.000011777077318\n",
      "Epoch: 131; total_step: 24150, loss: 1.6902131688275306, nll: 1.3055076653598339\n",
      "Epoch: 132; total_step: 24200, loss: 1.636811282516881, nll: 1.057584274837107\n",
      "Epoch: 132; total_step: 24250, loss: 1.6512175663519486, nll: 1.145433450242469\n",
      "Epoch: 132; total_step: 24300, loss: 1.728968412949526, nll: 1.2486437383858786\n",
      "Epoch: 133; total_step: 24350, loss: 1.7800279919179542, nll: 1.0432435561580187\n",
      "Epoch: 133; total_step: 24400, loss: 1.6495837146066983, nll: 1.1637902987041895\n",
      "Epoch: 133; total_step: 24450, loss: 1.6436755431483485, nll: 1.1680168363008923\n",
      "Epoch: 133; total_step: 24500, loss: 1.593032231524156, nll: 1.0957561301923\n",
      "Epoch: 134; total_step: 24550, loss: 1.7147884204985133, nll: 1.01740895136349\n",
      "Epoch: 134; total_step: 24600, loss: 1.6810615994361064, nll: 1.0406447852853937\n",
      "Epoch: 134; total_step: 24650, loss: 1.5879890479225933, nll: 1.0339580202236167\n",
      "Epoch: 134; total_step: 24700, loss: 1.7615115432784978, nll: 1.3210798159720445\n",
      "Epoch: 135; total_step: 24750, loss: 1.6537112369373035, nll: 1.1756764142050384\n",
      "Epoch: 135; total_step: 24800, loss: 1.7145036075093345, nll: 1.2064848560589243\n",
      "Epoch: 135; total_step: 24850, loss: 1.7454354741055016, nll: 1.2043079669278107\n",
      "Epoch: 136; total_step: 24900, loss: 1.653604385936029, nll: 1.1594638288077765\n",
      "Epoch: 136; total_step: 24950, loss: 1.6626303439704992, nll: 1.1463328709502505\n",
      "Epoch: 136; total_step: 25000, loss: 1.6541751466789254, nll: 1.1644216905118918\n",
      "Epoch: 136; total_step: 25050, loss: 1.6531111875311462, nll: 1.1263504776903708\n",
      "Epoch: 137; total_step: 25100, loss: 1.6745630395046307, nll: 1.1296232738331748\n",
      "Epoch: 137; total_step: 25150, loss: 1.6698001080848957, nll: 1.1318554831133754\n",
      "Epoch: 137; total_step: 25200, loss: 1.6319943683523632, nll: 1.0974261829588519\n",
      "Epoch: 137; total_step: 25250, loss: 1.6549617574947648, nll: 1.1341852468982412\n",
      "Epoch: 138; total_step: 25300, loss: 1.762763057377405, nll: 1.3267033824283785\n",
      "Epoch: 138; total_step: 25350, loss: 1.7249998259350086, nll: 1.1375595613360756\n",
      "Epoch: 138; total_step: 25400, loss: 1.6628434609566853, nll: 1.1327022814304062\n",
      "Epoch: 139; total_step: 25450, loss: 1.641913471252962, nll: 1.1226420724847146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 139; total_step: 25500, loss: 1.6202665464037507, nll: 1.0951962006239213\n",
      "Epoch: 139; total_step: 25550, loss: 1.6996850537069441, nll: 1.1633291253266993\n",
      "Epoch: 139; total_step: 25600, loss: 1.710704337025918, nll: 1.2570150092358443\n",
      "Epoch: 140; total_step: 25650, loss: 1.7129344365035122, nll: 1.2505761874982422\n",
      "Epoch: 140; total_step: 25700, loss: 1.6887521455398686, nll: 1.1578702375331484\n",
      "Epoch: 140; total_step: 25750, loss: 1.6857118872642243, nll: 1.0390673596321942\n",
      "Epoch: 140; total_step: 25800, loss: 1.6954566823983424, nll: 1.1709477064619231\n",
      "Epoch: 141; total_step: 25850, loss: 1.6690170242458644, nll: 1.0583071371230581\n",
      "Epoch: 141; total_step: 25900, loss: 1.7276863037201666, nll: 1.2069689646169652\n",
      "Epoch: 141; total_step: 25950, loss: 1.7142917408678724, nll: 1.1788582862331456\n",
      "Epoch: 142; total_step: 26000, loss: 1.643791453429493, nll: 1.0950508691689702\n",
      "Epoch: 142; total_step: 26050, loss: 1.779791659769582, nll: 1.2315456353885899\n",
      "Epoch: 142; total_step: 26100, loss: 1.637547115729122, nll: 1.191522211800813\n",
      "Epoch: 142; total_step: 26150, loss: 1.691873069903262, nll: 1.2429148799086525\n",
      "Epoch: 143; total_step: 26200, loss: 1.6308099200704316, nll: 1.0711572554857915\n",
      "Epoch: 143; total_step: 26250, loss: 1.7209826318955792, nll: 1.1848062309340208\n",
      "Epoch: 143; total_step: 26300, loss: 1.7579186840076542, nll: 1.1432358986856737\n",
      "Epoch: 143; total_step: 26350, loss: 1.695439801371767, nll: 1.1679021228990283\n",
      "Epoch: 144; total_step: 26400, loss: 1.780275768984625, nll: 1.322146269388154\n",
      "Epoch: 144; total_step: 26450, loss: 1.6666582273175283, nll: 1.1239042023309551\n",
      "Epoch: 144; total_step: 26500, loss: 1.8060432935575546, nll: 1.3294183605535144\n",
      "Epoch: 145; total_step: 26550, loss: 1.6782617942899767, nll: 1.1602655596074363\n",
      "Epoch: 145; total_step: 26600, loss: 1.7445938280935984, nll: 1.2189151708003783\n",
      "Epoch: 145; total_step: 26650, loss: 1.6745811628731229, nll: 1.1799405224138964\n",
      "Epoch: 145; total_step: 26700, loss: 1.6794170230612935, nll: 1.2787902381840297\n",
      "Epoch: 146; total_step: 26750, loss: 1.7029445323504473, nll: 1.1110410743478634\n",
      "Epoch: 146; total_step: 26800, loss: 1.679348747406799, nll: 1.0323752214999942\n",
      "Epoch: 146; total_step: 26850, loss: 1.6684121786490789, nll: 1.1765856900702107\n",
      "Epoch: 146; total_step: 26900, loss: 1.6728182197495622, nll: 1.1883515605458843\n",
      "Epoch: 147; total_step: 26950, loss: 1.6547355755827333, nll: 1.1632685370480358\n",
      "Epoch: 147; total_step: 27000, loss: 1.7122975482176264, nll: 1.299988590241217\n",
      "Epoch: 147; total_step: 27050, loss: 1.719898097481497, nll: 1.2409080166121558\n",
      "Epoch: 148; total_step: 27100, loss: 1.7331832366678173, nll: 1.1742477180458153\n",
      "Epoch: 148; total_step: 27150, loss: 1.6532800752378636, nll: 1.1152519758969819\n",
      "Epoch: 148; total_step: 27200, loss: 1.6848187114359627, nll: 1.1383770740152783\n",
      "Epoch: 148; total_step: 27250, loss: 1.6860616858103992, nll: 1.1939140841326719\n",
      "Epoch: 149; total_step: 27300, loss: 1.7367826422042498, nll: 1.248822281286445\n",
      "Epoch: 149; total_step: 27350, loss: 1.7388642092980624, nll: 1.2591373004268456\n",
      "Epoch: 149; total_step: 27400, loss: 1.6655636672483831, nll: 1.2183275327780587\n",
      "Epoch: 150; total_step: 27450, loss: 1.6352711550345709, nll: 1.0895052171415773\n",
      "Epoch: 150; total_step: 27500, loss: 1.6451988239439037, nll: 1.1345675534015396\n",
      "Epoch: 150; total_step: 27550, loss: 1.6550533887667473, nll: 1.1870787515526957\n",
      "Epoch: 150; total_step: 27600, loss: 1.7556146530218353, nll: 1.2398992131999644\n",
      "Epoch: 151; total_step: 27650, loss: 1.6589432925333631, nll: 1.1237334460206314\n",
      "Epoch: 151; total_step: 27700, loss: 1.6712182001551492, nll: 1.11430919354694\n",
      "Epoch: 151; total_step: 27750, loss: 1.7673256357337335, nll: 1.3492147480212657\n",
      "Epoch: 151; total_step: 27800, loss: 1.6726394596644674, nll: 1.0546137407477678\n",
      "Epoch: 152; total_step: 27850, loss: 1.6911961611736925, nll: 1.1412156395668687\n",
      "Epoch: 152; total_step: 27900, loss: 1.6694703612351702, nll: 1.1397238504285094\n",
      "Epoch: 152; total_step: 27950, loss: 1.7328250001214298, nll: 1.3309818959755562\n",
      "Epoch: 153; total_step: 28000, loss: 1.7359331832710345, nll: 1.2346873154337454\n",
      "Epoch: 153; total_step: 28050, loss: 1.703858558310988, nll: 1.1484730353556243\n",
      "Epoch: 153; total_step: 28100, loss: 1.72678604641423, nll: 1.2267231779370615\n",
      "Epoch: 153; total_step: 28150, loss: 1.7323643014107701, nll: 1.2074623932962414\n",
      "Epoch: 154; total_step: 28200, loss: 1.6540516378981067, nll: 1.1728957043818526\n",
      "Epoch: 154; total_step: 28250, loss: 1.6044252278503837, nll: 1.1158857313700916\n",
      "Epoch: 154; total_step: 28300, loss: 1.619762565435711, nll: 1.1696970771037754\n",
      "Epoch: 154; total_step: 28350, loss: 1.644805011771269, nll: 1.2193236871152948\n",
      "Epoch: 155; total_step: 28400, loss: 1.6827840234981852, nll: 1.1817985261896382\n",
      "Epoch: 155; total_step: 28450, loss: 1.7409018155367415, nll: 1.2488475739804692\n",
      "Epoch: 155; total_step: 28500, loss: 1.6798271969013547, nll: 1.1632354888216152\n",
      "Epoch: 156; total_step: 28550, loss: 1.6686309161147983, nll: 1.1191299529085676\n",
      "Epoch: 156; total_step: 28600, loss: 1.7456399510459573, nll: 1.2314851108902762\n",
      "Epoch: 156; total_step: 28650, loss: 1.6127646411730523, nll: 1.058448337308214\n",
      "Epoch: 156; total_step: 28700, loss: 1.71490618520336, nll: 1.2992018053115182\n",
      "Epoch: 157; total_step: 28750, loss: 1.6477497205898957, nll: 1.0783705248579762\n",
      "Epoch: 157; total_step: 28800, loss: 1.6513607254106455, nll: 1.2620353848892323\n",
      "Epoch: 157; total_step: 28850, loss: 1.692145640275088, nll: 1.0640136437132572\n",
      "Epoch: 157; total_step: 28900, loss: 1.673521243263706, nll: 1.1019988487646661\n",
      "Epoch: 158; total_step: 28950, loss: 1.609233922330982, nll: 1.1625066434628852\n",
      "Epoch: 158; total_step: 29000, loss: 1.723631486045333, nll: 1.2489437689290037\n",
      "Epoch: 158; total_step: 29050, loss: 1.6416723353306202, nll: 1.16479206955056\n",
      "Epoch: 159; total_step: 29100, loss: 1.6424185075055016, nll: 1.0187674912885487\n",
      "Epoch: 159; total_step: 29150, loss: 1.7654570250506516, nll: 1.3177886636640568\n",
      "Epoch: 159; total_step: 29200, loss: 1.7692297645702164, nll: 1.200408136097664\n",
      "Epoch: 159; total_step: 29250, loss: 1.60748792892827, nll: 1.1087308440511727\n",
      "Epoch: 160; total_step: 29300, loss: 1.6923021082996705, nll: 1.211014886413495\n",
      "Epoch: 160; total_step: 29350, loss: 1.7664033684943516, nll: 1.34143185321394\n",
      "Epoch: 160; total_step: 29400, loss: 1.7384906932333941, nll: 1.3197518788412452\n",
      "Epoch: 160; total_step: 29450, loss: 1.7326226631407595, nll: 1.1517636798972068\n",
      "Epoch: 161; total_step: 29500, loss: 1.6649097602281244, nll: 1.1077294992566882\n",
      "Epoch: 161; total_step: 29550, loss: 1.6640464206804584, nll: 1.3318549785872347\n",
      "Epoch: 161; total_step: 29600, loss: 1.7205745155936767, nll: 1.1621291444605324\n",
      "Epoch: 162; total_step: 29650, loss: 1.614051112756015, nll: 1.1336021970095969\n",
      "Epoch: 162; total_step: 29700, loss: 1.715049049636155, nll: 1.1928932904354175\n",
      "Epoch: 162; total_step: 29750, loss: 1.6494618916873938, nll: 1.1615706099197427\n",
      "Epoch: 162; total_step: 29800, loss: 1.5932186944056788, nll: 1.0815671235925512\n",
      "Epoch: 163; total_step: 29850, loss: 1.7036175432026783, nll: 1.20481607304251\n",
      "Epoch: 163; total_step: 29900, loss: 1.6472880710683035, nll: 1.1628352274957738\n",
      "Epoch: 163; total_step: 29950, loss: 1.5935179273833138, nll: 1.041866483159962\n",
      "Epoch: 163; total_step: 30000, loss: 1.6748780009964537, nll: 1.232184096174482\n",
      "Epoch: 164; total_step: 30050, loss: 1.7365897394989807, nll: 1.075656140545736\n",
      "Epoch: 164; total_step: 30100, loss: 1.6657852526983539, nll: 1.1055796904626105\n",
      "Epoch: 164; total_step: 30150, loss: 1.6415482726276278, nll: 1.1914643907838935\n",
      "Epoch: 165; total_step: 30200, loss: 1.6787236055485624, nll: 1.1836430693794828\n",
      "Epoch: 165; total_step: 30250, loss: 1.6840309891091494, nll: 1.209348398131618\n",
      "Epoch: 165; total_step: 30300, loss: 1.6520850072747992, nll: 1.0352868216879607\n",
      "Epoch: 165; total_step: 30350, loss: 1.630087197647499, nll: 0.9816540567713213\n",
      "Epoch: 166; total_step: 30400, loss: 1.7065197670031456, nll: 1.0758748764205415\n",
      "Epoch: 166; total_step: 30450, loss: 1.739117435938747, nll: 1.2950187515119662\n",
      "Epoch: 166; total_step: 30500, loss: 1.6555294586875293, nll: 1.1424953590171205\n",
      "Epoch: 166; total_step: 30550, loss: 1.673928233926431, nll: 1.2045952951804748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 167; total_step: 30600, loss: 1.729941457502878, nll: 1.0838789638561768\n",
      "Epoch: 167; total_step: 30650, loss: 1.7066573615224012, nll: 1.2296167852327387\n",
      "Epoch: 167; total_step: 30700, loss: 1.6113060193368602, nll: 1.0749211312713616\n",
      "Epoch: 168; total_step: 30750, loss: 1.7329608093636202, nll: 1.2969797915657884\n",
      "Epoch: 168; total_step: 30800, loss: 1.7927162943315278, nll: 1.2506158385329014\n",
      "Epoch: 168; total_step: 30850, loss: 1.669983888855653, nll: 1.1808135599137437\n",
      "Epoch: 168; total_step: 30900, loss: 1.7005586096230008, nll: 1.2032623681879424\n",
      "Epoch: 169; total_step: 30950, loss: 1.7003238004868695, nll: 1.2287916297340176\n",
      "Epoch: 169; total_step: 31000, loss: 1.6529349662314445, nll: 1.1715013922230146\n",
      "Epoch: 169; total_step: 31050, loss: 1.6622546936074338, nll: 1.1827281371703895\n",
      "Epoch: 169; total_step: 31100, loss: 1.6739839254338238, nll: 1.2562542183994936\n",
      "Epoch: 170; total_step: 31150, loss: 1.6317408002262948, nll: 1.162229046515433\n",
      "Epoch: 170; total_step: 31200, loss: 1.671345593649778, nll: 1.2013205350748632\n",
      "Epoch: 170; total_step: 31250, loss: 1.6169640027746228, nll: 1.0833237579530968\n",
      "Epoch: 171; total_step: 31300, loss: 1.812123510821654, nll: 1.184637813967127\n",
      "Epoch: 171; total_step: 31350, loss: 1.6566285945631785, nll: 1.1026366804281797\n",
      "Epoch: 171; total_step: 31400, loss: 1.5948757769189017, nll: 1.1609008119942013\n",
      "Epoch: 171; total_step: 31450, loss: 1.7199567550566919, nll: 1.1461312367449414\n",
      "Epoch: 172; total_step: 31500, loss: 1.660699702569905, nll: 1.211018484645582\n",
      "Epoch: 172; total_step: 31550, loss: 1.8089391492397187, nll: 1.2357064337073151\n",
      "Epoch: 172; total_step: 31600, loss: 1.7096316661631652, nll: 1.1057735502692685\n",
      "Epoch: 172; total_step: 31650, loss: 1.7458336813279993, nll: 1.1862760056030108\n",
      "Epoch: 173; total_step: 31700, loss: 1.6688231458754585, nll: 1.1957898595925458\n",
      "Epoch: 173; total_step: 31750, loss: 1.6773372946854535, nll: 1.1122745267697265\n",
      "Epoch: 173; total_step: 31800, loss: 1.724822569671151, nll: 1.1948878837563113\n",
      "Epoch: 174; total_step: 31850, loss: 1.8491701477978362, nll: 1.336379887277253\n",
      "Epoch: 174; total_step: 31900, loss: 1.6379864212351007, nll: 1.2508192419414463\n",
      "Epoch: 174; total_step: 31950, loss: 1.6925095796899539, nll: 1.201936893562938\n",
      "Epoch: 174; total_step: 32000, loss: 1.6436463518898543, nll: 1.0900232892213686\n",
      "Epoch: 175; total_step: 32050, loss: 1.684515541646395, nll: 1.126138603041536\n",
      "Epoch: 175; total_step: 32100, loss: 1.7259547046933343, nll: 1.224429925736982\n",
      "Epoch: 175; total_step: 32150, loss: 1.6477651412747252, nll: 1.1507824631884123\n",
      "Epoch: 175; total_step: 32200, loss: 1.6372119046158837, nll: 1.035650081665645\n",
      "Epoch: 176; total_step: 32250, loss: 1.6497551252550917, nll: 1.137867065731302\n",
      "Epoch: 176; total_step: 32300, loss: 1.6825083426267682, nll: 1.0639266839698485\n",
      "Epoch: 176; total_step: 32350, loss: 1.7270201964270537, nll: 1.343299043311775\n",
      "Epoch: 177; total_step: 32400, loss: 1.72805788321232, nll: 1.0700910597289652\n",
      "Epoch: 177; total_step: 32450, loss: 1.6702151123440165, nll: 1.076797955390062\n",
      "Epoch: 177; total_step: 32500, loss: 1.6669584116968486, nll: 1.0489815439195533\n",
      "Epoch: 177; total_step: 32550, loss: 1.7125799637777461, nll: 1.2002796462652334\n",
      "Epoch: 178; total_step: 32600, loss: 1.6978790274522129, nll: 1.1079130183823453\n",
      "Epoch: 178; total_step: 32650, loss: 1.6663577221813397, nll: 1.2776404810619584\n",
      "Epoch: 178; total_step: 32700, loss: 1.5835695534653196, nll: 1.1358284061191668\n",
      "Epoch: 178; total_step: 32750, loss: 1.7546839203300968, nll: 1.202943249578208\n",
      "Epoch: 179; total_step: 32800, loss: 1.6697541181880746, nll: 1.2005650617692771\n",
      "Epoch: 179; total_step: 32850, loss: 1.6287885568812317, nll: 1.1290455475296315\n",
      "Epoch: 179; total_step: 32900, loss: 1.755688358992727, nll: 1.253727033086287\n",
      "Epoch: 180; total_step: 32950, loss: 1.7390718297873407, nll: 1.1866585670237721\n",
      "Epoch: 180; total_step: 33000, loss: 1.6997214292851117, nll: 1.2933932397403072\n",
      "Epoch: 180; total_step: 33050, loss: 1.7207253031120402, nll: 1.11002678623738\n",
      "Epoch: 180; total_step: 33100, loss: 1.6706605167058939, nll: 1.0478480904261072\n",
      "Epoch: 181; total_step: 33150, loss: 1.6642571123884562, nll: 1.1905307430492018\n",
      "Epoch: 181; total_step: 33200, loss: 1.6621337047341103, nll: 1.1977843642777322\n",
      "Epoch: 181; total_step: 33250, loss: 1.7272520047892153, nll: 1.2144633012433803\n",
      "Epoch: 181; total_step: 33300, loss: 1.6451222019502374, nll: 1.1363431874862508\n",
      "Epoch: 182; total_step: 33350, loss: 1.755775598730092, nll: 1.2675810080372518\n",
      "Epoch: 182; total_step: 33400, loss: 1.6879266917760243, nll: 1.1303294990601\n",
      "Epoch: 182; total_step: 33450, loss: 1.7055789185731265, nll: 1.164888898450936\n",
      "Epoch: 183; total_step: 33500, loss: 1.625233441562886, nll: 1.1193055909175833\n",
      "Epoch: 183; total_step: 33550, loss: 1.740305309836407, nll: 1.1132275786922357\n",
      "Epoch: 183; total_step: 33600, loss: 1.667606644507442, nll: 1.1870863987585\n",
      "Epoch: 183; total_step: 33650, loss: 1.7478145052449456, nll: 1.3698963002299545\n",
      "Epoch: 184; total_step: 33700, loss: 1.6388089033776225, nll: 1.168787210576045\n",
      "Epoch: 184; total_step: 33750, loss: 1.6787389725430433, nll: 1.250686088519678\n",
      "Epoch: 184; total_step: 33800, loss: 1.6598616205651222, nll: 1.0834787875702114\n",
      "Epoch: 184; total_step: 33850, loss: 1.7404392082404825, nll: 1.247261187054922\n",
      "Epoch: 185; total_step: 33900, loss: 1.713470047596657, nll: 1.3018662611343992\n",
      "Epoch: 185; total_step: 33950, loss: 1.669234639355106, nll: 1.0203383952633922\n",
      "Epoch: 185; total_step: 34000, loss: 1.7207893819493418, nll: 1.2160945848326117\n",
      "Epoch: 186; total_step: 34050, loss: 1.7585118512825033, nll: 1.2306524665951146\n",
      "Epoch: 186; total_step: 34100, loss: 1.6126018212554896, nll: 1.1063557348479636\n",
      "Epoch: 186; total_step: 34150, loss: 1.7122817837620437, nll: 1.2827823793653568\n",
      "Epoch: 186; total_step: 34200, loss: 1.5851359911704135, nll: 1.0877576874464066\n",
      "Epoch: 187; total_step: 34250, loss: 1.6474802499061374, nll: 1.0816546524969959\n",
      "Epoch: 187; total_step: 34300, loss: 1.6588045392878763, nll: 1.1335148624133244\n",
      "Epoch: 187; total_step: 34350, loss: 1.6690007060980514, nll: 1.0757362803270583\n",
      "Epoch: 187; total_step: 34400, loss: 1.682547032180648, nll: 1.1229377940663032\n",
      "Epoch: 188; total_step: 34450, loss: 1.7771507965772855, nll: 1.2293705073988666\n",
      "Epoch: 188; total_step: 34500, loss: 1.7407725184769043, nll: 1.2176196708016012\n",
      "Epoch: 188; total_step: 34550, loss: 1.7647910199285406, nll: 1.351101782068791\n",
      "Epoch: 189; total_step: 34600, loss: 1.7491330063372421, nll: 1.2674189739141846\n",
      "Epoch: 189; total_step: 34650, loss: 1.75276006914952, nll: 1.1448295611022405\n",
      "Epoch: 189; total_step: 34700, loss: 1.6212341494843097, nll: 1.1641610977759063\n",
      "Epoch: 189; total_step: 34750, loss: 1.759169785393278, nll: 1.203840768841377\n",
      "Epoch: 190; total_step: 34800, loss: 1.6972610032819047, nll: 1.2421272245681882\n",
      "Epoch: 190; total_step: 34850, loss: 1.6019931988397973, nll: 1.0990776203900907\n",
      "Epoch: 190; total_step: 34900, loss: 1.7274377216007912, nll: 1.2451369331517645\n",
      "Epoch: 190; total_step: 34950, loss: 1.6916698195181663, nll: 1.138880905779356\n",
      "Epoch: 191; total_step: 35000, loss: 1.649810316373873, nll: 1.1429292001889053\n",
      "Epoch: 191; total_step: 35050, loss: 1.686680497694152, nll: 1.088520173429527\n",
      "Epoch: 191; total_step: 35100, loss: 1.7144891902414645, nll: 1.1371853501703677\n",
      "Epoch: 192; total_step: 35150, loss: 1.6460607549577073, nll: 1.0797306744383404\n",
      "Epoch: 192; total_step: 35200, loss: 1.7458140310286654, nll: 1.1424449514949109\n",
      "Epoch: 192; total_step: 35250, loss: 1.7026537922299116, nll: 1.1346004679851789\n",
      "Epoch: 192; total_step: 35300, loss: 1.645791188864437, nll: 1.1956496255505975\n",
      "Epoch: 193; total_step: 35350, loss: 1.6631839427368937, nll: 1.105912382246525\n",
      "Epoch: 193; total_step: 35400, loss: 1.5996660713485278, nll: 1.1533381227454196\n",
      "Epoch: 193; total_step: 35450, loss: 1.7242697296223803, nll: 1.27949339820014\n",
      "Epoch: 193; total_step: 35500, loss: 1.7475439375820563, nll: 1.2137856515352665\n",
      "Epoch: 194; total_step: 35550, loss: 1.7085132203179063, nll: 1.1213582568294314\n",
      "Epoch: 194; total_step: 35600, loss: 1.7345532727557527, nll: 1.2201566282831187\n",
      "Epoch: 194; total_step: 35650, loss: 1.6814743879566794, nll: 1.2317612259867123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195; total_step: 35700, loss: 1.6200633169904044, nll: 1.0632510616441582\n",
      "Epoch: 195; total_step: 35750, loss: 1.624881794592427, nll: 1.1386802575470114\n",
      "Epoch: 195; total_step: 35800, loss: 1.6650514987187508, nll: 1.1566098459756988\n",
      "Epoch: 195; total_step: 35850, loss: 1.6336828830505683, nll: 1.1978369176881825\n",
      "Epoch: 196; total_step: 35900, loss: 1.6381849153777148, nll: 1.1184879973330144\n",
      "Epoch: 196; total_step: 35950, loss: 1.699993522790126, nll: 1.1778572495774005\n",
      "Epoch: 196; total_step: 36000, loss: 1.6268112535203636, nll: 1.1301978223010334\n",
      "Epoch: 196; total_step: 36050, loss: 1.6591517032013972, nll: 1.07795961152099\n",
      "Epoch: 197; total_step: 36100, loss: 1.6979165789613133, nll: 1.240214304642135\n",
      "Epoch: 197; total_step: 36150, loss: 1.678551266696708, nll: 1.2613757621117718\n",
      "Epoch: 197; total_step: 36200, loss: 1.7332826926074558, nll: 1.1802260193405782\n",
      "Epoch: 198; total_step: 36250, loss: 1.7277112193675654, nll: 1.1767648801211907\n",
      "Epoch: 198; total_step: 36300, loss: 1.652015685487247, nll: 1.0530576273155603\n",
      "Epoch: 198; total_step: 36350, loss: 1.619454648410065, nll: 1.0782507831447041\n",
      "Epoch: 198; total_step: 36400, loss: 1.6457327404353053, nll: 1.1725460976786966\n",
      "Epoch: 199; total_step: 36450, loss: 1.6880605744045971, nll: 1.11640669323509\n",
      "Epoch: 199; total_step: 36500, loss: 1.7495238328863323, nll: 1.312272319984724\n",
      "Epoch: 199; total_step: 36550, loss: 1.6656204384623132, nll: 1.081160897071152\n",
      "Epoch: 200; total_step: 36600, loss: 1.7728798257259002, nll: 1.3030640303749663\n",
      "Epoch: 200; total_step: 36650, loss: 1.6845447561569322, nll: 1.269877578662042\n",
      "Epoch: 200; total_step: 36700, loss: 1.6490858783097735, nll: 1.092837262608298\n",
      "Epoch: 200; total_step: 36750, loss: 1.5863787409853543, nll: 1.1294689175243564\n",
      "Epoch: 201; total_step: 36800, loss: 1.6981375847301083, nll: 1.150466609749541\n",
      "Epoch: 201; total_step: 36850, loss: 1.6796738132512914, nll: 1.2045272957847304\n",
      "Epoch: 201; total_step: 36900, loss: 1.6673463543774627, nll: 1.2517999696988218\n",
      "Epoch: 201; total_step: 36950, loss: 1.6318975210603992, nll: 1.1608640027288055\n",
      "Epoch: 202; total_step: 37000, loss: 1.6956049365633852, nll: 1.2724269562887274\n",
      "Epoch: 202; total_step: 37050, loss: 1.7087643225537752, nll: 1.3093635762503932\n",
      "Epoch: 202; total_step: 37100, loss: 1.682169292142101, nll: 1.142562726794809\n",
      "Epoch: 203; total_step: 37150, loss: 1.6878344602600828, nll: 1.181912473962292\n",
      "Epoch: 203; total_step: 37200, loss: 1.7380842797000073, nll: 1.2806378867702777\n",
      "Epoch: 203; total_step: 37250, loss: 1.6418024470564412, nll: 1.0659097447363615\n",
      "Epoch: 203; total_step: 37300, loss: 1.670127844165548, nll: 1.1577415121763739\n",
      "Epoch: 204; total_step: 37350, loss: 1.6750806902790414, nll: 1.2391769592446384\n",
      "Epoch: 204; total_step: 37400, loss: 1.5800609367769787, nll: 1.087984551857406\n",
      "Epoch: 204; total_step: 37450, loss: 1.6960486766001137, nll: 1.155530985313646\n",
      "Epoch: 204; total_step: 37500, loss: 1.6500664204075774, nll: 1.2441535180626793\n",
      "Epoch: 205; total_step: 37550, loss: 1.732891010290941, nll: 1.3241915914735365\n",
      "Epoch: 205; total_step: 37600, loss: 1.6699805304141162, nll: 1.1295284265598704\n",
      "Epoch: 205; total_step: 37650, loss: 1.756209629035436, nll: 1.2808349223543916\n",
      "Epoch: 206; total_step: 37700, loss: 1.6250500884543966, nll: 1.1788098844198538\n",
      "Epoch: 206; total_step: 37750, loss: 1.7171675786596439, nll: 1.2142842742105686\n",
      "Epoch: 206; total_step: 37800, loss: 1.6503882681403073, nll: 1.0195799984001548\n",
      "Epoch: 206; total_step: 37850, loss: 1.6618266849167926, nll: 1.2411005890041118\n",
      "Epoch: 207; total_step: 37900, loss: 1.7339651728376868, nll: 1.1952361273105276\n",
      "Epoch: 207; total_step: 37950, loss: 1.609758990580322, nll: 1.1092992470664365\n",
      "Epoch: 207; total_step: 38000, loss: 1.6628457415545335, nll: 1.184924604963295\n",
      "Epoch: 207; total_step: 38050, loss: 1.6399841818976448, nll: 1.0747753608908308\n",
      "Epoch: 208; total_step: 38100, loss: 1.702561472840615, nll: 1.0410248564912277\n",
      "Epoch: 208; total_step: 38150, loss: 1.7028916868974233, nll: 1.2207312390084646\n",
      "Epoch: 208; total_step: 38200, loss: 1.708723232113146, nll: 1.13480073976037\n",
      "Epoch: 209; total_step: 38250, loss: 1.6440182190506232, nll: 1.1672121481009046\n",
      "Epoch: 209; total_step: 38300, loss: 1.7579907781696673, nll: 1.2604791572830645\n",
      "Epoch: 209; total_step: 38350, loss: 1.657427877877557, nll: 1.1428295081004067\n",
      "Epoch: 209; total_step: 38400, loss: 1.5797041908116158, nll: 1.0782075205620103\n",
      "Epoch: 210; total_step: 38450, loss: 1.6514257068986606, nll: 1.0242230473273741\n",
      "Epoch: 210; total_step: 38500, loss: 1.6727639182175307, nll: 1.0582400322283725\n",
      "Epoch: 210; total_step: 38550, loss: 1.732557488301552, nll: 1.242484493030499\n",
      "Epoch: 210; total_step: 38600, loss: 1.6780671375910696, nll: 1.1648868637432217\n",
      "Epoch: 211; total_step: 38650, loss: 1.6264046736171889, nll: 1.188152699110318\n",
      "Epoch: 211; total_step: 38700, loss: 1.7767560709837835, nll: 1.24513597161792\n",
      "Epoch: 211; total_step: 38750, loss: 1.7405117429885808, nll: 1.1519196743581988\n",
      "Epoch: 212; total_step: 38800, loss: 1.7133635595655863, nll: 1.1995723925106727\n",
      "Epoch: 212; total_step: 38850, loss: 1.7132326838781298, nll: 1.237598958318328\n",
      "Epoch: 212; total_step: 38900, loss: 1.6406444894324976, nll: 1.0586900186140615\n",
      "Epoch: 212; total_step: 38950, loss: 1.691259291296383, nll: 1.1353930049490815\n",
      "Epoch: 213; total_step: 39000, loss: 1.6355619913481365, nll: 1.2163577795357743\n",
      "Epoch: 213; total_step: 39050, loss: 1.7845445080087858, nll: 1.219125832221515\n",
      "Epoch: 213; total_step: 39100, loss: 1.6873271615225929, nll: 1.1298973073848568\n",
      "Epoch: 213; total_step: 39150, loss: 1.6345851549493517, nll: 1.1747382418335928\n",
      "Epoch: 214; total_step: 39200, loss: 1.640995910170668, nll: 1.150067047876971\n",
      "Epoch: 214; total_step: 39250, loss: 1.6934460708791768, nll: 1.132701287164422\n",
      "Epoch: 214; total_step: 39300, loss: 1.758354143089463, nll: 1.1727005220369582\n",
      "Epoch: 215; total_step: 39350, loss: 1.608162337984232, nll: 1.0875635584793102\n",
      "Epoch: 215; total_step: 39400, loss: 1.6574147809661515, nll: 1.1179672264570755\n",
      "Epoch: 215; total_step: 39450, loss: 1.754116933831824, nll: 1.306427748028231\n",
      "Epoch: 215; total_step: 39500, loss: 1.7062253007130754, nll: 1.1859571889456066\n",
      "Epoch: 216; total_step: 39550, loss: 1.7010046488824366, nll: 1.0580142635577654\n",
      "Epoch: 216; total_step: 39600, loss: 1.7395466641890658, nll: 1.1445168054219623\n",
      "Epoch: 216; total_step: 39650, loss: 1.7433069215523682, nll: 1.1157715180035777\n",
      "Epoch: 216; total_step: 39700, loss: 1.650185212792299, nll: 1.1151513629484215\n",
      "Epoch: 217; total_step: 39750, loss: 1.6367772715070692, nll: 1.119630159786964\n",
      "Epoch: 217; total_step: 39800, loss: 1.7523581368707324, nll: 1.2569992892962703\n",
      "Epoch: 217; total_step: 39850, loss: 1.6734292452796722, nll: 1.2380306006089836\n",
      "Epoch: 218; total_step: 39900, loss: 1.5893645448859457, nll: 1.118591870535302\n",
      "Epoch: 218; total_step: 39950, loss: 1.6704148324142727, nll: 1.2535092048740235\n",
      "Epoch: 218; total_step: 40000, loss: 1.6279561911948413, nll: 1.0254398664526896\n",
      "Epoch: 218; total_step: 40050, loss: 1.7379070358042383, nll: 1.1638784154437734\n",
      "Epoch: 219; total_step: 40100, loss: 1.611585911985946, nll: 1.1143518143648417\n",
      "Epoch: 219; total_step: 40150, loss: 1.65493651958768, nll: 1.0773451544987132\n",
      "Epoch: 219; total_step: 40200, loss: 1.6736487174984156, nll: 1.1485378288634476\n",
      "Epoch: 219; total_step: 40250, loss: 1.6569413182630957, nll: 1.2344813205002598\n",
      "Epoch: 220; total_step: 40300, loss: 1.6472431827135912, nll: 1.0872149506484028\n",
      "Epoch: 220; total_step: 40350, loss: 1.6518469497280348, nll: 1.2094380219079996\n",
      "Epoch: 220; total_step: 40400, loss: 1.6502111180518897, nll: 1.1191776032688068\n",
      "Epoch: 221; total_step: 40450, loss: 1.7615572218416709, nll: 1.1821698120831567\n",
      "Epoch: 221; total_step: 40500, loss: 1.6921059394184146, nll: 1.3769059246122324\n",
      "Epoch: 221; total_step: 40550, loss: 1.6592117914000952, nll: 1.129732737813055\n",
      "Epoch: 221; total_step: 40600, loss: 1.6479331725669208, nll: 1.0934733895777013\n",
      "Epoch: 222; total_step: 40650, loss: 1.7750143376898115, nll: 1.3462558593883454\n",
      "Epoch: 222; total_step: 40700, loss: 1.6885198112696203, nll: 1.2185814213099966\n",
      "Epoch: 222; total_step: 40750, loss: 1.752711451535047, nll: 1.223718840099759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 222; total_step: 40800, loss: 1.6641923990791418, nll: 1.115259701166449\n",
      "Epoch: 223; total_step: 40850, loss: 1.6419105712031214, nll: 0.9875460546177072\n",
      "Epoch: 223; total_step: 40900, loss: 1.6402272362131414, nll: 1.1721792837273504\n",
      "Epoch: 223; total_step: 40950, loss: 1.6493758095228546, nll: 1.1805136043134095\n",
      "Epoch: 224; total_step: 41000, loss: 1.6683375185441616, nll: 1.2065496385333232\n",
      "Epoch: 224; total_step: 41050, loss: 1.6461127280947345, nll: 1.1461511760983847\n",
      "Epoch: 224; total_step: 41100, loss: 1.6603967932611345, nll: 1.0825522980179034\n",
      "Epoch: 224; total_step: 41150, loss: 1.6569560301753592, nll: 1.181336282187857\n",
      "Epoch: 225; total_step: 41200, loss: 1.615645214677267, nll: 1.0728982844701933\n",
      "Epoch: 225; total_step: 41250, loss: 1.7048809667224032, nll: 1.1663605041585638\n",
      "Epoch: 225; total_step: 41300, loss: 1.6800201019391239, nll: 1.1662099436605284\n",
      "Epoch: 225; total_step: 41350, loss: 1.6954083832735625, nll: 1.2088111636130343\n",
      "Epoch: 226; total_step: 41400, loss: 1.6782154887329253, nll: 1.2670851253046869\n",
      "Epoch: 226; total_step: 41450, loss: 1.598458949199852, nll: 1.1131165549928144\n",
      "Epoch: 226; total_step: 41500, loss: 1.6812069318387688, nll: 1.1025693554921228\n",
      "Epoch: 227; total_step: 41550, loss: 1.6621479212371535, nll: 1.2185371259950426\n",
      "Epoch: 227; total_step: 41600, loss: 1.6991348704192952, nll: 1.1407348673667177\n",
      "Epoch: 227; total_step: 41650, loss: 1.6896829510009423, nll: 1.135858365695454\n",
      "Epoch: 227; total_step: 41700, loss: 1.6375551519057006, nll: 1.041796805388489\n",
      "Epoch: 228; total_step: 41750, loss: 1.6246828425969995, nll: 1.0101490268952773\n",
      "Epoch: 228; total_step: 41800, loss: 1.7256590311436997, nll: 1.2065981644918609\n",
      "Epoch: 228; total_step: 41850, loss: 1.550881676247558, nll: 1.0168501562220562\n",
      "Epoch: 228; total_step: 41900, loss: 1.7088201658948718, nll: 1.14385277700868\n",
      "Epoch: 229; total_step: 41950, loss: 1.6444983688100485, nll: 1.2629314199999522\n",
      "Epoch: 229; total_step: 42000, loss: 1.7151114724971845, nll: 1.1907311059656833\n",
      "Epoch: 229; total_step: 42050, loss: 1.673382398993466, nll: 1.2135185241039201\n",
      "Epoch: 230; total_step: 42100, loss: 1.6463037564403649, nll: 1.1290309075280662\n",
      "Epoch: 230; total_step: 42150, loss: 1.6582742484299329, nll: 1.184813958093294\n",
      "Epoch: 230; total_step: 42200, loss: 1.5695449317213046, nll: 1.0183591796970262\n",
      "Epoch: 230; total_step: 42250, loss: 1.644164542433034, nll: 1.1846490623468307\n",
      "Epoch: 231; total_step: 42300, loss: 1.6838073324515028, nll: 1.0566752155502093\n",
      "Epoch: 231; total_step: 42350, loss: 1.6601825887894173, nll: 1.1576850556134277\n",
      "Epoch: 231; total_step: 42400, loss: 1.6477957789478077, nll: 1.0604068183205264\n",
      "Epoch: 231; total_step: 42450, loss: 1.5841861952502052, nll: 1.1143447496450611\n",
      "Epoch: 232; total_step: 42500, loss: 1.7508447032605365, nll: 1.1757137188240057\n",
      "Epoch: 232; total_step: 42550, loss: 1.6453530655949726, nll: 1.0786734114224013\n",
      "Epoch: 232; total_step: 42600, loss: 1.7504635053370423, nll: 1.20989333384315\n",
      "Epoch: 233; total_step: 42650, loss: 1.6368723541655492, nll: 1.159499563461928\n",
      "Epoch: 233; total_step: 42700, loss: 1.7290804203461136, nll: 1.2037847852505008\n",
      "Epoch: 233; total_step: 42750, loss: 1.6919749719473756, nll: 1.169267045578951\n",
      "Epoch: 233; total_step: 42800, loss: 1.6571771647166094, nll: 1.0964129507451261\n",
      "Epoch: 234; total_step: 42850, loss: 1.746717203124807, nll: 1.2085372695452887\n",
      "Epoch: 234; total_step: 42900, loss: 1.6412611567233215, nll: 1.0450522482264024\n",
      "Epoch: 234; total_step: 42950, loss: 1.7115809983223778, nll: 1.140434230244722\n",
      "Epoch: 234; total_step: 43000, loss: 1.6794458288218117, nll: 1.047857869264467\n",
      "Epoch: 235; total_step: 43050, loss: 1.643472520269468, nll: 1.0517966549280109\n",
      "Epoch: 235; total_step: 43100, loss: 1.6528089395994052, nll: 1.1790008756467691\n",
      "Epoch: 235; total_step: 43150, loss: 1.6922684841675002, nll: 1.062248315517021\n",
      "Epoch: 236; total_step: 43200, loss: 1.6564332717511001, nll: 1.2148951705633124\n",
      "Epoch: 236; total_step: 43250, loss: 1.6974134666726923, nll: 1.2706837174559418\n",
      "Epoch: 236; total_step: 43300, loss: 1.7015046312908515, nll: 1.269076925748095\n",
      "Epoch: 236; total_step: 43350, loss: 1.6732359856654342, nll: 1.0819830755004547\n",
      "Epoch: 237; total_step: 43400, loss: 1.6401838063655418, nll: 1.1010563970613028\n",
      "Epoch: 237; total_step: 43450, loss: 1.751579668724603, nll: 1.32271724819235\n",
      "Epoch: 237; total_step: 43500, loss: 1.745218076119651, nll: 1.2921156415660902\n",
      "Epoch: 237; total_step: 43550, loss: 1.7068076824557585, nll: 1.244654088207252\n",
      "Epoch: 238; total_step: 43600, loss: 1.6714564956365916, nll: 1.1442756052361625\n",
      "Epoch: 238; total_step: 43650, loss: 1.6984333734263806, nll: 1.0635177855242592\n",
      "Epoch: 238; total_step: 43700, loss: 1.6509087551295112, nll: 1.107063003661226\n",
      "Epoch: 239; total_step: 43750, loss: 1.6508841038689577, nll: 1.2827908796981333\n",
      "Epoch: 239; total_step: 43800, loss: 1.6940366378800729, nll: 1.2015743118358007\n",
      "Epoch: 239; total_step: 43850, loss: 1.6606459697604508, nll: 1.2039085975849158\n",
      "Epoch: 239; total_step: 43900, loss: 1.7220477660320879, nll: 1.2423525912038833\n",
      "Epoch: 240; total_step: 43950, loss: 1.6239279972067353, nll: 1.1218636890249056\n",
      "Epoch: 240; total_step: 44000, loss: 1.6813242614638606, nll: 1.1174110457608677\n",
      "Epoch: 240; total_step: 44050, loss: 1.6587090590709312, nll: 1.209050786772659\n",
      "Epoch: 240; total_step: 44100, loss: 1.6982711971023992, nll: 1.1342238380961256\n",
      "Epoch: 241; total_step: 44150, loss: 1.8026359793083904, nll: 1.2715514152673502\n",
      "Epoch: 241; total_step: 44200, loss: 1.669021757264927, nll: 1.1513682462164132\n",
      "Epoch: 241; total_step: 44250, loss: 1.6322841551824052, nll: 1.019773394592898\n",
      "Epoch: 242; total_step: 44300, loss: 1.6632598925987154, nll: 1.1221651976143752\n",
      "Epoch: 242; total_step: 44350, loss: 1.6648997803935814, nll: 1.2552345995999068\n",
      "Epoch: 242; total_step: 44400, loss: 1.6627323631012028, nll: 1.1895311193968803\n",
      "Epoch: 242; total_step: 44450, loss: 1.7224347018537918, nll: 1.2539410937980247\n",
      "Epoch: 243; total_step: 44500, loss: 1.683724348241052, nll: 1.1965705094540728\n",
      "Epoch: 243; total_step: 44550, loss: 1.6966306146532337, nll: 1.1909070992954078\n",
      "Epoch: 243; total_step: 44600, loss: 1.6493905247573313, nll: 1.2368888635996527\n",
      "Epoch: 243; total_step: 44650, loss: 1.6279243163778994, nll: 1.057515814698087\n",
      "Epoch: 244; total_step: 44700, loss: 1.6031127800272464, nll: 1.087710613496102\n",
      "Epoch: 244; total_step: 44750, loss: 1.6852076979380775, nll: 1.121128737679439\n",
      "Epoch: 244; total_step: 44800, loss: 1.6777016923628747, nll: 1.1862942146417872\n",
      "Epoch: 245; total_step: 44850, loss: 1.6933208479813582, nll: 1.1137947822811578\n",
      "Epoch: 245; total_step: 44900, loss: 1.7069760160960834, nll: 1.0652324555444639\n",
      "Epoch: 245; total_step: 44950, loss: 1.771738333456285, nll: 1.284665771004171\n",
      "Epoch: 245; total_step: 45000, loss: 1.7158016033085477, nll: 1.161383307394479\n",
      "Epoch: 246; total_step: 45050, loss: 1.6428813007336152, nll: 1.1345390842074976\n",
      "Epoch: 246; total_step: 45100, loss: 1.7504716123707826, nll: 1.298152012433662\n",
      "Epoch: 246; total_step: 45150, loss: 1.873921195560461, nll: 1.375926761414312\n",
      "Epoch: 246; total_step: 45200, loss: 1.740756870238623, nll: 1.2770764160209476\n",
      "Epoch: 247; total_step: 45250, loss: 1.6272482517757152, nll: 1.1387168654088229\n",
      "Epoch: 247; total_step: 45300, loss: 1.7629854376533742, nll: 1.1860109884212129\n",
      "Epoch: 247; total_step: 45350, loss: 1.6752050993085745, nll: 1.2404253392699038\n",
      "Epoch: 248; total_step: 45400, loss: 1.6445122294509218, nll: 1.0397674633220741\n",
      "Epoch: 248; total_step: 45450, loss: 1.7245906766396941, nll: 1.2634791342663263\n",
      "Epoch: 248; total_step: 45500, loss: 1.6202672365187256, nll: 1.1203042423781022\n",
      "Epoch: 248; total_step: 45550, loss: 1.706188255424802, nll: 1.1462031436721218\n",
      "Epoch: 249; total_step: 45600, loss: 1.7461891638274512, nll: 1.3693802642668587\n",
      "Epoch: 249; total_step: 45650, loss: 1.6630247094640298, nll: 1.2273781673494781\n",
      "Epoch: 249; total_step: 45700, loss: 1.6286456387165618, nll: 1.1564182730582628\n",
      "Epoch: 250; total_step: 45750, loss: 1.7228960425475202, nll: 1.172615391412424\n",
      "Epoch: 250; total_step: 45800, loss: 1.7168318184729685, nll: 1.2023083808345527\n",
      "Epoch: 250; total_step: 45850, loss: 1.7382179773332336, nll: 1.1971220114600645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250; total_step: 45900, loss: 1.721640723438419, nll: 1.1753713434955582\n",
      "Epoch: 251; total_step: 45950, loss: 1.6225360184257038, nll: 1.0856017667742441\n",
      "Epoch: 251; total_step: 46000, loss: 1.6963952834479046, nll: 1.1713685755219043\n",
      "Epoch: 251; total_step: 46050, loss: 1.7293751129895316, nll: 1.2852873329585304\n",
      "Epoch: 251; total_step: 46100, loss: 1.7364429459250414, nll: 1.1434098526731942\n",
      "Epoch: 252; total_step: 46150, loss: 1.6852466305435798, nll: 1.1757587144283124\n",
      "Epoch: 252; total_step: 46200, loss: 1.6678807667559754, nll: 1.145337152336791\n",
      "Epoch: 252; total_step: 46250, loss: 1.7254897438823105, nll: 1.3078519051909727\n",
      "Epoch: 253; total_step: 46300, loss: 1.685372044451119, nll: 1.296275362241938\n",
      "Epoch: 253; total_step: 46350, loss: 1.7504393421222104, nll: 1.3264213138975844\n",
      "Epoch: 253; total_step: 46400, loss: 1.6587629356157974, nll: 1.087351806666651\n",
      "Epoch: 253; total_step: 46450, loss: 1.5979667683337306, nll: 1.0635800643698872\n",
      "Epoch: 254; total_step: 46500, loss: 1.7651342999937727, nll: 1.2653494990752332\n",
      "Epoch: 254; total_step: 46550, loss: 1.5927384230073611, nll: 1.1247747547237563\n",
      "Epoch: 254; total_step: 46600, loss: 1.66992328634726, nll: 1.1588572285980467\n",
      "Epoch: 254; total_step: 46650, loss: 1.664811007368786, nll: 1.146618807006435\n",
      "Epoch: 255; total_step: 46700, loss: 1.6700180966334406, nll: 1.0094072158436578\n",
      "Epoch: 255; total_step: 46750, loss: 1.742059191214221, nll: 1.1902258233743797\n",
      "Epoch: 255; total_step: 46800, loss: 1.6905439668231985, nll: 1.2619193957801653\n",
      "Epoch: 256; total_step: 46850, loss: 1.6637444584932541, nll: 1.1543538413947207\n",
      "Epoch: 256; total_step: 46900, loss: 1.682144149014443, nll: 1.1874924298881298\n",
      "Epoch: 256; total_step: 46950, loss: 1.6643993751398127, nll: 1.0632202408446412\n",
      "Epoch: 256; total_step: 47000, loss: 1.6084730586323268, nll: 1.0815631071017584\n",
      "Epoch: 257; total_step: 47050, loss: 1.6842551385554645, nll: 1.0807107226184507\n",
      "Epoch: 257; total_step: 47100, loss: 1.7364574661777328, nll: 1.2903838093815663\n",
      "Epoch: 257; total_step: 47150, loss: 1.6948029230732151, nll: 1.1380489169543788\n",
      "Epoch: 257; total_step: 47200, loss: 1.6767420669397852, nll: 1.1654764950110372\n",
      "Epoch: 258; total_step: 47250, loss: 1.6329561152531509, nll: 1.08177731452533\n",
      "Epoch: 258; total_step: 47300, loss: 1.6583086564013019, nll: 1.1750854291218524\n",
      "Epoch: 258; total_step: 47350, loss: 1.648308822108089, nll: 1.1764679546796295\n",
      "Epoch: 259; total_step: 47400, loss: 1.6609620210152405, nll: 1.1131912749177724\n",
      "Epoch: 259; total_step: 47450, loss: 1.7392772476099492, nll: 1.262522428519633\n",
      "Epoch: 259; total_step: 47500, loss: 1.5932086810821608, nll: 0.9690473174727199\n",
      "Epoch: 259; total_step: 47550, loss: 1.6568589604849362, nll: 1.1826468967469692\n",
      "Epoch: 260; total_step: 47600, loss: 1.640028120510338, nll: 1.1597165410201058\n",
      "Epoch: 260; total_step: 47650, loss: 1.5852951803696251, nll: 1.0601320558124028\n",
      "Epoch: 260; total_step: 47700, loss: 1.6962908077446561, nll: 1.263374618726249\n",
      "Epoch: 260; total_step: 47750, loss: 1.7248199801411601, nll: 1.1959746782238176\n",
      "Epoch: 261; total_step: 47800, loss: 1.7257284703382156, nll: 1.180934216736474\n",
      "Epoch: 261; total_step: 47850, loss: 1.6995630669161468, nll: 1.2275902012910855\n",
      "Epoch: 261; total_step: 47900, loss: 1.62937258151166, nll: 1.0789103487214686\n",
      "Epoch: 262; total_step: 47950, loss: 1.696867443952426, nll: 1.1654468105579916\n",
      "Epoch: 262; total_step: 48000, loss: 1.7653173824797306, nll: 1.15194541636607\n",
      "Epoch: 262; total_step: 48050, loss: 1.6463972938747249, nll: 1.1092954391662444\n",
      "Epoch: 262; total_step: 48100, loss: 1.7314539352031495, nll: 1.2963805992540003\n",
      "Epoch: 263; total_step: 48150, loss: 1.6682836335148, nll: 1.249453011999043\n",
      "Epoch: 263; total_step: 48200, loss: 1.66146342862344, nll: 1.1423612387209778\n",
      "Epoch: 263; total_step: 48250, loss: 1.6509889025760387, nll: 1.1356813164019577\n",
      "Epoch: 263; total_step: 48300, loss: 1.7240682207246407, nll: 1.286839740707547\n",
      "Epoch: 264; total_step: 48350, loss: 1.6862499446025219, nll: 1.130564628978904\n",
      "Epoch: 264; total_step: 48400, loss: 1.7732579670169213, nll: 1.3129810902979704\n",
      "Epoch: 264; total_step: 48450, loss: 1.702910328100646, nll: 1.2276371443989333\n",
      "Epoch: 265; total_step: 48500, loss: 1.6767122492631517, nll: 1.1975707819149053\n",
      "Epoch: 265; total_step: 48550, loss: 1.6476245045576965, nll: 1.0924954144179562\n",
      "Epoch: 265; total_step: 48600, loss: 1.7375518016769405, nll: 1.0988859709849705\n",
      "Epoch: 265; total_step: 48650, loss: 1.6329646654933674, nll: 0.9999783074961357\n",
      "Epoch: 266; total_step: 48700, loss: 1.6844790632458433, nll: 1.1628463107293485\n",
      "Epoch: 266; total_step: 48750, loss: 1.6411549030090509, nll: 1.1806285166051782\n",
      "Epoch: 266; total_step: 48800, loss: 1.6950823372567283, nll: 1.1624617475644798\n",
      "Epoch: 266; total_step: 48850, loss: 1.7926648999164743, nll: 1.4304081242324949\n",
      "Epoch: 267; total_step: 48900, loss: 1.735875231273742, nll: 1.2065908766403863\n",
      "Epoch: 267; total_step: 48950, loss: 1.7191184818161864, nll: 1.17572350735976\n",
      "Epoch: 267; total_step: 49000, loss: 1.704058230109229, nll: 1.123601953643476\n",
      "Epoch: 268; total_step: 49050, loss: 1.7132381109889576, nll: 1.3154237483163516\n",
      "Epoch: 268; total_step: 49100, loss: 1.6627792438663733, nll: 1.1597760547151836\n",
      "Epoch: 268; total_step: 49150, loss: 1.6414132154049537, nll: 1.0460566524309267\n",
      "Epoch: 268; total_step: 49200, loss: 1.7232370391858052, nll: 1.1755803653441912\n",
      "Epoch: 269; total_step: 49250, loss: 1.6404137147389815, nll: 1.1097128192284904\n",
      "Epoch: 269; total_step: 49300, loss: 1.7608988353481765, nll: 1.159404401229774\n",
      "Epoch: 269; total_step: 49350, loss: 1.8073951384030988, nll: 1.325150561662036\n",
      "Epoch: 269; total_step: 49400, loss: 1.6631066072214482, nll: 1.1611436377108126\n",
      "Epoch: 270; total_step: 49450, loss: 1.721114166007588, nll: 1.1969288428266516\n",
      "Epoch: 270; total_step: 49500, loss: 1.6375046596564686, nll: 1.129262130494517\n",
      "Epoch: 270; total_step: 49550, loss: 1.738196108904483, nll: 1.259616950130387\n",
      "Epoch: 271; total_step: 49600, loss: 1.6610327395492583, nll: 1.2028126168336108\n",
      "Epoch: 271; total_step: 49650, loss: 1.7197062941274295, nll: 1.2673894912522408\n",
      "Epoch: 271; total_step: 49700, loss: 1.6555845571753482, nll: 1.1013188065146111\n",
      "Epoch: 271; total_step: 49750, loss: 1.761353770847055, nll: 1.3314821383180824\n",
      "Epoch: 272; total_step: 49800, loss: 1.713383787720351, nll: 1.078383586594629\n",
      "Epoch: 272; total_step: 49850, loss: 1.7224815557992528, nll: 1.2522688934986301\n",
      "Epoch: 272; total_step: 49900, loss: 1.620777636118757, nll: 1.045687400159506\n",
      "Epoch: 272; total_step: 49950, loss: 1.682240328707492, nll: 1.1699792965515803\n",
      "Epoch: 273; total_step: 50000, loss: 1.6632849365611484, nll: 1.2000370388009405\n",
      "Epoch: 273; total_step: 50050, loss: 1.6596427489516292, nll: 1.1731470095833032\n",
      "Epoch: 273; total_step: 50100, loss: 1.6504046434200825, nll: 1.2207234675671577\n",
      "Epoch: 274; total_step: 50150, loss: 1.7132163980493973, nll: 1.0786970028187521\n",
      "Epoch: 274; total_step: 50200, loss: 1.750060899663917, nll: 1.2804754333365698\n",
      "Epoch: 274; total_step: 50250, loss: 1.7431099847383091, nll: 1.1546722325721974\n",
      "Epoch: 274; total_step: 50300, loss: 1.687317072441456, nll: 1.1449133855043776\n",
      "Epoch: 275; total_step: 50350, loss: 1.6588826569253472, nll: 1.2019755226009035\n",
      "Epoch: 275; total_step: 50400, loss: 1.6830678377372987, nll: 1.1701225113352416\n",
      "Epoch: 275; total_step: 50450, loss: 1.6243628769451561, nll: 1.122757001639255\n",
      "Epoch: 275; total_step: 50500, loss: 1.7471706444453179, nll: 1.2007053375230226\n",
      "Epoch: 276; total_step: 50550, loss: 1.6068043073526292, nll: 1.099725747480032\n",
      "Epoch: 276; total_step: 50600, loss: 1.6579616990111674, nll: 1.0689907769846603\n",
      "Epoch: 276; total_step: 50650, loss: 1.7123320693894482, nll: 1.1549415745408347\n",
      "Epoch: 277; total_step: 50700, loss: 1.6777104221810828, nll: 1.01799516114353\n",
      "Epoch: 277; total_step: 50750, loss: 1.726572408471622, nll: 1.2941523857003587\n",
      "Epoch: 277; total_step: 50800, loss: 1.7390244554077947, nll: 1.1688152155303366\n",
      "Epoch: 277; total_step: 50850, loss: 1.7228403669786414, nll: 1.3743258390747766\n",
      "Epoch: 278; total_step: 50900, loss: 1.6670492322798827, nll: 1.0294135722577455\n",
      "Epoch: 278; total_step: 50950, loss: 1.7555868924690372, nll: 1.1893532657186523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 278; total_step: 51000, loss: 1.6738545239773808, nll: 1.0912250134732502\n",
      "Epoch: 278; total_step: 51050, loss: 1.575992178018825, nll: 1.114507883492572\n",
      "Epoch: 279; total_step: 51100, loss: 1.5638198801344592, nll: 1.191394273945553\n",
      "Epoch: 279; total_step: 51150, loss: 1.6215687240051961, nll: 1.0540806457436318\n",
      "Epoch: 279; total_step: 51200, loss: 1.752329491767794, nll: 1.2522910573991186\n",
      "Epoch: 280; total_step: 51250, loss: 1.7027336971143046, nll: 1.1273297293653233\n",
      "Epoch: 280; total_step: 51300, loss: 1.6712247977259, nll: 1.2819874378588831\n",
      "Epoch: 280; total_step: 51350, loss: 1.6404729596409293, nll: 1.2392431507951467\n",
      "Epoch: 280; total_step: 51400, loss: 1.6933786418184327, nll: 1.4155894870325436\n",
      "Epoch: 281; total_step: 51450, loss: 1.687870901621742, nll: 1.0717050648497668\n",
      "Epoch: 281; total_step: 51500, loss: 1.647246605883624, nll: 1.0270774513781564\n",
      "Epoch: 281; total_step: 51550, loss: 1.6388420799400336, nll: 1.057934184692943\n",
      "Epoch: 281; total_step: 51600, loss: 1.689463039577527, nll: 1.0605237166892465\n",
      "Epoch: 282; total_step: 51650, loss: 1.6480721648872854, nll: 1.0994220558015473\n",
      "Epoch: 282; total_step: 51700, loss: 1.7620381463160817, nll: 1.177974441536529\n",
      "Epoch: 282; total_step: 51750, loss: 1.6690247195975607, nll: 1.0882899560636459\n",
      "Epoch: 283; total_step: 51800, loss: 1.6573487352167091, nll: 1.1398910945644316\n",
      "Epoch: 283; total_step: 51850, loss: 1.653237561172968, nll: 1.146940704955235\n",
      "Epoch: 283; total_step: 51900, loss: 1.7034957217329845, nll: 1.1070673180367252\n",
      "Epoch: 283; total_step: 51950, loss: 1.657059861129638, nll: 1.1451984435877436\n",
      "Epoch: 284; total_step: 52000, loss: 1.7035523156223473, nll: 1.1159694308838033\n",
      "Epoch: 284; total_step: 52050, loss: 1.653382185234642, nll: 1.201912527553803\n",
      "Epoch: 284; total_step: 52100, loss: 1.658440038057957, nll: 1.1826988200382687\n",
      "Epoch: 284; total_step: 52150, loss: 1.717351370048386, nll: 1.2186781989460627\n",
      "Epoch: 285; total_step: 52200, loss: 1.651423497579787, nll: 1.011988125253577\n",
      "Epoch: 285; total_step: 52250, loss: 1.6363816749905447, nll: 1.1106136570251604\n",
      "Epoch: 285; total_step: 52300, loss: 1.6258204685741395, nll: 1.1039388051510626\n",
      "Epoch: 286; total_step: 52350, loss: 1.6272968428914494, nll: 1.1404803122290146\n",
      "Epoch: 286; total_step: 52400, loss: 1.6764321565018632, nll: 1.109344274828854\n",
      "Epoch: 286; total_step: 52450, loss: 1.8880546297563752, nll: 1.1902260929790311\n",
      "Epoch: 286; total_step: 52500, loss: 1.6672307903982633, nll: 1.2244567708504834\n",
      "Epoch: 287; total_step: 52550, loss: 1.7136312077920735, nll: 1.256570146978954\n",
      "Epoch: 287; total_step: 52600, loss: 1.7948285462004585, nll: 1.4755087173156158\n",
      "Epoch: 287; total_step: 52650, loss: 1.6678003155930177, nll: 1.0849373326874785\n",
      "Epoch: 287; total_step: 52700, loss: 1.5986855851717043, nll: 1.1138414116773765\n",
      "Epoch: 288; total_step: 52750, loss: 1.7091399260975073, nll: 1.065593687830046\n",
      "Epoch: 288; total_step: 52800, loss: 1.6685308628348259, nll: 1.1655437148576897\n",
      "Epoch: 288; total_step: 52850, loss: 1.5814846263954618, nll: 1.1101666692120273\n",
      "Epoch: 289; total_step: 52900, loss: 1.7088186108457901, nll: 1.1499378321582245\n",
      "Epoch: 289; total_step: 52950, loss: 1.6458547727211188, nll: 1.0974248888865905\n",
      "Epoch: 289; total_step: 53000, loss: 1.616044823025988, nll: 1.1007883691380516\n",
      "Epoch: 289; total_step: 53050, loss: 1.7574130974267284, nll: 1.1104448938533327\n",
      "Epoch: 290; total_step: 53100, loss: 1.686443628048222, nll: 1.1392958617655358\n",
      "Epoch: 290; total_step: 53150, loss: 1.7065405155120386, nll: 1.1863877482753231\n",
      "Epoch: 290; total_step: 53200, loss: 1.715837113483891, nll: 1.164905287139488\n",
      "Epoch: 290; total_step: 53250, loss: 1.658315158855707, nll: 1.1436229388988604\n",
      "Epoch: 291; total_step: 53300, loss: 1.6960750848451795, nll: 1.0724120032567184\n",
      "Epoch: 291; total_step: 53350, loss: 1.6531505400822033, nll: 1.1603873335383983\n",
      "Epoch: 291; total_step: 53400, loss: 1.6297344890095098, nll: 1.172338988945707\n",
      "Epoch: 292; total_step: 53450, loss: 1.6993430223134243, nll: 1.198702440388682\n",
      "Epoch: 292; total_step: 53500, loss: 1.758141651611001, nll: 1.1133322643564822\n",
      "Epoch: 292; total_step: 53550, loss: 1.7515954190272205, nll: 1.2807961693666812\n",
      "Epoch: 292; total_step: 53600, loss: 1.6661219334469337, nll: 1.0929588414407017\n",
      "Epoch: 293; total_step: 53650, loss: 1.671469803956856, nll: 1.0693254912197756\n",
      "Epoch: 293; total_step: 53700, loss: 1.6380099278684634, nll: 1.2586461663263748\n",
      "Epoch: 293; total_step: 53750, loss: 1.7078031294277878, nll: 1.1562185614452116\n",
      "Epoch: 293; total_step: 53800, loss: 1.610942316397224, nll: 1.2105735677603642\n",
      "Epoch: 294; total_step: 53850, loss: 1.6371046787672343, nll: 0.9349758706671479\n",
      "Epoch: 294; total_step: 53900, loss: 1.5978907507957012, nll: 1.1358770570773218\n",
      "Epoch: 294; total_step: 53950, loss: 1.6702164163889994, nll: 1.3061683663807042\n",
      "Epoch: 295; total_step: 54000, loss: 1.7356882614571227, nll: 1.317424585964383\n",
      "Epoch: 295; total_step: 54050, loss: 1.6552359510224144, nll: 1.125317155853234\n",
      "Epoch: 295; total_step: 54100, loss: 1.695723159587196, nll: 1.1858783656060023\n",
      "Epoch: 295; total_step: 54150, loss: 1.694718254858553, nll: 1.0491811874105654\n",
      "Epoch: 296; total_step: 54200, loss: 1.673402719964097, nll: 1.0874881297937036\n",
      "Epoch: 296; total_step: 54250, loss: 1.7280626738713067, nll: 1.206891384726672\n",
      "Epoch: 296; total_step: 54300, loss: 1.580974540013442, nll: 1.0909852398680755\n",
      "Epoch: 296; total_step: 54350, loss: 1.7177244572736228, nll: 1.2932999789674182\n",
      "Epoch: 297; total_step: 54400, loss: 1.66036776926732, nll: 1.1289890504987514\n",
      "Epoch: 297; total_step: 54450, loss: 1.7369603246701433, nll: 1.2203062123468946\n",
      "Epoch: 297; total_step: 54500, loss: 1.6999002940285595, nll: 1.0974987561134373\n",
      "Epoch: 298; total_step: 54550, loss: 1.6355013486619876, nll: 1.059938121351165\n",
      "Epoch: 298; total_step: 54600, loss: 1.7888989482407605, nll: 1.2831627918238535\n",
      "Epoch: 298; total_step: 54650, loss: 1.6917375507924493, nll: 1.191648632027998\n",
      "Epoch: 298; total_step: 54700, loss: 1.7094859499966801, nll: 1.394430471942535\n",
      "Epoch: 299; total_step: 54750, loss: 1.6522185001936804, nll: 1.162358408122208\n",
      "Epoch: 299; total_step: 54800, loss: 1.7120115285563329, nll: 1.2395321105077286\n",
      "Epoch: 299; total_step: 54850, loss: 1.6930027432996917, nll: 1.2121253909612268\n",
      "Epoch: 300; total_step: 54900, loss: 1.6983695641633574, nll: 1.1956704688743858\n",
      "Epoch: 300; total_step: 54950, loss: 1.7337861223717257, nll: 1.2748058529317687\n",
      "Epoch: 300; total_step: 55000, loss: 1.7121122079889273, nll: 1.1827338911987344\n",
      "Epoch: 300; total_step: 55050, loss: 1.700528821529578, nll: 1.2309606949745977\n",
      "Epoch: 301; total_step: 55100, loss: 1.646441984676127, nll: 1.1037244030865492\n",
      "Epoch: 301; total_step: 55150, loss: 1.79021548877871, nll: 1.2419845187427772\n",
      "Epoch: 301; total_step: 55200, loss: 1.6806639445534353, nll: 1.1679159048483185\n",
      "Epoch: 301; total_step: 55250, loss: 1.6710703538348906, nll: 1.1656374821927733\n",
      "Epoch: 302; total_step: 55300, loss: 1.705272197838151, nll: 1.09583220012911\n",
      "Epoch: 302; total_step: 55350, loss: 1.6460274271484285, nll: 1.0610207354591423\n",
      "Epoch: 302; total_step: 55400, loss: 1.6691215823850791, nll: 1.1760562076261005\n",
      "Epoch: 303; total_step: 55450, loss: 1.7014330919952871, nll: 1.1569029145763454\n",
      "Epoch: 303; total_step: 55500, loss: 1.6807141568504418, nll: 1.168046111922898\n",
      "Epoch: 303; total_step: 55550, loss: 1.6564313515517262, nll: 1.2003492636505813\n",
      "Epoch: 303; total_step: 55600, loss: 1.6682184419848614, nll: 1.085021313919703\n",
      "Epoch: 304; total_step: 55650, loss: 1.677214194077228, nll: 1.154629943653183\n",
      "Epoch: 304; total_step: 55700, loss: 1.642959533751841, nll: 1.0525997937513272\n",
      "Epoch: 304; total_step: 55750, loss: 1.6906953406296537, nll: 1.1755045868630907\n",
      "Epoch: 304; total_step: 55800, loss: 1.652441741179955, nll: 1.1277777082510723\n",
      "Epoch: 305; total_step: 55850, loss: 1.7073347807826884, nll: 1.218669631353095\n",
      "Epoch: 305; total_step: 55900, loss: 1.7344769019469704, nll: 1.4303667962270443\n",
      "Epoch: 305; total_step: 55950, loss: 1.6805561456228484, nll: 1.1795986526573061\n",
      "Epoch: 306; total_step: 56000, loss: 1.6055662494370961, nll: 1.1900142270783824\n",
      "Epoch: 306; total_step: 56050, loss: 1.6912763647911304, nll: 1.1388017975651321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 306; total_step: 56100, loss: 1.720756542237445, nll: 1.289038496791467\n",
      "Epoch: 306; total_step: 56150, loss: 1.6459479880257089, nll: 1.1746836884474925\n",
      "Epoch: 307; total_step: 56200, loss: 1.614653100250991, nll: 1.1259246811142736\n",
      "Epoch: 307; total_step: 56250, loss: 1.6244587231219334, nll: 1.117871642601186\n",
      "Epoch: 307; total_step: 56300, loss: 1.7255389996844122, nll: 1.1259222649138507\n",
      "Epoch: 307; total_step: 56350, loss: 1.6439072254954954, nll: 1.0368041043725102\n",
      "Epoch: 308; total_step: 56400, loss: 1.712695632931019, nll: 1.1956018325778697\n",
      "Epoch: 308; total_step: 56450, loss: 1.6400820483036682, nll: 1.0597889570034438\n",
      "Epoch: 308; total_step: 56500, loss: 1.5787198934054487, nll: 1.064285073671678\n",
      "Epoch: 309; total_step: 56550, loss: 1.62207834218671, nll: 1.0847425019881054\n",
      "Epoch: 309; total_step: 56600, loss: 1.7367155086738422, nll: 1.0653908658015203\n",
      "Epoch: 309; total_step: 56650, loss: 1.651451666777605, nll: 1.261682569184644\n",
      "Epoch: 309; total_step: 56700, loss: 1.6599759343948637, nll: 0.9534880169345497\n",
      "Epoch: 310; total_step: 56750, loss: 1.6835969077993018, nll: 1.261691459277405\n",
      "Epoch: 310; total_step: 56800, loss: 1.7242532044889427, nll: 1.164519704407429\n",
      "Epoch: 310; total_step: 56850, loss: 1.7588869953501298, nll: 1.3584206757265287\n",
      "Epoch: 310; total_step: 56900, loss: 1.6302015595914363, nll: 1.0771147956329603\n",
      "Epoch: 311; total_step: 56950, loss: 1.6192499182911069, nll: 1.0797153315632457\n",
      "Epoch: 311; total_step: 57000, loss: 1.7642468334754053, nll: 1.2628556042126828\n",
      "Epoch: 311; total_step: 57050, loss: 1.6639988509289725, nll: 1.1872102629830137\n",
      "Epoch: 312; total_step: 57100, loss: 1.7423005319265064, nll: 1.2484325552210196\n",
      "Epoch: 312; total_step: 57150, loss: 1.7212993401346341, nll: 1.0809576364339983\n",
      "Epoch: 312; total_step: 57200, loss: 1.5821460596231594, nll: 1.155435042650327\n",
      "Epoch: 312; total_step: 57250, loss: 1.7107524887988657, nll: 1.1338468340731216\n",
      "Epoch: 313; total_step: 57300, loss: 1.6536774004627837, nll: 1.0638850715975927\n",
      "Epoch: 313; total_step: 57350, loss: 1.6634017469004914, nll: 1.158226705032403\n",
      "Epoch: 313; total_step: 57400, loss: 1.6993648233337717, nll: 1.1566531658814492\n",
      "Epoch: 313; total_step: 57450, loss: 1.623712390026119, nll: 1.1482860358844624\n",
      "Epoch: 314; total_step: 57500, loss: 1.6818797054837793, nll: 1.141837845400866\n",
      "Epoch: 314; total_step: 57550, loss: 1.757210240880237, nll: 1.3756121451036993\n",
      "Epoch: 314; total_step: 57600, loss: 1.6872627078848308, nll: 1.0844289558822953\n",
      "Epoch: 315; total_step: 57650, loss: 1.740735293206636, nll: 1.2979893363090511\n",
      "Epoch: 315; total_step: 57700, loss: 1.6571571245574859, nll: 1.0900292919212138\n",
      "Epoch: 315; total_step: 57750, loss: 1.7163614363702544, nll: 1.1313281006822382\n",
      "Epoch: 315; total_step: 57800, loss: 1.6741973211847694, nll: 1.202123690726112\n",
      "Epoch: 316; total_step: 57850, loss: 1.6581497873934938, nll: 1.1641839042185318\n",
      "Epoch: 316; total_step: 57900, loss: 1.587618385662385, nll: 1.0801345392423392\n",
      "Epoch: 316; total_step: 57950, loss: 1.7502323499175296, nll: 1.2867999344935552\n",
      "Epoch: 316; total_step: 58000, loss: 1.767301303971226, nll: 1.2553504510569449\n",
      "Epoch: 317; total_step: 58050, loss: 1.6949021290259896, nll: 1.1736081246466508\n",
      "Epoch: 317; total_step: 58100, loss: 1.7007971357644005, nll: 1.1861115924097272\n",
      "Epoch: 317; total_step: 58150, loss: 1.6714388029497158, nll: 1.0784702961722643\n",
      "Epoch: 318; total_step: 58200, loss: 1.7130110825771308, nll: 1.1673325979498275\n",
      "Epoch: 318; total_step: 58250, loss: 1.6671688314880029, nll: 1.0677845859201478\n",
      "Epoch: 318; total_step: 58300, loss: 1.6238635848241243, nll: 1.1896141412618149\n",
      "Epoch: 318; total_step: 58350, loss: 1.664894535912009, nll: 1.1276445916499511\n",
      "Epoch: 319; total_step: 58400, loss: 1.6401903660867174, nll: 1.1617850685389086\n",
      "Epoch: 319; total_step: 58450, loss: 1.752379576982467, nll: 1.2291870168221974\n",
      "Epoch: 319; total_step: 58500, loss: 1.6715307339002712, nll: 1.315946158485654\n",
      "Epoch: 319; total_step: 58550, loss: 1.6664248517116456, nll: 1.1676074552396303\n",
      "Epoch: 320; total_step: 58600, loss: 1.6966522513891957, nll: 1.1331562163521467\n",
      "Epoch: 320; total_step: 58650, loss: 1.625342786532952, nll: 1.0495043152691557\n",
      "Epoch: 320; total_step: 58700, loss: 1.7249567042204654, nll: 1.244205444137634\n",
      "Epoch: 321; total_step: 58750, loss: 1.6828889403193958, nll: 1.2022593044371719\n",
      "Epoch: 321; total_step: 58800, loss: 1.7657946693650268, nll: 1.3141789589242647\n",
      "Epoch: 321; total_step: 58850, loss: 1.6955359759032553, nll: 1.2574906894135816\n",
      "Epoch: 321; total_step: 58900, loss: 1.7906445570152432, nll: 1.2256127572909619\n",
      "Epoch: 322; total_step: 58950, loss: 1.5677975398652892, nll: 1.0050386743228343\n",
      "Epoch: 322; total_step: 59000, loss: 1.6707349764890405, nll: 1.044357238875759\n",
      "Epoch: 322; total_step: 59050, loss: 1.8020696866896082, nll: 1.3391054037113819\n",
      "Epoch: 322; total_step: 59100, loss: 1.7020347766027424, nll: 1.1581121738847866\n",
      "Epoch: 323; total_step: 59150, loss: 1.6765925900388094, nll: 1.1682362897059662\n",
      "Epoch: 323; total_step: 59200, loss: 1.6910677301507224, nll: 1.152900392800919\n",
      "Epoch: 323; total_step: 59250, loss: 1.7750406454564394, nll: 1.281867104590288\n",
      "Epoch: 324; total_step: 59300, loss: 1.7354063596714489, nll: 1.261884073086469\n",
      "Epoch: 324; total_step: 59350, loss: 1.7268562500549558, nll: 1.1598036194572627\n",
      "Epoch: 324; total_step: 59400, loss: 1.7115025707926383, nll: 1.1285466988701833\n",
      "Epoch: 324; total_step: 59450, loss: 1.7706559768019638, nll: 1.2842405096193041\n",
      "Epoch: 325; total_step: 59500, loss: 1.6009730714431836, nll: 1.0707982401712643\n",
      "Epoch: 325; total_step: 59550, loss: 1.5943693948252637, nll: 1.0579677642029814\n",
      "Epoch: 325; total_step: 59600, loss: 1.7646758751410443, nll: 1.2125724108675004\n",
      "Epoch: 325; total_step: 59650, loss: 1.699570783185456, nll: 1.2215204203075831\n",
      "Epoch: 326; total_step: 59700, loss: 1.6758198197639058, nll: 1.2439164752158807\n",
      "Epoch: 326; total_step: 59750, loss: 1.6603030725259484, nll: 1.182573718729244\n",
      "Epoch: 326; total_step: 59800, loss: 1.6480614420091364, nll: 1.1486630299028668\n",
      "Epoch: 327; total_step: 59850, loss: 1.7337355553416376, nll: 1.2192182825276703\n",
      "Epoch: 327; total_step: 59900, loss: 1.6950080846851525, nll: 1.2500770685511324\n",
      "Epoch: 327; total_step: 59950, loss: 1.721367364644083, nll: 1.2200015197409166\n",
      "Epoch: 327; total_step: 60000, loss: 1.6627924718783182, nll: 1.0749019265743511\n",
      "Epoch: 328; total_step: 60050, loss: 1.6759543234422225, nll: 1.2094314466690304\n",
      "Epoch: 328; total_step: 60100, loss: 1.7123270367734804, nll: 1.2045261993282137\n",
      "Epoch: 328; total_step: 60150, loss: 1.6897390994016233, nll: 1.1660392392223458\n",
      "Epoch: 328; total_step: 60200, loss: 1.611012064178636, nll: 1.1050815627322008\n",
      "Epoch: 329; total_step: 60250, loss: 1.6071402504331473, nll: 1.048988688696424\n",
      "Epoch: 329; total_step: 60300, loss: 1.5620643008276696, nll: 1.0881661021979228\n",
      "Epoch: 329; total_step: 60350, loss: 1.698317185571343, nll: 1.1650129083277714\n",
      "Epoch: 330; total_step: 60400, loss: 1.6840215931351303, nll: 1.2515366939636745\n",
      "Epoch: 330; total_step: 60450, loss: 1.7452923133284042, nll: 1.2325752915363366\n",
      "Epoch: 330; total_step: 60500, loss: 1.6367092829041043, nll: 1.1227055015242682\n",
      "Epoch: 330; total_step: 60550, loss: 1.6580337795018847, nll: 1.0899727924687486\n",
      "Epoch: 331; total_step: 60600, loss: 1.7030250978367376, nll: 1.1059190647952108\n",
      "Epoch: 331; total_step: 60650, loss: 1.5827464413643657, nll: 0.9957330745115904\n",
      "Epoch: 331; total_step: 60700, loss: 1.6334554222429387, nll: 1.1979962140334457\n",
      "Epoch: 331; total_step: 60750, loss: 1.6923022664457177, nll: 1.2249041947499606\n",
      "Epoch: 332; total_step: 60800, loss: 1.594605888567022, nll: 1.0885286449443647\n",
      "Epoch: 332; total_step: 60850, loss: 1.7291580270222893, nll: 1.1927213639559788\n",
      "Epoch: 332; total_step: 60900, loss: 1.6869932164789336, nll: 1.1863676031411186\n",
      "Epoch: 333; total_step: 60950, loss: 1.6391342640181585, nll: 1.106245260603301\n",
      "Epoch: 333; total_step: 61000, loss: 1.6479234553007165, nll: 1.0974232440944027\n",
      "Epoch: 333; total_step: 61050, loss: 1.7000017520127262, nll: 1.163185972438316\n",
      "Epoch: 333; total_step: 61100, loss: 1.6413188586659293, nll: 1.175051673758837\n",
      "Epoch: 334; total_step: 61150, loss: 1.714230323751452, nll: 1.0600089765632648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 334; total_step: 61200, loss: 1.7238270907335453, nll: 1.2384418760716758\n",
      "Epoch: 334; total_step: 61250, loss: 1.6617716355344032, nll: 1.0506151709261802\n",
      "Epoch: 334; total_step: 61300, loss: 1.6547344041304075, nll: 1.0829338987615287\n",
      "Epoch: 335; total_step: 61350, loss: 1.7283068475584507, nll: 1.3079322409558387\n",
      "Epoch: 335; total_step: 61400, loss: 1.6494100344379772, nll: 1.1399314026439835\n",
      "Epoch: 335; total_step: 61450, loss: 1.6615315388118332, nll: 1.0855957175794244\n",
      "Epoch: 336; total_step: 61500, loss: 1.696749364895376, nll: 1.2103296128411998\n",
      "Epoch: 336; total_step: 61550, loss: 1.6358651741932624, nll: 1.0454304208163037\n",
      "Epoch: 336; total_step: 61600, loss: 1.7323481805305248, nll: 1.1716733921178137\n",
      "Epoch: 336; total_step: 61650, loss: 1.7619328964641414, nll: 1.223404837225651\n",
      "Epoch: 337; total_step: 61700, loss: 1.7426365553564165, nll: 1.1719169903093374\n",
      "Epoch: 337; total_step: 61750, loss: 1.6354015387123662, nll: 1.0378479855944556\n",
      "Epoch: 337; total_step: 61800, loss: 1.6720855551368683, nll: 1.1848645386248415\n",
      "Epoch: 337; total_step: 61850, loss: 1.7055840388997436, nll: 1.1305764938612537\n",
      "Epoch: 338; total_step: 61900, loss: 1.6619432402194108, nll: 1.2765356655138356\n",
      "Epoch: 338; total_step: 61950, loss: 1.7588440726192425, nll: 1.3061445444977973\n",
      "Epoch: 338; total_step: 62000, loss: 1.598973736535462, nll: 1.0581365834025076\n",
      "Epoch: 339; total_step: 62050, loss: 1.6519819316701108, nll: 1.1443658871942821\n",
      "Epoch: 339; total_step: 62100, loss: 1.6491938593280906, nll: 1.183244571108662\n",
      "Epoch: 339; total_step: 62150, loss: 1.706931891386689, nll: 1.179250216820119\n",
      "Epoch: 339; total_step: 62200, loss: 1.6091603981065752, nll: 1.1075492433726648\n",
      "Epoch: 340; total_step: 62250, loss: 1.7113647211201475, nll: 1.2478017921655817\n",
      "Epoch: 340; total_step: 62300, loss: 1.6361387930481657, nll: 1.0935422969708168\n",
      "Epoch: 340; total_step: 62350, loss: 1.5853332866310534, nll: 1.0054767768624417\n",
      "Epoch: 340; total_step: 62400, loss: 1.7614428822921502, nll: 1.2549728501567885\n",
      "Epoch: 341; total_step: 62450, loss: 1.7186154840293348, nll: 1.4262856849241534\n",
      "Epoch: 341; total_step: 62500, loss: 1.7399499477957574, nll: 1.1376536643239747\n",
      "Epoch: 341; total_step: 62550, loss: 1.6931174056407428, nll: 1.258862338692734\n",
      "Epoch: 342; total_step: 62600, loss: 1.5863464398968912, nll: 1.006703693473669\n",
      "Epoch: 342; total_step: 62650, loss: 1.6470657021290094, nll: 1.2937884454882185\n",
      "Epoch: 342; total_step: 62700, loss: 1.6604917964296062, nll: 1.2098233104167686\n",
      "Epoch: 342; total_step: 62750, loss: 1.6465191880127632, nll: 1.1759513050425698\n",
      "Epoch: 343; total_step: 62800, loss: 1.6247487607520077, nll: 1.1328414735053505\n",
      "Epoch: 343; total_step: 62850, loss: 1.8631281865250005, nll: 1.3859825413661377\n",
      "Epoch: 343; total_step: 62900, loss: 1.607216264366956, nll: 1.0794714084921364\n",
      "Epoch: 343; total_step: 62950, loss: 1.7483131152869413, nll: 1.1855027560253104\n",
      "Epoch: 344; total_step: 63000, loss: 1.7062291332647141, nll: 1.2145004082192994\n",
      "Epoch: 344; total_step: 63050, loss: 1.6936183562083753, nll: 1.1938746745141002\n",
      "Epoch: 344; total_step: 63100, loss: 1.6443022280249122, nll: 1.2190169757907015\n",
      "Epoch: 345; total_step: 63150, loss: 1.7141908950391178, nll: 1.1989766183809385\n",
      "Epoch: 345; total_step: 63200, loss: 1.7100677715270092, nll: 1.1927544713985294\n",
      "Epoch: 345; total_step: 63250, loss: 1.6335197852396832, nll: 1.2000939686662933\n",
      "Epoch: 345; total_step: 63300, loss: 1.6481553660789963, nll: 1.164599830406108\n",
      "Epoch: 346; total_step: 63350, loss: 1.7145602184017097, nll: 1.1378295999448753\n",
      "Epoch: 346; total_step: 63400, loss: 1.7043393475486246, nll: 1.2709720188336118\n",
      "Epoch: 346; total_step: 63450, loss: 1.6717795325340221, nll: 1.2226186358327717\n",
      "Epoch: 346; total_step: 63500, loss: 1.6727980390968045, nll: 1.3479540198073983\n",
      "Epoch: 347; total_step: 63550, loss: 1.72911327774376, nll: 1.1784127748314563\n",
      "Epoch: 347; total_step: 63600, loss: 1.6574681295125788, nll: 1.1269132076023596\n",
      "Epoch: 347; total_step: 63650, loss: 1.7571002099772488, nll: 1.1891801257937946\n",
      "Epoch: 348; total_step: 63700, loss: 1.6446850799214456, nll: 1.2072939663006934\n",
      "Epoch: 348; total_step: 63750, loss: 1.698549542498181, nll: 1.1433050890282157\n",
      "Epoch: 348; total_step: 63800, loss: 1.6026296490147056, nll: 1.2026517785624227\n",
      "Epoch: 348; total_step: 63850, loss: 1.7336586174608806, nll: 1.1429915079322537\n",
      "Epoch: 349; total_step: 63900, loss: 1.6648478397082735, nll: 1.2520908735909977\n",
      "Epoch: 349; total_step: 63950, loss: 1.6620135358873853, nll: 1.0683539571979423\n",
      "Epoch: 349; total_step: 64000, loss: 1.6966904425295906, nll: 1.2845481984159586\n",
      "Epoch: 350; total_step: 64050, loss: 1.6904982187955664, nll: 1.2402822574979233\n",
      "Epoch: 350; total_step: 64100, loss: 1.7116652611559493, nll: 1.1821842355615335\n",
      "Epoch: 350; total_step: 64150, loss: 1.6959317834257122, nll: 1.2642885423721442\n",
      "Epoch: 350; total_step: 64200, loss: 1.6490246445014913, nll: 1.2441865367634473\n",
      "Epoch: 351; total_step: 64250, loss: 1.782444191072755, nll: 1.1932846284847753\n",
      "Epoch: 351; total_step: 64300, loss: 1.6520234028176235, nll: 1.0426579055465783\n",
      "Epoch: 351; total_step: 64350, loss: 1.6821415015493955, nll: 1.1680756729564072\n",
      "Epoch: 351; total_step: 64400, loss: 1.6820508758359634, nll: 1.17315203089313\n",
      "Epoch: 352; total_step: 64450, loss: 1.6572485264603398, nll: 1.0947175636063877\n",
      "Epoch: 352; total_step: 64500, loss: 1.6815578390722197, nll: 1.183757654355442\n",
      "Epoch: 352; total_step: 64550, loss: 1.6732038754467495, nll: 1.1686325533285724\n",
      "Epoch: 353; total_step: 64600, loss: 1.6643495815253055, nll: 1.09237198027392\n",
      "Epoch: 353; total_step: 64650, loss: 1.6393210455073526, nll: 1.2050593740681437\n",
      "Epoch: 353; total_step: 64700, loss: 1.6783195253731968, nll: 1.1345034672197623\n",
      "Epoch: 353; total_step: 64750, loss: 1.7299284983727017, nll: 1.4541233879958007\n",
      "Epoch: 354; total_step: 64800, loss: 1.6971364965222795, nll: 1.1152065056094995\n",
      "Epoch: 354; total_step: 64850, loss: 1.7277699147971766, nll: 1.1926684246287271\n",
      "Epoch: 354; total_step: 64900, loss: 1.6828009158031116, nll: 1.277998685813523\n",
      "Epoch: 354; total_step: 64950, loss: 1.730706344262384, nll: 1.0919625880046506\n",
      "Epoch: 355; total_step: 65000, loss: 1.6499596342732974, nll: 1.10383895855008\n",
      "Epoch: 355; total_step: 65050, loss: 1.6980611004921706, nll: 1.3449956062788104\n",
      "Epoch: 355; total_step: 65100, loss: 1.6321988684221465, nll: 1.0998761032130038\n",
      "Epoch: 356; total_step: 65150, loss: 1.773540540032684, nll: 1.3678270748488097\n",
      "Epoch: 356; total_step: 65200, loss: 1.6244065281952569, nll: 1.1285325984403751\n",
      "Epoch: 356; total_step: 65250, loss: 1.8047240660851238, nll: 1.210016414021275\n",
      "Epoch: 356; total_step: 65300, loss: 1.6832241642998214, nll: 1.1827683557442692\n",
      "Epoch: 357; total_step: 65350, loss: 1.6820751650669123, nll: 1.170841657101148\n",
      "Epoch: 357; total_step: 65400, loss: 1.7845686798253824, nll: 1.1632399787160044\n",
      "Epoch: 357; total_step: 65450, loss: 1.6226956871738798, nll: 1.1617360078066497\n",
      "Epoch: 357; total_step: 65500, loss: 1.7177752156432593, nll: 1.2120879896040981\n",
      "Epoch: 358; total_step: 65550, loss: 1.6820237001018636, nll: 1.0752547454638282\n",
      "Epoch: 358; total_step: 65600, loss: 1.6864390667041949, nll: 1.1216773441050698\n",
      "Epoch: 358; total_step: 65650, loss: 1.6500167878906953, nll: 1.1031737250459663\n",
      "Epoch: 359; total_step: 65700, loss: 1.6654312866404097, nll: 1.12552571836616\n",
      "Epoch: 359; total_step: 65750, loss: 1.5997121601088542, nll: 1.1044747464609068\n",
      "Epoch: 359; total_step: 65800, loss: 1.7002420484856204, nll: 1.090216170638688\n",
      "Epoch: 359; total_step: 65850, loss: 1.5955062348363203, nll: 1.1446359781199913\n",
      "Epoch: 360; total_step: 65900, loss: 1.650604039259901, nll: 1.2433834029934896\n",
      "Epoch: 360; total_step: 65950, loss: 1.6696720435697836, nll: 1.149822787917947\n",
      "Epoch: 360; total_step: 66000, loss: 1.7287097654062462, nll: 1.186951267011778\n",
      "Epoch: 360; total_step: 66050, loss: 1.7517299353037812, nll: 1.3398821466084085\n",
      "Epoch: 361; total_step: 66100, loss: 1.7484071536481778, nll: 1.2200064644119137\n",
      "Epoch: 361; total_step: 66150, loss: 1.7410084649704243, nll: 1.0217187748182535\n",
      "Epoch: 361; total_step: 66200, loss: 1.6595545583408644, nll: 1.193178274322065\n",
      "Epoch: 362; total_step: 66250, loss: 1.7103600072892189, nll: 1.224240377952765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 362; total_step: 66300, loss: 1.7065070021668478, nll: 1.1104754885867585\n",
      "Epoch: 362; total_step: 66350, loss: 1.732520479085917, nll: 1.1652223071325176\n",
      "Epoch: 362; total_step: 66400, loss: 1.672301438381088, nll: 1.0906285721626474\n",
      "Epoch: 363; total_step: 66450, loss: 1.64466011441246, nll: 1.1900258710668559\n",
      "Epoch: 363; total_step: 66500, loss: 1.7039197359248843, nll: 1.1709838241746644\n",
      "Epoch: 363; total_step: 66550, loss: 1.699154272593745, nll: 1.078924841454866\n",
      "Epoch: 363; total_step: 66600, loss: 1.6420039940469926, nll: 1.089630928287124\n",
      "Epoch: 364; total_step: 66650, loss: 1.6351752894213711, nll: 1.1903652932239324\n",
      "Epoch: 364; total_step: 66700, loss: 1.751857472784077, nll: 1.3219817259085311\n",
      "Epoch: 364; total_step: 66750, loss: 1.620276738641535, nll: 1.1718197649947584\n",
      "Epoch: 365; total_step: 66800, loss: 1.7657421063289294, nll: 1.1857430934338595\n",
      "Epoch: 365; total_step: 66850, loss: 1.7305765034556315, nll: 1.2827506986530834\n",
      "Epoch: 365; total_step: 66900, loss: 1.8098801319926292, nll: 1.331459688397091\n",
      "Epoch: 365; total_step: 66950, loss: 1.6850201057659486, nll: 1.09693098323994\n",
      "Epoch: 366; total_step: 67000, loss: 1.5785110632396127, nll: 1.0222826550935236\n",
      "Epoch: 366; total_step: 67050, loss: 1.691249070486217, nll: 1.3023607944109674\n",
      "Epoch: 366; total_step: 67100, loss: 1.67935381309357, nll: 1.2433697237479406\n",
      "Epoch: 366; total_step: 67150, loss: 1.652817868763073, nll: 1.0797945296560343\n",
      "Epoch: 367; total_step: 67200, loss: 1.715912825333448, nll: 1.102068214338972\n",
      "Epoch: 367; total_step: 67250, loss: 1.7571803116150415, nll: 1.2609420045185857\n",
      "Epoch: 367; total_step: 67300, loss: 1.6682966234528924, nll: 1.0753083179092093\n",
      "Epoch: 368; total_step: 67350, loss: 1.6717428413296866, nll: 1.2271133744197915\n",
      "Epoch: 368; total_step: 67400, loss: 1.6567786640244873, nll: 1.1601584568601913\n",
      "Epoch: 368; total_step: 67450, loss: 1.7115889279250223, nll: 1.1872493732226785\n",
      "Epoch: 368; total_step: 67500, loss: 1.63653544530047, nll: 1.1126935070566417\n",
      "Epoch: 369; total_step: 67550, loss: 1.6372950240067343, nll: 1.183872903731794\n",
      "Epoch: 369; total_step: 67600, loss: 1.6515509227172191, nll: 1.075238290496057\n",
      "Epoch: 369; total_step: 67650, loss: 1.743034650302109, nll: 1.4628237613755823\n",
      "Epoch: 369; total_step: 67700, loss: 1.7537144526033046, nll: 1.206464505959121\n",
      "Epoch: 370; total_step: 67750, loss: 1.7276083406542666, nll: 1.1948296631127155\n",
      "Epoch: 370; total_step: 67800, loss: 1.7686151503076233, nll: 1.1928418023554426\n",
      "Epoch: 370; total_step: 67850, loss: 1.6212452045015908, nll: 1.1766534212871633\n",
      "Epoch: 371; total_step: 67900, loss: 1.6877941981326132, nll: 1.0341636824721776\n",
      "Epoch: 371; total_step: 67950, loss: 1.730506589297985, nll: 1.2909372516848372\n",
      "Epoch: 371; total_step: 68000, loss: 1.7304392012210412, nll: 1.1195378479509912\n",
      "Epoch: 371; total_step: 68050, loss: 1.7312963055547437, nll: 1.2085206515163616\n",
      "Epoch: 372; total_step: 68100, loss: 1.6537675667076228, nll: 1.1648948425766659\n",
      "Epoch: 372; total_step: 68150, loss: 1.6794719109175185, nll: 1.255665552975187\n",
      "Epoch: 372; total_step: 68200, loss: 1.6127252193413153, nll: 0.9939161614899755\n",
      "Epoch: 372; total_step: 68250, loss: 1.635955192631771, nll: 1.1480680272911168\n",
      "Epoch: 373; total_step: 68300, loss: 1.7281804344158027, nll: 1.1700761752085795\n",
      "Epoch: 373; total_step: 68350, loss: 1.7118157983589941, nll: 1.2504339843918868\n",
      "Epoch: 373; total_step: 68400, loss: 1.6842998364450086, nll: 1.1660226586254447\n",
      "Epoch: 374; total_step: 68450, loss: 1.6198840063367046, nll: 1.0495362373520791\n",
      "Epoch: 374; total_step: 68500, loss: 1.789844407584493, nll: 1.27235007002231\n",
      "Epoch: 374; total_step: 68550, loss: 1.589693358246674, nll: 1.149350151135502\n",
      "Epoch: 374; total_step: 68600, loss: 1.705237612190221, nll: 1.2245695309832119\n",
      "Epoch: 375; total_step: 68650, loss: 1.587271057241252, nll: 1.0740118530064233\n",
      "Epoch: 375; total_step: 68700, loss: 1.6369227320791095, nll: 1.0748545481733016\n",
      "Epoch: 375; total_step: 68750, loss: 1.6009661304099767, nll: 1.0993935168485423\n",
      "Epoch: 375; total_step: 68800, loss: 1.7013143382962794, nll: 1.1230585285238774\n",
      "Epoch: 376; total_step: 68850, loss: 1.7641454748740666, nll: 1.228474066668272\n",
      "Epoch: 376; total_step: 68900, loss: 1.659847855556532, nll: 1.0538885434196106\n",
      "Epoch: 376; total_step: 68950, loss: 1.6746467928470827, nll: 1.1884288397520413\n",
      "Epoch: 377; total_step: 69000, loss: 1.7202692713331138, nll: 1.184746701422865\n",
      "Epoch: 377; total_step: 69050, loss: 1.697335100628994, nll: 1.2127583257145622\n",
      "Epoch: 377; total_step: 69100, loss: 1.6693727644076466, nll: 1.1928439421720853\n",
      "Epoch: 377; total_step: 69150, loss: 1.6592472820325428, nll: 1.191150585346139\n",
      "Epoch: 378; total_step: 69200, loss: 1.554335667305553, nll: 1.0076829029026952\n",
      "Epoch: 378; total_step: 69250, loss: 1.7655471986900428, nll: 1.1999730500545691\n",
      "Epoch: 378; total_step: 69300, loss: 1.642917199474777, nll: 1.2808375810020023\n",
      "Epoch: 378; total_step: 69350, loss: 1.647683617420378, nll: 1.0762881639573951\n",
      "Epoch: 379; total_step: 69400, loss: 1.6406218490387356, nll: 1.1581106320787877\n",
      "Epoch: 379; total_step: 69450, loss: 1.7211350824434988, nll: 1.1689876067524736\n",
      "Epoch: 379; total_step: 69500, loss: 1.682298164695897, nll: 1.1705797491739318\n",
      "Epoch: 380; total_step: 69550, loss: 1.6321710652616468, nll: 1.1194827374098413\n",
      "Epoch: 380; total_step: 69600, loss: 1.608194769367474, nll: 1.1088200745537615\n",
      "Epoch: 380; total_step: 69650, loss: 1.6675108488212154, nll: 1.1444896795376012\n",
      "Epoch: 380; total_step: 69700, loss: 1.7256942834291584, nll: 1.1310536850162145\n",
      "Epoch: 381; total_step: 69750, loss: 1.7040126614674205, nll: 1.174090772437731\n",
      "Epoch: 381; total_step: 69800, loss: 1.6984093097364212, nll: 1.2463074428098067\n",
      "Epoch: 381; total_step: 69850, loss: 1.7673000112468682, nll: 1.2525376389660356\n",
      "Epoch: 381; total_step: 69900, loss: 1.7272769735327966, nll: 1.3739632741771786\n",
      "Epoch: 382; total_step: 69950, loss: 1.7192574659694408, nll: 1.0949236225560144\n",
      "Epoch: 382; total_step: 70000, loss: 1.7170290621550675, nll: 1.1697360961686305\n",
      "Epoch: 382; total_step: 70050, loss: 1.6927893829423466, nll: 1.0978874730448354\n",
      "Epoch: 383; total_step: 70100, loss: 1.7097820429027741, nll: 1.2603689885827472\n",
      "Epoch: 383; total_step: 70150, loss: 1.7247962901445049, nll: 1.1831681522833708\n",
      "Epoch: 383; total_step: 70200, loss: 1.6370600985061246, nll: 1.1340345865728703\n",
      "Epoch: 383; total_step: 70250, loss: 1.674941213473727, nll: 1.2361126733688115\n",
      "Epoch: 384; total_step: 70300, loss: 1.7287603622519794, nll: 1.3098360281542791\n",
      "Epoch: 384; total_step: 70350, loss: 1.673830900584305, nll: 1.2636889384363432\n",
      "Epoch: 384; total_step: 70400, loss: 1.7245917828554247, nll: 1.2073552880244618\n",
      "Epoch: 384; total_step: 70450, loss: 1.7300980874129066, nll: 1.1742366521328966\n",
      "Epoch: 385; total_step: 70500, loss: 1.7268534690613935, nll: 1.2765413242292831\n",
      "Epoch: 385; total_step: 70550, loss: 1.6726426534738266, nll: 1.0837145032762068\n",
      "Epoch: 385; total_step: 70600, loss: 1.627410192770819, nll: 1.144155652838351\n",
      "Epoch: 386; total_step: 70650, loss: 1.6314450823908129, nll: 1.1253098737058231\n",
      "Epoch: 386; total_step: 70700, loss: 1.6517416793654254, nll: 1.1810416830369372\n",
      "Epoch: 386; total_step: 70750, loss: 1.6441353936092435, nll: 1.1086170345690705\n",
      "Epoch: 386; total_step: 70800, loss: 1.689033053964531, nll: 1.1957418502355028\n",
      "Epoch: 387; total_step: 70850, loss: 1.682453856498864, nll: 1.0713847652978956\n",
      "Epoch: 387; total_step: 70900, loss: 1.6711016003131538, nll: 1.1254339376825833\n",
      "Epoch: 387; total_step: 70950, loss: 1.6370288926621068, nll: 1.060223444911638\n",
      "Epoch: 387; total_step: 71000, loss: 1.6986103668696921, nll: 1.0941336725650157\n",
      "Epoch: 388; total_step: 71050, loss: 1.6304616047134988, nll: 1.158984390701304\n",
      "Epoch: 388; total_step: 71100, loss: 1.7037881398463748, nll: 1.2702553207769147\n",
      "Epoch: 388; total_step: 71150, loss: 1.7498563074876845, nll: 1.3359471145120454\n",
      "Epoch: 389; total_step: 71200, loss: 1.709070893469593, nll: 1.0968163028457543\n",
      "Epoch: 389; total_step: 71250, loss: 1.6002503941392474, nll: 1.0934189121222668\n",
      "Epoch: 389; total_step: 71300, loss: 1.7439616189942726, nll: 1.1537884353397225\n",
      "Epoch: 389; total_step: 71350, loss: 1.8413538749675262, nll: 1.2394550459322853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 390; total_step: 71400, loss: 1.6711201283801531, nll: 1.158033140237762\n",
      "Epoch: 390; total_step: 71450, loss: 1.6592879368080662, nll: 1.1169881023327914\n",
      "Epoch: 390; total_step: 71500, loss: 1.7089538899630303, nll: 1.1141892102799933\n",
      "Epoch: 390; total_step: 71550, loss: 1.7174888427351467, nll: 1.144198989103378\n",
      "Epoch: 391; total_step: 71600, loss: 1.7262397548876927, nll: 1.3483994029586568\n",
      "Epoch: 391; total_step: 71650, loss: 1.684174752231155, nll: 1.0923819408702984\n",
      "Epoch: 391; total_step: 71700, loss: 1.8059428172763319, nll: 1.3915274806890985\n",
      "Epoch: 392; total_step: 71750, loss: 1.6683444362387316, nll: 1.1046929811055914\n",
      "Epoch: 392; total_step: 71800, loss: 1.697708924949026, nll: 1.2358139927166014\n",
      "Epoch: 392; total_step: 71850, loss: 1.6286581078321927, nll: 1.1535250183274053\n",
      "Epoch: 392; total_step: 71900, loss: 1.6443795475882832, nll: 1.2092535821010648\n",
      "Epoch: 393; total_step: 71950, loss: 1.6864186419919793, nll: 1.3268319095414705\n",
      "Epoch: 393; total_step: 72000, loss: 1.670404285239539, nll: 1.0696154587808469\n",
      "Epoch: 393; total_step: 72050, loss: 1.6152162216480606, nll: 1.0738818240273265\n",
      "Epoch: 393; total_step: 72100, loss: 1.6143162172793768, nll: 1.1154053340787948\n",
      "Epoch: 394; total_step: 72150, loss: 1.6403075399503484, nll: 1.1589568762387867\n",
      "Epoch: 394; total_step: 72200, loss: 1.7054876370201526, nll: 1.1156846233080113\n",
      "Epoch: 394; total_step: 72250, loss: 1.7215418524248622, nll: 1.2890815913781257\n",
      "Epoch: 395; total_step: 72300, loss: 1.6155485186473808, nll: 1.044872021047616\n",
      "Epoch: 395; total_step: 72350, loss: 1.6593883539984597, nll: 1.1374876847318036\n",
      "Epoch: 395; total_step: 72400, loss: 1.7439597644592157, nll: 1.1654943820121644\n",
      "Epoch: 395; total_step: 72450, loss: 1.7857026206580986, nll: 1.3526874056834737\n",
      "Epoch: 396; total_step: 72500, loss: 1.669204064552675, nll: 1.137153317723962\n",
      "Epoch: 396; total_step: 72550, loss: 1.6860358295676303, nll: 1.0761435932035177\n",
      "Epoch: 396; total_step: 72600, loss: 1.742387287970064, nll: 1.2433765394193852\n",
      "Epoch: 396; total_step: 72650, loss: 1.725122137616957, nll: 1.2707625158665858\n",
      "Epoch: 397; total_step: 72700, loss: 1.6493252645993137, nll: 1.110264542842535\n",
      "Epoch: 397; total_step: 72750, loss: 1.7035645896677485, nll: 1.1288542771850996\n",
      "Epoch: 397; total_step: 72800, loss: 1.6593084037579036, nll: 1.1561811953757593\n",
      "Epoch: 398; total_step: 72850, loss: 1.7191586875909777, nll: 1.2892979346288185\n",
      "Epoch: 398; total_step: 72900, loss: 1.6430385072749032, nll: 1.1495152005808753\n",
      "Epoch: 398; total_step: 72950, loss: 1.7329411245961455, nll: 1.1565880395565078\n",
      "Epoch: 398; total_step: 73000, loss: 1.6328566945451988, nll: 1.1964048555067495\n",
      "Epoch: 399; total_step: 73050, loss: 1.7934841671261221, nll: 1.2222416974354449\n",
      "Epoch: 399; total_step: 73100, loss: 1.7419497397305848, nll: 1.2202834886918181\n",
      "Epoch: 399; total_step: 73150, loss: 1.6318383992067789, nll: 1.1232619562568569\n",
      "Done! loss: 1.586625474592587\n",
      "\n",
      "Done Training!\n",
      "Done Testing!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1000) must match the size of tensor b (9146) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-a8d47eea597f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# compute MSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mtest_mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;31m# compute mean negative predictive density\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mtest_nll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\GP-Derivatives-Variational-Inference\\directionalvi\\utils\\metrics.py\u001b[0m in \u001b[0;36mMSE\u001b[1;34m(Y, Z)\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mZ\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \"\"\"\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mMAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (1000) must match the size of tensor b (9146) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# train\n",
    "print(\"\\n\\n---DirectionalGradVGP---\")\n",
    "print(f\"Start training with {n} trainig data of dim {dim}\")\n",
    "print(f\"VI setups: {num_inducing} inducing points, {num_directions} inducing directions\")\n",
    "args={\"verbose\":True}\n",
    "t1 = time.time()\t\n",
    "model,likelihood = train_gp(train_dataset,\n",
    "                      num_inducing=num_inducing,\n",
    "                      num_directions=num_directions,\n",
    "                      minibatch_size = minibatch_size,\n",
    "                      minibatch_dim = num_directions,\n",
    "                      num_epochs =num_epochs, \n",
    "                      learning_rate_hypers=learning_rate_hypers,\n",
    "                      learning_rate_ngd=learning_rate_ngd,\n",
    "                      inducing_data_initialization=inducing_data_initialization,\n",
    "                      use_ngd = use_ngd,\n",
    "                      use_ciq = use_ciq,\n",
    "                      lr_sched=lr_sched,\n",
    "                      num_contour_quadrature=num_contour_quadrature,\n",
    "                      tqdm=tqdm,**args\n",
    "                      )\n",
    "t2 = time.time()\t\n",
    "\n",
    "# save the model\n",
    "# torch.save(model.state_dict(), \"../data/test_dvi_basic.model\")\n",
    "\n",
    "# test\n",
    "means, variances = eval_gp( test_dataset,model,likelihood,\n",
    "                            num_directions=num_directions,\n",
    "                            minibatch_size=n_test,\n",
    "                            minibatch_dim=num_directions)\n",
    "t3 = time.time()\t\n",
    "\n",
    "# compute MSE\n",
    "test_y = test_y.cpu()\n",
    "test_mse = MSE(test_y,means)\n",
    "# compute mean negative predictive density\n",
    "test_nll = -torch.distributions.Normal(means, variances.sqrt()).log_prob(test_y).mean()\n",
    "print(f\"At {n_test} testing points, MSE: {test_mse:.4e}, nll: {test_nll:.4e}.\")\n",
    "print(f\"Training time: {(t2-t1):.2f} sec, testing time: {(t3-t2):.2f} sec\")\n",
    "\n",
    "plot=1\n",
    "if plot == 1:\n",
    "    from mpl_toolkits.mplot3d import axes3d\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(test_x[:,0],test_x[:,1],test_y, color='k')\n",
    "    ax.scatter(test_x[:,0],test_x[:,1],means, color='b')\n",
    "    plt.title(\"f(x,y) variational fit; actual curve is black, variational is blue\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
