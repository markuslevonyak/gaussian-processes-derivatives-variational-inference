#!/bin/bash
#SBATCH -J  stell                 # Job name
#SBATCH -o ./slurm_output/job_%j.out    # Name of stdout output file(%j expands to jobId)
#SBATCH -e ./slurm_output/job_%j.err    # Name of stderr output file(%j expands to jobId)
#SBATCH --get-user-env                     # Tells sbatch to retrieve the users login environment
#SBATCH -N 1                               # Total number of nodes requested
#SBATCH -n 1                               # Total number of cores requested
#SBATCH --mem=15000                        # Total amount of (real) memory requested (per node)
#SBATCH -t 168:00:00                       # Time limit (hh:mm:ss)
#SBATCH --partition=default_gpu            # Request partition for resource 
#SBATCH --gres=gpu:1                       # Specify a list of generic consumable resources (per node)
python stell_exp.py
