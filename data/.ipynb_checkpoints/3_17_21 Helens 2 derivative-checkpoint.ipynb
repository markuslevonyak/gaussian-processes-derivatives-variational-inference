{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mount St. Helens Countour Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import matplotlib\n",
    "import tqdm\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import sys\n",
    "import sys\n",
    "import scipy.io\n",
    "import torch\n",
    "import numpy as np \n",
    "sys.path.append(\"../directionalvi\")\n",
    "#sys.path.append(\"../../data\")\n",
    "sys.path.append(\"../directionalvi/utils\")\n",
    "from directional_vi import train_gp, eval_gp\n",
    "from metrics import MSE\n",
    "from metrics import MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "mat = scipy.io.loadmat('helens')\n",
    "x = torch.tensor(np.float64(mat['mth_points'])).float()\n",
    "#assume xs are positive\n",
    "SCALE_0_FACTOR = max(x[:, 0])\n",
    "SCALE_1_FACTOR = max(x[:, 1])\n",
    "x[:, 0] = x[:, 0]/SCALE_0_FACTOR\n",
    "x[:, 1] = x[:, 1]/SCALE_1_FACTOR\n",
    "y = torch.tensor(np.float64(mat['mth_verts'])).float()\n",
    "SCALE_Y_FACTOR = max(y)\n",
    "y = y/SCALE_Y_FACTOR\n",
    "#y = y - torch.mean(y)\n",
    "dy = torch.tensor(np.float64(mat['mth_grads'])).float()\n",
    "dy = dy / SCALE_Y_FACTOR #modify derivatives due to y-scaling\n",
    "dy[:, 0] = dy[:, 0]*SCALE_0_FACTOR #modify derivatives due to x-scaling\n",
    "dy[:, 1] = dy[:, 1]*SCALE_1_FACTOR\n",
    "data = torch.cat((y, dy), dim = 1).float()\n",
    "full_data = torch.cat((x, data), dim=1).float() #location concatenated with y and dy values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14040, 2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3033])\n"
     ]
    }
   ],
   "source": [
    "print(min(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter and Round Dataset (If Applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "temp_full_data = np.array(full_data)\n",
    "def fun(x, val = 0.1):\n",
    "    if x[0]>val or x[1]>val:       \n",
    "        return False \n",
    "    else:\n",
    "        return True\n",
    "filtered = filter(fun, temp_full_data)\n",
    "#for item in filtered:\n",
    "#    print(item)\n",
    "arr = [item for item in filtered]\n",
    "len_arr = len(arr)\n",
    "len_arr = len_arr - len_arr%100\n",
    "arr = arr[:len_arr]\n",
    "#full_data_truncated = torch.tensor(arr)\n",
    "print(len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2a243ddae88>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs1 = [item[0] for item in arr]\n",
    "xs2 = [item[1] for item in arr]\n",
    "plt.scatter(xs1, xs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3822)\n",
      "tensor(0.3616)\n"
     ]
    }
   ],
   "source": [
    "#recover x and data from filtered concatenated values\n",
    "x = torch.tensor([item[0:2] for item in arr])\n",
    "data = torch.tensor([item[2:] for item in arr])\n",
    "#data[:, 0] = data[:, 0] - torch.mean(data[:, 0]) #normalize\n",
    "print(max(data[:, 0]))\n",
    "print(min(data[:, 0]))\n",
    "\n",
    "# generate training data\n",
    "dataset = TensorDataset(x, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is:  100\n",
      "n_test is:  20\n",
      "num_inducing is: 50\n",
      "num_directions is:  2\n"
     ]
    }
   ],
   "source": [
    "# data parameters\n",
    "n  = data.shape[0] \n",
    "dim = 2\n",
    "n_test = n//5\n",
    "\n",
    "# training params\n",
    "num_inducing = 50\n",
    "num_directions = dim\n",
    "minibatch_size = n_test #how does minibatch size impact convergence rate\n",
    "num_epochs =  200\n",
    "\n",
    "#print\n",
    "print(\"n is: \", n)\n",
    "print(\"n_test is: \", n_test)\n",
    "print(\"num_inducing is:\", num_inducing)\n",
    "print(\"num_directions is: \", num_directions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [n - n_test, n_test], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader  = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
    "dim = len(train_dataset[0][0])\n",
    "n_samples = len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Step: 0, loss: 1.629319190979004\n",
      "Epoch: 1; Step: 0, loss: 1.472276210784912\n",
      "Epoch: 2; Step: 0, loss: 1.32328462600708\n",
      "Epoch: 3; Step: 0, loss: 1.1965081691741943\n",
      "Epoch: 4; Step: 0, loss: 1.087859034538269\n",
      "Epoch: 5; Step: 0, loss: 0.9881214499473572\n"
     ]
    }
   ],
   "source": [
    "model,likelihood = train_gp(train_dataset,\n",
    "                      num_inducing=num_inducing,\n",
    "                      num_directions=num_directions,\n",
    "                      minibatch_size = minibatch_size,\n",
    "                      minibatch_dim = num_directions,\n",
    "                      num_epochs =num_epochs\n",
    "                      )\n",
    "torch.save(model.state_dict(), \"helens_2_derivatives.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, variances = eval_gp( test_dataset,model,likelihood,\n",
    "                            num_directions=num_directions,\n",
    "                            minibatch_size=n_test,\n",
    "                            minibatch_dim=num_directions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.size(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader  = DataLoader(test_dataset, batch_size=n_test, shuffle=True)\n",
    "# predict in batches\n",
    "kwargs = {}\n",
    "derivative_directions = torch.eye(dim)[:num_directions]\n",
    "derivative_directions = derivative_directions.repeat(n_test,1)\n",
    "print(derivative_directions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "kwargs['derivative_directions'] = derivative_directions\n",
    "#means   = model(test_x, **kwargs).mean.cpu()\n",
    "means = torch.tensor([0.])\n",
    "test_y = torch.zeros(1,dim+1)\n",
    "test_x = torch.zeros(1,dim)\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        preds = model(x_batch,**kwargs)\n",
    "        means = torch.cat([means, preds.mean.cpu()])\n",
    "        test_y = torch.cat([test_y, y_batch])\n",
    "        test_x = torch.cat([test_x, x_batch])\n",
    "\n",
    "means = means[1:]\n",
    "test_y = test_y[1:]\n",
    "test_x = test_x[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute MSE\n",
    "test_mse = MSE(test_y[:,0],means[::num_directions+1])\n",
    "print(f\"\\nTesting MSE: {test_mse}\")\n",
    "print(f\"\\nTesting RMSE: {math.sqrt(test_mse)}\")\n",
    "test_mae = MAE(test_y[:,0],means[::num_directions+1])\n",
    "print(f\"\\nTesting MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing RMSE is 364 for 1000 epochs...\n",
    "# 300 inducing, 900 datapoints, 10% test, 1500 epochs: MAE = 101, MSE = 126\n",
    "#I suspect that 1500 epochs is not enough. Try 4000 if I have time...\n",
    "len(means[::num_directions+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#xlist = np.linspace(-3.0, 3.0, 100)\n",
    "#ylist = np.linspace(-3.0, 3.0, 100)\n",
    "#X, Y = np.meshgrid(xlist, ylist)\n",
    "#Z = np.sqrt(X**2 + Y**2)\n",
    "X = test_x[:, 0]\n",
    "Y = test_x[:, 1]\n",
    "Z = means[::num_directions+1]\n",
    "fig,ax=plt.subplots(1,1)\n",
    "cp = ax.contourf(X, Y, Z)\n",
    "fig.colorbar(cp) # Add a colorbar to a plot\n",
    "ax.set_title('Filled Contours Plot')\n",
    "#ax.set_xlabel('x (cm)')\n",
    "ax.set_ylabel('y (cm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.contour(test_x[:, 0], test_x[:, 1], means[::num_directions+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Actual vs Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mpl_toolkits.mplot3d import axes3d\n",
    "#import matplotlib.pyplot as plt\n",
    "#fig = plt.figure(figsize=(12,6))\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.scatter(train_x[:,0],train_x[:,1],train_y[:,0], color='k')\n",
    "#ax.scatter(train_x[:,0],train_x[:,1],preds.detach().numpy()[::num_directions+1], color='b')\n",
    "#plt.title(\"f(x,y) variational fit; actual curve is black, variational is blue\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-1, -2, -3]).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
